2024-07-28 18:01:47,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:01:47,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:01:47,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:01:47,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:06:23,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:06:23,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:06:23,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:06:23,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-28 18:10:41,514:INFO:PyCaret RegressionExperiment
2024-07-28 18:10:41,514:INFO:Logging name: reg-default-name
2024-07-28 18:10:41,514:INFO:ML Usecase: MLUsecase.REGRESSION
2024-07-28 18:10:41,514:INFO:version 3.2.0
2024-07-28 18:10:41,514:INFO:Initializing setup()
2024-07-28 18:10:41,514:INFO:self.USI: b5b6
2024-07-28 18:10:41,514:INFO:self._variable_keys: {'y_train', 'exp_name_log', 'n_jobs_param', 'exp_id', 'memory', 'fold_generator', 'target_param', 'transform_target_param', 'USI', 'pipeline', 'fold_groups_param', 'log_plots_param', 'X', 'X_train', 'y', '_available_plots', '_ml_usecase', 'idx', 'fold_shuffle_param', 'gpu_param', 'X_test', 'seed', 'y_test', 'gpu_n_jobs_param', 'data', 'logging_param', 'html_param'}
2024-07-28 18:10:41,514:INFO:Checking environment
2024-07-28 18:10:41,514:INFO:python_version: 3.8.10
2024-07-28 18:10:41,514:INFO:python_build: ('tags/v3.8.10:3d8993a', 'May  3 2021 11:48:03')
2024-07-28 18:10:41,514:INFO:machine: AMD64
2024-07-28 18:10:41,514:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-28 18:10:41,516:INFO:Memory: svmem(total=34308190208, available=19768049664, percent=42.4, used=14540140544, free=19768049664)
2024-07-28 18:10:41,516:INFO:Physical Core: 8
2024-07-28 18:10:41,516:INFO:Logical Core: 16
2024-07-28 18:10:41,516:INFO:Checking libraries
2024-07-28 18:10:41,516:INFO:System:
2024-07-28 18:10:41,516:INFO:    python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]
2024-07-28 18:10:41,516:INFO:executable: C:\Users\chima\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\python.exe
2024-07-28 18:10:41,517:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-28 18:10:41,517:INFO:PyCaret required dependencies:
2024-07-28 18:10:41,652:INFO:                 pip: 21.1.1
2024-07-28 18:10:41,652:INFO:          setuptools: 56.0.0
2024-07-28 18:10:41,652:INFO:             pycaret: 3.2.0
2024-07-28 18:10:41,652:INFO:             IPython: 8.4.0
2024-07-28 18:10:41,652:INFO:          ipywidgets: 8.1.3
2024-07-28 18:10:41,652:INFO:                tqdm: 4.65.0
2024-07-28 18:10:41,652:INFO:               numpy: 1.24.4
2024-07-28 18:10:41,652:INFO:              pandas: 1.5.0
2024-07-28 18:10:41,652:INFO:              jinja2: 3.1.4
2024-07-28 18:10:41,652:INFO:               scipy: 1.10.1
2024-07-28 18:10:41,652:INFO:              joblib: 1.2.0
2024-07-28 18:10:41,652:INFO:             sklearn: 1.2.2
2024-07-28 18:10:41,652:INFO:                pyod: 2.0.1
2024-07-28 18:10:41,653:INFO:            imblearn: 0.12.3
2024-07-28 18:10:41,653:INFO:   category_encoders: 2.6.3
2024-07-28 18:10:41,653:INFO:            lightgbm: 4.5.0
2024-07-28 18:10:41,653:INFO:               numba: 0.58.1
2024-07-28 18:10:41,653:INFO:            requests: 2.32.3
2024-07-28 18:10:41,653:INFO:          matplotlib: 3.6.0
2024-07-28 18:10:41,653:INFO:          scikitplot: 0.3.7
2024-07-28 18:10:41,653:INFO:         yellowbrick: 1.5
2024-07-28 18:10:41,653:INFO:              plotly: 5.23.0
2024-07-28 18:10:41,653:INFO:    plotly-resampler: Not installed
2024-07-28 18:10:41,653:INFO:             kaleido: 0.2.1
2024-07-28 18:10:41,653:INFO:           schemdraw: 0.15
2024-07-28 18:10:41,653:INFO:         statsmodels: 0.14.1
2024-07-28 18:10:41,653:INFO:              sktime: 0.21.1
2024-07-28 18:10:41,653:INFO:               tbats: 1.1.3
2024-07-28 18:10:41,653:INFO:            pmdarima: 2.0.4
2024-07-28 18:10:41,653:INFO:              psutil: 5.9.1
2024-07-28 18:10:41,653:INFO:          markupsafe: 2.1.5
2024-07-28 18:10:41,653:INFO:             pickle5: Not installed
2024-07-28 18:10:41,654:INFO:         cloudpickle: 3.0.0
2024-07-28 18:10:41,654:INFO:         deprecation: 2.1.0
2024-07-28 18:10:41,654:INFO:              xxhash: 3.4.1
2024-07-28 18:10:41,654:INFO:           wurlitzer: Not installed
2024-07-28 18:10:41,654:INFO:PyCaret optional dependencies:
2024-07-28 18:10:41,685:INFO:                shap: Not installed
2024-07-28 18:10:41,685:INFO:           interpret: Not installed
2024-07-28 18:10:41,685:INFO:                umap: Not installed
2024-07-28 18:10:41,685:INFO:     ydata_profiling: Not installed
2024-07-28 18:10:41,685:INFO:  explainerdashboard: Not installed
2024-07-28 18:10:41,685:INFO:             autoviz: Not installed
2024-07-28 18:10:41,685:INFO:           fairlearn: Not installed
2024-07-28 18:10:41,685:INFO:          deepchecks: Not installed
2024-07-28 18:10:41,685:INFO:             xgboost: Not installed
2024-07-28 18:10:41,685:INFO:            catboost: Not installed
2024-07-28 18:10:41,685:INFO:              kmodes: Not installed
2024-07-28 18:10:41,685:INFO:             mlxtend: Not installed
2024-07-28 18:10:41,685:INFO:       statsforecast: Not installed
2024-07-28 18:10:41,685:INFO:        tune_sklearn: Not installed
2024-07-28 18:10:41,685:INFO:                 ray: Not installed
2024-07-28 18:10:41,685:INFO:            hyperopt: Not installed
2024-07-28 18:10:41,685:INFO:              optuna: Not installed
2024-07-28 18:10:41,685:INFO:               skopt: Not installed
2024-07-28 18:10:41,685:INFO:              mlflow: Not installed
2024-07-28 18:10:41,685:INFO:              gradio: Not installed
2024-07-28 18:10:41,685:INFO:             fastapi: Not installed
2024-07-28 18:10:41,685:INFO:             uvicorn: Not installed
2024-07-28 18:10:41,685:INFO:              m2cgen: Not installed
2024-07-28 18:10:41,685:INFO:           evidently: Not installed
2024-07-28 18:10:41,685:INFO:               fugue: Not installed
2024-07-28 18:10:41,685:INFO:           streamlit: Not installed
2024-07-28 18:10:41,685:INFO:             prophet: Not installed
2024-07-28 18:10:41,686:INFO:None
2024-07-28 18:10:41,686:INFO:Set up data.
2024-07-28 18:13:30,137:WARNING:C:\Users\chima\AppData\Local\Temp\ipykernel_47480\1382177597.py:5: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = new_df.corr()

2024-07-28 18:13:31,078:INFO:PyCaret RegressionExperiment
2024-07-28 18:13:31,078:INFO:Logging name: reg-default-name
2024-07-28 18:13:31,078:INFO:ML Usecase: MLUsecase.REGRESSION
2024-07-28 18:13:31,079:INFO:version 3.2.0
2024-07-28 18:13:31,079:INFO:Initializing setup()
2024-07-28 18:13:31,079:INFO:self.USI: 3fa3
2024-07-28 18:13:31,079:INFO:self._variable_keys: {'y_train', 'exp_name_log', 'n_jobs_param', 'exp_id', 'memory', 'fold_generator', 'target_param', 'transform_target_param', 'USI', 'pipeline', 'fold_groups_param', 'log_plots_param', 'X', 'X_train', 'y', '_available_plots', '_ml_usecase', 'idx', 'fold_shuffle_param', 'gpu_param', 'X_test', 'seed', 'y_test', 'gpu_n_jobs_param', 'data', 'logging_param', 'html_param'}
2024-07-28 18:13:31,079:INFO:Checking environment
2024-07-28 18:13:31,079:INFO:python_version: 3.8.10
2024-07-28 18:13:31,079:INFO:python_build: ('tags/v3.8.10:3d8993a', 'May  3 2021 11:48:03')
2024-07-28 18:13:31,079:INFO:machine: AMD64
2024-07-28 18:13:31,079:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-28 18:13:31,079:INFO:Memory: svmem(total=34308190208, available=19229302784, percent=44.0, used=15078887424, free=19229302784)
2024-07-28 18:13:31,079:INFO:Physical Core: 8
2024-07-28 18:13:31,079:INFO:Logical Core: 16
2024-07-28 18:13:31,079:INFO:Checking libraries
2024-07-28 18:13:31,079:INFO:System:
2024-07-28 18:13:31,080:INFO:    python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]
2024-07-28 18:13:31,080:INFO:executable: C:\Users\chima\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\python.exe
2024-07-28 18:13:31,080:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-28 18:13:31,080:INFO:PyCaret required dependencies:
2024-07-28 18:13:31,080:INFO:                 pip: 21.1.1
2024-07-28 18:13:31,080:INFO:          setuptools: 56.0.0
2024-07-28 18:13:31,080:INFO:             pycaret: 3.2.0
2024-07-28 18:13:31,080:INFO:             IPython: 8.4.0
2024-07-28 18:13:31,080:INFO:          ipywidgets: 8.1.3
2024-07-28 18:13:31,080:INFO:                tqdm: 4.65.0
2024-07-28 18:13:31,081:INFO:               numpy: 1.24.4
2024-07-28 18:13:31,081:INFO:              pandas: 1.5.0
2024-07-28 18:13:31,081:INFO:              jinja2: 3.1.4
2024-07-28 18:13:31,081:INFO:               scipy: 1.10.1
2024-07-28 18:13:31,081:INFO:              joblib: 1.2.0
2024-07-28 18:13:31,081:INFO:             sklearn: 1.2.2
2024-07-28 18:13:31,081:INFO:                pyod: 2.0.1
2024-07-28 18:13:31,081:INFO:            imblearn: 0.12.3
2024-07-28 18:13:31,082:INFO:   category_encoders: 2.6.3
2024-07-28 18:13:31,082:INFO:            lightgbm: 4.5.0
2024-07-28 18:13:31,082:INFO:               numba: 0.58.1
2024-07-28 18:13:31,082:INFO:            requests: 2.32.3
2024-07-28 18:13:31,082:INFO:          matplotlib: 3.6.0
2024-07-28 18:13:31,082:INFO:          scikitplot: 0.3.7
2024-07-28 18:13:31,082:INFO:         yellowbrick: 1.5
2024-07-28 18:13:31,082:INFO:              plotly: 5.23.0
2024-07-28 18:13:31,082:INFO:    plotly-resampler: Not installed
2024-07-28 18:13:31,082:INFO:             kaleido: 0.2.1
2024-07-28 18:13:31,082:INFO:           schemdraw: 0.15
2024-07-28 18:13:31,082:INFO:         statsmodels: 0.14.1
2024-07-28 18:13:31,082:INFO:              sktime: 0.21.1
2024-07-28 18:13:31,083:INFO:               tbats: 1.1.3
2024-07-28 18:13:31,083:INFO:            pmdarima: 2.0.4
2024-07-28 18:13:31,083:INFO:              psutil: 5.9.1
2024-07-28 18:13:31,083:INFO:          markupsafe: 2.1.5
2024-07-28 18:13:31,083:INFO:             pickle5: Not installed
2024-07-28 18:13:31,083:INFO:         cloudpickle: 3.0.0
2024-07-28 18:13:31,083:INFO:         deprecation: 2.1.0
2024-07-28 18:13:31,083:INFO:              xxhash: 3.4.1
2024-07-28 18:13:31,083:INFO:           wurlitzer: Not installed
2024-07-28 18:13:31,083:INFO:PyCaret optional dependencies:
2024-07-28 18:13:31,083:INFO:                shap: Not installed
2024-07-28 18:13:31,084:INFO:           interpret: Not installed
2024-07-28 18:13:31,084:INFO:                umap: Not installed
2024-07-28 18:13:31,084:INFO:     ydata_profiling: Not installed
2024-07-28 18:13:31,084:INFO:  explainerdashboard: Not installed
2024-07-28 18:13:31,084:INFO:             autoviz: Not installed
2024-07-28 18:13:31,084:INFO:           fairlearn: Not installed
2024-07-28 18:13:31,084:INFO:          deepchecks: Not installed
2024-07-28 18:13:31,084:INFO:             xgboost: Not installed
2024-07-28 18:13:31,085:INFO:            catboost: Not installed
2024-07-28 18:13:31,085:INFO:              kmodes: Not installed
2024-07-28 18:13:31,085:INFO:             mlxtend: Not installed
2024-07-28 18:13:31,085:INFO:       statsforecast: Not installed
2024-07-28 18:13:31,085:INFO:        tune_sklearn: Not installed
2024-07-28 18:13:31,085:INFO:                 ray: Not installed
2024-07-28 18:13:31,085:INFO:            hyperopt: Not installed
2024-07-28 18:13:31,085:INFO:              optuna: Not installed
2024-07-28 18:13:31,085:INFO:               skopt: Not installed
2024-07-28 18:13:31,085:INFO:              mlflow: Not installed
2024-07-28 18:13:31,085:INFO:              gradio: Not installed
2024-07-28 18:13:31,085:INFO:             fastapi: Not installed
2024-07-28 18:13:31,086:INFO:             uvicorn: Not installed
2024-07-28 18:13:31,086:INFO:              m2cgen: Not installed
2024-07-28 18:13:31,086:INFO:           evidently: Not installed
2024-07-28 18:13:31,086:INFO:               fugue: Not installed
2024-07-28 18:13:31,086:INFO:           streamlit: Not installed
2024-07-28 18:13:31,086:INFO:             prophet: Not installed
2024-07-28 18:13:31,086:INFO:None
2024-07-28 18:13:31,086:INFO:Set up data.
2024-07-28 18:13:31,111:INFO:Set up folding strategy.
2024-07-28 18:13:31,111:INFO:Set up train/test split.
2024-07-28 18:13:31,144:INFO:Set up index.
2024-07-28 18:13:31,145:INFO:Assigning column types.
2024-07-28 18:13:31,158:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-28 18:13:31,158:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,172:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,183:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,296:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,371:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,379:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,538:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-07-28 18:13:31,545:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,638:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,711:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,718:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:31,875:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-07-28 18:13:31,889:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-28 18:13:31,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,265:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-07-28 18:13:32,379:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,612:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-28 18:13:32,712:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,874:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-28 18:13:32,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:32,940:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-07-28 18:13:33,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:33,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:33,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:33,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:33,275:INFO:Preparing preprocessing pipeline...
2024-07-28 18:13:33,275:INFO:Set up simple imputation.
2024-07-28 18:13:33,282:INFO:Set up encoding of categorical features.
2024-07-28 18:13:33,284:INFO:Set up column name cleaning.
2024-07-28 18:13:33,411:INFO:Finished creating preprocessing pipeline.
2024-07-28 18:13:33,428:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chima\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-07-28 18:13:33,428:INFO:Creating final display dataframe.
2024-07-28 18:13:33,764:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    Rating Average
2                   Target type        Regression
3           Original data shape        (8861, 12)
4        Transformed data shape        (8861, 12)
5   Transformed train set shape        (6202, 12)
6    Transformed test set shape        (2659, 12)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values              4.4%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3fa3
2024-07-28 18:13:33,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:33,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:34,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:34,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-28 18:13:34,101:INFO:setup() successfully completed in 3.03s...............
2024-07-28 18:14:04,510:INFO:Initializing compare_models()
2024-07-28 18:14:04,510:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-07-28 18:14:04,510:INFO:Checking exceptions
2024-07-28 18:14:04,513:INFO:Preparing display monitor
2024-07-28 18:14:04,556:INFO:Initializing Linear Regression
2024-07-28 18:14:04,556:INFO:Total runtime is 0.0 minutes
2024-07-28 18:14:04,567:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:04,568:INFO:Initializing create_model()
2024-07-28 18:14:04,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:04,568:INFO:Checking exceptions
2024-07-28 18:14:04,568:INFO:Importing libraries
2024-07-28 18:14:04,569:INFO:Copying training dataset
2024-07-28 18:14:04,574:INFO:Defining folds
2024-07-28 18:14:04,575:INFO:Declaring metric variables
2024-07-28 18:14:04,578:INFO:Importing untrained model
2024-07-28 18:14:04,582:INFO:Linear Regression Imported successfully
2024-07-28 18:14:04,591:INFO:Starting cross validation
2024-07-28 18:14:04,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:10,410:INFO:Calculating mean and std
2024-07-28 18:14:10,412:INFO:Creating metrics dataframe
2024-07-28 18:14:10,419:INFO:Uploading results into container
2024-07-28 18:14:10,420:INFO:Uploading model into container now
2024-07-28 18:14:10,421:INFO:_master_model_container: 1
2024-07-28 18:14:10,421:INFO:_display_container: 2
2024-07-28 18:14:10,421:INFO:LinearRegression(n_jobs=-1)
2024-07-28 18:14:10,421:INFO:create_model() successfully completed......................................
2024-07-28 18:14:11,738:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:11,738:INFO:Creating metrics dataframe
2024-07-28 18:14:11,747:INFO:Initializing Lasso Regression
2024-07-28 18:14:11,747:INFO:Total runtime is 0.11984950304031372 minutes
2024-07-28 18:14:11,751:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:11,752:INFO:Initializing create_model()
2024-07-28 18:14:11,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:11,752:INFO:Checking exceptions
2024-07-28 18:14:11,752:INFO:Importing libraries
2024-07-28 18:14:11,752:INFO:Copying training dataset
2024-07-28 18:14:11,760:INFO:Defining folds
2024-07-28 18:14:11,760:INFO:Declaring metric variables
2024-07-28 18:14:11,764:INFO:Importing untrained model
2024-07-28 18:14:11,769:INFO:Lasso Regression Imported successfully
2024-07-28 18:14:11,777:INFO:Starting cross validation
2024-07-28 18:14:11,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:14,966:INFO:Calculating mean and std
2024-07-28 18:14:14,967:INFO:Creating metrics dataframe
2024-07-28 18:14:14,971:INFO:Uploading results into container
2024-07-28 18:14:14,972:INFO:Uploading model into container now
2024-07-28 18:14:14,973:INFO:_master_model_container: 2
2024-07-28 18:14:14,973:INFO:_display_container: 2
2024-07-28 18:14:14,973:INFO:Lasso(random_state=123)
2024-07-28 18:14:14,973:INFO:create_model() successfully completed......................................
2024-07-28 18:14:15,959:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:15,960:INFO:Creating metrics dataframe
2024-07-28 18:14:15,971:INFO:Initializing Ridge Regression
2024-07-28 18:14:15,972:INFO:Total runtime is 0.1902632435162862 minutes
2024-07-28 18:14:15,976:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:15,977:INFO:Initializing create_model()
2024-07-28 18:14:15,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:15,977:INFO:Checking exceptions
2024-07-28 18:14:15,977:INFO:Importing libraries
2024-07-28 18:14:15,977:INFO:Copying training dataset
2024-07-28 18:14:15,985:INFO:Defining folds
2024-07-28 18:14:15,985:INFO:Declaring metric variables
2024-07-28 18:14:15,990:INFO:Importing untrained model
2024-07-28 18:14:15,994:INFO:Ridge Regression Imported successfully
2024-07-28 18:14:16,002:INFO:Starting cross validation
2024-07-28 18:14:16,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:16,253:INFO:Calculating mean and std
2024-07-28 18:14:16,255:INFO:Creating metrics dataframe
2024-07-28 18:14:16,258:INFO:Uploading results into container
2024-07-28 18:14:16,259:INFO:Uploading model into container now
2024-07-28 18:14:16,259:INFO:_master_model_container: 3
2024-07-28 18:14:16,259:INFO:_display_container: 2
2024-07-28 18:14:16,260:INFO:Ridge(random_state=123)
2024-07-28 18:14:16,260:INFO:create_model() successfully completed......................................
2024-07-28 18:14:16,654:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:16,654:INFO:Creating metrics dataframe
2024-07-28 18:14:16,667:INFO:Initializing Elastic Net
2024-07-28 18:14:16,667:INFO:Total runtime is 0.20184196631113688 minutes
2024-07-28 18:14:16,670:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:16,671:INFO:Initializing create_model()
2024-07-28 18:14:16,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:16,671:INFO:Checking exceptions
2024-07-28 18:14:16,671:INFO:Importing libraries
2024-07-28 18:14:16,671:INFO:Copying training dataset
2024-07-28 18:14:16,679:INFO:Defining folds
2024-07-28 18:14:16,679:INFO:Declaring metric variables
2024-07-28 18:14:16,683:INFO:Importing untrained model
2024-07-28 18:14:16,687:INFO:Elastic Net Imported successfully
2024-07-28 18:14:16,695:INFO:Starting cross validation
2024-07-28 18:14:16,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:16,942:INFO:Calculating mean and std
2024-07-28 18:14:16,944:INFO:Creating metrics dataframe
2024-07-28 18:14:16,947:INFO:Uploading results into container
2024-07-28 18:14:16,948:INFO:Uploading model into container now
2024-07-28 18:14:16,948:INFO:_master_model_container: 4
2024-07-28 18:14:16,949:INFO:_display_container: 2
2024-07-28 18:14:16,949:INFO:ElasticNet(random_state=123)
2024-07-28 18:14:16,949:INFO:create_model() successfully completed......................................
2024-07-28 18:14:17,390:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:17,391:INFO:Creating metrics dataframe
2024-07-28 18:14:17,404:INFO:Initializing Least Angle Regression
2024-07-28 18:14:17,404:INFO:Total runtime is 0.2141175349553426 minutes
2024-07-28 18:14:17,408:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:17,408:INFO:Initializing create_model()
2024-07-28 18:14:17,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:17,409:INFO:Checking exceptions
2024-07-28 18:14:17,409:INFO:Importing libraries
2024-07-28 18:14:17,409:INFO:Copying training dataset
2024-07-28 18:14:17,416:INFO:Defining folds
2024-07-28 18:14:17,417:INFO:Declaring metric variables
2024-07-28 18:14:17,420:INFO:Importing untrained model
2024-07-28 18:14:17,426:INFO:Least Angle Regression Imported successfully
2024-07-28 18:14:17,434:INFO:Starting cross validation
2024-07-28 18:14:17,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:17,675:INFO:Calculating mean and std
2024-07-28 18:14:17,676:INFO:Creating metrics dataframe
2024-07-28 18:14:17,680:INFO:Uploading results into container
2024-07-28 18:14:17,681:INFO:Uploading model into container now
2024-07-28 18:14:17,681:INFO:_master_model_container: 5
2024-07-28 18:14:17,681:INFO:_display_container: 2
2024-07-28 18:14:17,682:INFO:Lars(random_state=123)
2024-07-28 18:14:17,682:INFO:create_model() successfully completed......................................
2024-07-28 18:14:18,115:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:18,115:INFO:Creating metrics dataframe
2024-07-28 18:14:18,126:INFO:Initializing Lasso Least Angle Regression
2024-07-28 18:14:18,126:INFO:Total runtime is 0.2261621594429016 minutes
2024-07-28 18:14:18,131:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:18,131:INFO:Initializing create_model()
2024-07-28 18:14:18,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:18,132:INFO:Checking exceptions
2024-07-28 18:14:18,132:INFO:Importing libraries
2024-07-28 18:14:18,132:INFO:Copying training dataset
2024-07-28 18:14:18,140:INFO:Defining folds
2024-07-28 18:14:18,140:INFO:Declaring metric variables
2024-07-28 18:14:18,145:INFO:Importing untrained model
2024-07-28 18:14:18,149:INFO:Lasso Least Angle Regression Imported successfully
2024-07-28 18:14:18,157:INFO:Starting cross validation
2024-07-28 18:14:18,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:18,380:INFO:Calculating mean and std
2024-07-28 18:14:18,382:INFO:Creating metrics dataframe
2024-07-28 18:14:18,385:INFO:Uploading results into container
2024-07-28 18:14:18,386:INFO:Uploading model into container now
2024-07-28 18:14:18,386:INFO:_master_model_container: 6
2024-07-28 18:14:18,386:INFO:_display_container: 2
2024-07-28 18:14:18,387:INFO:LassoLars(random_state=123)
2024-07-28 18:14:18,387:INFO:create_model() successfully completed......................................
2024-07-28 18:14:18,778:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:18,778:INFO:Creating metrics dataframe
2024-07-28 18:14:18,790:INFO:Initializing Orthogonal Matching Pursuit
2024-07-28 18:14:18,790:INFO:Total runtime is 0.2372279167175293 minutes
2024-07-28 18:14:18,795:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:18,795:INFO:Initializing create_model()
2024-07-28 18:14:18,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:18,795:INFO:Checking exceptions
2024-07-28 18:14:18,795:INFO:Importing libraries
2024-07-28 18:14:18,795:INFO:Copying training dataset
2024-07-28 18:14:18,803:INFO:Defining folds
2024-07-28 18:14:18,803:INFO:Declaring metric variables
2024-07-28 18:14:18,807:INFO:Importing untrained model
2024-07-28 18:14:18,812:INFO:Orthogonal Matching Pursuit Imported successfully
2024-07-28 18:14:18,821:INFO:Starting cross validation
2024-07-28 18:14:18,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:19,065:INFO:Calculating mean and std
2024-07-28 18:14:19,067:INFO:Creating metrics dataframe
2024-07-28 18:14:19,072:INFO:Uploading results into container
2024-07-28 18:14:19,073:INFO:Uploading model into container now
2024-07-28 18:14:19,073:INFO:_master_model_container: 7
2024-07-28 18:14:19,073:INFO:_display_container: 2
2024-07-28 18:14:19,074:INFO:OrthogonalMatchingPursuit()
2024-07-28 18:14:19,074:INFO:create_model() successfully completed......................................
2024-07-28 18:14:19,481:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:19,481:INFO:Creating metrics dataframe
2024-07-28 18:14:19,493:INFO:Initializing Bayesian Ridge
2024-07-28 18:14:19,493:INFO:Total runtime is 0.2489369034767151 minutes
2024-07-28 18:14:19,498:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:19,498:INFO:Initializing create_model()
2024-07-28 18:14:19,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:19,498:INFO:Checking exceptions
2024-07-28 18:14:19,498:INFO:Importing libraries
2024-07-28 18:14:19,499:INFO:Copying training dataset
2024-07-28 18:14:19,505:INFO:Defining folds
2024-07-28 18:14:19,506:INFO:Declaring metric variables
2024-07-28 18:14:19,509:INFO:Importing untrained model
2024-07-28 18:14:19,513:INFO:Bayesian Ridge Imported successfully
2024-07-28 18:14:19,522:INFO:Starting cross validation
2024-07-28 18:14:19,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:19,752:INFO:Calculating mean and std
2024-07-28 18:14:19,754:INFO:Creating metrics dataframe
2024-07-28 18:14:19,757:INFO:Uploading results into container
2024-07-28 18:14:19,758:INFO:Uploading model into container now
2024-07-28 18:14:19,758:INFO:_master_model_container: 8
2024-07-28 18:14:19,758:INFO:_display_container: 2
2024-07-28 18:14:19,759:INFO:BayesianRidge()
2024-07-28 18:14:19,759:INFO:create_model() successfully completed......................................
2024-07-28 18:14:20,138:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:20,138:INFO:Creating metrics dataframe
2024-07-28 18:14:20,149:INFO:Initializing Passive Aggressive Regressor
2024-07-28 18:14:20,149:INFO:Total runtime is 0.25987701416015624 minutes
2024-07-28 18:14:20,154:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:20,154:INFO:Initializing create_model()
2024-07-28 18:14:20,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:20,154:INFO:Checking exceptions
2024-07-28 18:14:20,154:INFO:Importing libraries
2024-07-28 18:14:20,154:INFO:Copying training dataset
2024-07-28 18:14:20,160:INFO:Defining folds
2024-07-28 18:14:20,160:INFO:Declaring metric variables
2024-07-28 18:14:20,166:INFO:Importing untrained model
2024-07-28 18:14:20,170:INFO:Passive Aggressive Regressor Imported successfully
2024-07-28 18:14:20,178:INFO:Starting cross validation
2024-07-28 18:14:20,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:20,414:INFO:Calculating mean and std
2024-07-28 18:14:20,416:INFO:Creating metrics dataframe
2024-07-28 18:14:20,419:INFO:Uploading results into container
2024-07-28 18:14:20,419:INFO:Uploading model into container now
2024-07-28 18:14:20,420:INFO:_master_model_container: 9
2024-07-28 18:14:20,420:INFO:_display_container: 2
2024-07-28 18:14:20,420:INFO:PassiveAggressiveRegressor(random_state=123)
2024-07-28 18:14:20,421:INFO:create_model() successfully completed......................................
2024-07-28 18:14:20,797:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:20,797:INFO:Creating metrics dataframe
2024-07-28 18:14:20,808:INFO:Initializing Huber Regressor
2024-07-28 18:14:20,809:INFO:Total runtime is 0.2708654006322225 minutes
2024-07-28 18:14:20,812:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:20,813:INFO:Initializing create_model()
2024-07-28 18:14:20,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:20,813:INFO:Checking exceptions
2024-07-28 18:14:20,813:INFO:Importing libraries
2024-07-28 18:14:20,814:INFO:Copying training dataset
2024-07-28 18:14:20,820:INFO:Defining folds
2024-07-28 18:14:20,821:INFO:Declaring metric variables
2024-07-28 18:14:20,825:INFO:Importing untrained model
2024-07-28 18:14:20,828:INFO:Huber Regressor Imported successfully
2024-07-28 18:14:20,836:INFO:Starting cross validation
2024-07-28 18:14:20,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:21,150:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,155:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,199:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,205:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,213:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,218:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,222:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,222:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,244:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-28 18:14:21,274:INFO:Calculating mean and std
2024-07-28 18:14:21,276:INFO:Creating metrics dataframe
2024-07-28 18:14:21,278:INFO:Uploading results into container
2024-07-28 18:14:21,279:INFO:Uploading model into container now
2024-07-28 18:14:21,280:INFO:_master_model_container: 10
2024-07-28 18:14:21,280:INFO:_display_container: 2
2024-07-28 18:14:21,280:INFO:HuberRegressor()
2024-07-28 18:14:21,280:INFO:create_model() successfully completed......................................
2024-07-28 18:14:21,645:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:21,646:INFO:Creating metrics dataframe
2024-07-28 18:14:21,659:INFO:Initializing K Neighbors Regressor
2024-07-28 18:14:21,659:INFO:Total runtime is 0.28504167000452674 minutes
2024-07-28 18:14:21,663:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:21,663:INFO:Initializing create_model()
2024-07-28 18:14:21,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:21,664:INFO:Checking exceptions
2024-07-28 18:14:21,664:INFO:Importing libraries
2024-07-28 18:14:21,664:INFO:Copying training dataset
2024-07-28 18:14:21,671:INFO:Defining folds
2024-07-28 18:14:21,672:INFO:Declaring metric variables
2024-07-28 18:14:21,676:INFO:Importing untrained model
2024-07-28 18:14:21,680:INFO:K Neighbors Regressor Imported successfully
2024-07-28 18:14:21,688:INFO:Starting cross validation
2024-07-28 18:14:21,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:21,965:INFO:Calculating mean and std
2024-07-28 18:14:21,966:INFO:Creating metrics dataframe
2024-07-28 18:14:21,970:INFO:Uploading results into container
2024-07-28 18:14:21,971:INFO:Uploading model into container now
2024-07-28 18:14:21,971:INFO:_master_model_container: 11
2024-07-28 18:14:21,971:INFO:_display_container: 2
2024-07-28 18:14:21,972:INFO:KNeighborsRegressor(n_jobs=-1)
2024-07-28 18:14:21,972:INFO:create_model() successfully completed......................................
2024-07-28 18:14:22,348:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:22,349:INFO:Creating metrics dataframe
2024-07-28 18:14:22,361:INFO:Initializing Decision Tree Regressor
2024-07-28 18:14:22,362:INFO:Total runtime is 0.2967557867368062 minutes
2024-07-28 18:14:22,366:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:22,366:INFO:Initializing create_model()
2024-07-28 18:14:22,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:22,366:INFO:Checking exceptions
2024-07-28 18:14:22,366:INFO:Importing libraries
2024-07-28 18:14:22,366:INFO:Copying training dataset
2024-07-28 18:14:22,373:INFO:Defining folds
2024-07-28 18:14:22,373:INFO:Declaring metric variables
2024-07-28 18:14:22,378:INFO:Importing untrained model
2024-07-28 18:14:22,382:INFO:Decision Tree Regressor Imported successfully
2024-07-28 18:14:22,390:INFO:Starting cross validation
2024-07-28 18:14:22,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:22,667:INFO:Calculating mean and std
2024-07-28 18:14:22,668:INFO:Creating metrics dataframe
2024-07-28 18:14:22,672:INFO:Uploading results into container
2024-07-28 18:14:22,673:INFO:Uploading model into container now
2024-07-28 18:14:22,673:INFO:_master_model_container: 12
2024-07-28 18:14:22,673:INFO:_display_container: 2
2024-07-28 18:14:22,674:INFO:DecisionTreeRegressor(random_state=123)
2024-07-28 18:14:22,674:INFO:create_model() successfully completed......................................
2024-07-28 18:14:23,086:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:23,086:INFO:Creating metrics dataframe
2024-07-28 18:14:23,099:INFO:Initializing Random Forest Regressor
2024-07-28 18:14:23,099:INFO:Total runtime is 0.3090424299240112 minutes
2024-07-28 18:14:23,103:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:23,104:INFO:Initializing create_model()
2024-07-28 18:14:23,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:23,104:INFO:Checking exceptions
2024-07-28 18:14:23,104:INFO:Importing libraries
2024-07-28 18:14:23,104:INFO:Copying training dataset
2024-07-28 18:14:23,111:INFO:Defining folds
2024-07-28 18:14:23,112:INFO:Declaring metric variables
2024-07-28 18:14:23,116:INFO:Importing untrained model
2024-07-28 18:14:23,120:INFO:Random Forest Regressor Imported successfully
2024-07-28 18:14:23,127:INFO:Starting cross validation
2024-07-28 18:14:23,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:27,713:INFO:Calculating mean and std
2024-07-28 18:14:27,716:INFO:Creating metrics dataframe
2024-07-28 18:14:27,719:INFO:Uploading results into container
2024-07-28 18:14:27,720:INFO:Uploading model into container now
2024-07-28 18:14:27,721:INFO:_master_model_container: 13
2024-07-28 18:14:27,721:INFO:_display_container: 2
2024-07-28 18:14:27,721:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-07-28 18:14:27,721:INFO:create_model() successfully completed......................................
2024-07-28 18:14:28,108:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:28,108:INFO:Creating metrics dataframe
2024-07-28 18:14:28,122:INFO:Initializing Extra Trees Regressor
2024-07-28 18:14:28,122:INFO:Total runtime is 0.392760956287384 minutes
2024-07-28 18:14:28,126:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:28,127:INFO:Initializing create_model()
2024-07-28 18:14:28,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:28,127:INFO:Checking exceptions
2024-07-28 18:14:28,127:INFO:Importing libraries
2024-07-28 18:14:28,127:INFO:Copying training dataset
2024-07-28 18:14:28,134:INFO:Defining folds
2024-07-28 18:14:28,134:INFO:Declaring metric variables
2024-07-28 18:14:28,138:INFO:Importing untrained model
2024-07-28 18:14:28,142:INFO:Extra Trees Regressor Imported successfully
2024-07-28 18:14:28,151:INFO:Starting cross validation
2024-07-28 18:14:28,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:30,255:INFO:Calculating mean and std
2024-07-28 18:14:30,257:INFO:Creating metrics dataframe
2024-07-28 18:14:30,261:INFO:Uploading results into container
2024-07-28 18:14:30,261:INFO:Uploading model into container now
2024-07-28 18:14:30,262:INFO:_master_model_container: 14
2024-07-28 18:14:30,262:INFO:_display_container: 2
2024-07-28 18:14:30,262:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-07-28 18:14:30,262:INFO:create_model() successfully completed......................................
2024-07-28 18:14:30,660:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:30,660:INFO:Creating metrics dataframe
2024-07-28 18:14:30,675:INFO:Initializing AdaBoost Regressor
2024-07-28 18:14:30,675:INFO:Total runtime is 0.43531403938929236 minutes
2024-07-28 18:14:30,679:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:30,679:INFO:Initializing create_model()
2024-07-28 18:14:30,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:30,680:INFO:Checking exceptions
2024-07-28 18:14:30,680:INFO:Importing libraries
2024-07-28 18:14:30,680:INFO:Copying training dataset
2024-07-28 18:14:30,686:INFO:Defining folds
2024-07-28 18:14:30,686:INFO:Declaring metric variables
2024-07-28 18:14:30,690:INFO:Importing untrained model
2024-07-28 18:14:30,695:INFO:AdaBoost Regressor Imported successfully
2024-07-28 18:14:30,703:INFO:Starting cross validation
2024-07-28 18:14:30,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:31,498:INFO:Calculating mean and std
2024-07-28 18:14:31,500:INFO:Creating metrics dataframe
2024-07-28 18:14:31,503:INFO:Uploading results into container
2024-07-28 18:14:31,504:INFO:Uploading model into container now
2024-07-28 18:14:31,506:INFO:_master_model_container: 15
2024-07-28 18:14:31,506:INFO:_display_container: 2
2024-07-28 18:14:31,506:INFO:AdaBoostRegressor(random_state=123)
2024-07-28 18:14:31,506:INFO:create_model() successfully completed......................................
2024-07-28 18:14:31,916:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:31,917:INFO:Creating metrics dataframe
2024-07-28 18:14:31,931:INFO:Initializing Gradient Boosting Regressor
2024-07-28 18:14:31,931:INFO:Total runtime is 0.4562364339828491 minutes
2024-07-28 18:14:31,934:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:31,935:INFO:Initializing create_model()
2024-07-28 18:14:31,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:31,935:INFO:Checking exceptions
2024-07-28 18:14:31,935:INFO:Importing libraries
2024-07-28 18:14:31,935:INFO:Copying training dataset
2024-07-28 18:14:31,942:INFO:Defining folds
2024-07-28 18:14:31,942:INFO:Declaring metric variables
2024-07-28 18:14:31,947:INFO:Importing untrained model
2024-07-28 18:14:31,952:INFO:Gradient Boosting Regressor Imported successfully
2024-07-28 18:14:31,958:INFO:Starting cross validation
2024-07-28 18:14:31,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:33,648:INFO:Calculating mean and std
2024-07-28 18:14:33,650:INFO:Creating metrics dataframe
2024-07-28 18:14:33,653:INFO:Uploading results into container
2024-07-28 18:14:33,654:INFO:Uploading model into container now
2024-07-28 18:14:33,654:INFO:_master_model_container: 16
2024-07-28 18:14:33,654:INFO:_display_container: 2
2024-07-28 18:14:33,654:INFO:GradientBoostingRegressor(random_state=123)
2024-07-28 18:14:33,655:INFO:create_model() successfully completed......................................
2024-07-28 18:14:34,046:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:34,047:INFO:Creating metrics dataframe
2024-07-28 18:14:34,060:INFO:Initializing Light Gradient Boosting Machine
2024-07-28 18:14:34,060:INFO:Total runtime is 0.4917264938354492 minutes
2024-07-28 18:14:34,064:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:34,065:INFO:Initializing create_model()
2024-07-28 18:14:34,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:34,065:INFO:Checking exceptions
2024-07-28 18:14:34,065:INFO:Importing libraries
2024-07-28 18:14:34,065:INFO:Copying training dataset
2024-07-28 18:14:34,072:INFO:Defining folds
2024-07-28 18:14:34,072:INFO:Declaring metric variables
2024-07-28 18:14:34,075:INFO:Importing untrained model
2024-07-28 18:14:34,081:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-28 18:14:34,090:INFO:Starting cross validation
2024-07-28 18:14:34,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:36,903:INFO:Calculating mean and std
2024-07-28 18:14:36,908:INFO:Creating metrics dataframe
2024-07-28 18:14:36,916:INFO:Uploading results into container
2024-07-28 18:14:36,918:INFO:Uploading model into container now
2024-07-28 18:14:36,919:INFO:_master_model_container: 17
2024-07-28 18:14:36,919:INFO:_display_container: 2
2024-07-28 18:14:36,920:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-07-28 18:14:36,920:INFO:create_model() successfully completed......................................
2024-07-28 18:14:37,324:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:37,324:INFO:Creating metrics dataframe
2024-07-28 18:14:37,339:INFO:Initializing Dummy Regressor
2024-07-28 18:14:37,339:INFO:Total runtime is 0.5463757673899332 minutes
2024-07-28 18:14:37,343:INFO:SubProcess create_model() called ==================================
2024-07-28 18:14:37,343:INFO:Initializing create_model()
2024-07-28 18:14:37,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001ABAB87CA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:37,343:INFO:Checking exceptions
2024-07-28 18:14:37,343:INFO:Importing libraries
2024-07-28 18:14:37,344:INFO:Copying training dataset
2024-07-28 18:14:37,352:INFO:Defining folds
2024-07-28 18:14:37,352:INFO:Declaring metric variables
2024-07-28 18:14:37,356:INFO:Importing untrained model
2024-07-28 18:14:37,360:INFO:Dummy Regressor Imported successfully
2024-07-28 18:14:37,368:INFO:Starting cross validation
2024-07-28 18:14:37,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-28 18:14:37,599:INFO:Calculating mean and std
2024-07-28 18:14:37,601:INFO:Creating metrics dataframe
2024-07-28 18:14:37,606:INFO:Uploading results into container
2024-07-28 18:14:37,606:INFO:Uploading model into container now
2024-07-28 18:14:37,607:INFO:_master_model_container: 18
2024-07-28 18:14:37,607:INFO:_display_container: 2
2024-07-28 18:14:37,607:INFO:DummyRegressor()
2024-07-28 18:14:37,608:INFO:create_model() successfully completed......................................
2024-07-28 18:14:37,986:INFO:SubProcess create_model() end ==================================
2024-07-28 18:14:37,986:INFO:Creating metrics dataframe
2024-07-28 18:14:38,012:INFO:Initializing create_model()
2024-07-28 18:14:38,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:14:38,012:INFO:Checking exceptions
2024-07-28 18:14:38,015:INFO:Importing libraries
2024-07-28 18:14:38,015:INFO:Copying training dataset
2024-07-28 18:14:38,021:INFO:Defining folds
2024-07-28 18:14:38,021:INFO:Declaring metric variables
2024-07-28 18:14:38,021:INFO:Importing untrained model
2024-07-28 18:14:38,021:INFO:Declaring custom model
2024-07-28 18:14:38,022:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-28 18:14:38,023:INFO:Cross validation set to False
2024-07-28 18:14:38,023:INFO:Fitting Model
2024-07-28 18:14:38,097:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-28 18:14:38,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000512 seconds.
2024-07-28 18:14:38,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:14:38,100:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:14:38,100:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 11
2024-07-28 18:14:38,101:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:14:38,241:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-07-28 18:14:38,241:INFO:create_model() successfully completed......................................
2024-07-28 18:14:38,666:INFO:_master_model_container: 18
2024-07-28 18:14:38,667:INFO:_display_container: 2
2024-07-28 18:14:38,667:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-07-28 18:14:38,667:INFO:compare_models() successfully completed......................................
2024-07-28 18:17:44,939:INFO:Initializing finalize_model()
2024-07-28 18:17:44,939:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-28 18:17:44,939:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2024-07-28 18:17:44,943:INFO:Initializing create_model()
2024-07-28 18:17:44,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-28 18:17:44,943:INFO:Checking exceptions
2024-07-28 18:17:44,945:INFO:Importing libraries
2024-07-28 18:17:44,945:INFO:Copying training dataset
2024-07-28 18:17:44,945:INFO:Defining folds
2024-07-28 18:17:44,945:INFO:Declaring metric variables
2024-07-28 18:17:44,945:INFO:Importing untrained model
2024-07-28 18:17:44,947:INFO:Declaring custom model
2024-07-28 18:17:44,947:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-28 18:17:44,949:INFO:Cross validation set to False
2024-07-28 18:17:44,949:INFO:Fitting Model
2024-07-28 18:17:45,026:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-07-28 18:17:45,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
2024-07-28 18:17:45,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:17:45,028:INFO:[LightGBM] [Info] Total Bins 1420
2024-07-28 18:17:45,028:INFO:[LightGBM] [Info] Number of data points in the train set: 8861, number of used features: 11
2024-07-28 18:17:45,028:INFO:[LightGBM] [Info] Start training from score 6.629909
2024-07-28 18:17:45,192:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-07-28 18:17:45,193:INFO:create_model() successfully completed......................................
2024-07-28 18:17:45,624:INFO:_master_model_container: 18
2024-07-28 18:17:45,624:INFO:_display_container: 2
2024-07-28 18:17:45,634:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-07-28 18:17:45,634:INFO:finalize_model() successfully completed......................................
2024-07-28 18:17:46,040:INFO:Initializing predict_model()
2024-07-28 18:17:46,040:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001ABB5324160>)
2024-07-28 18:17:46,040:INFO:Checking exceptions
2024-07-28 18:17:46,040:INFO:Preloading libraries
2024-07-28 18:17:46,043:INFO:Set up data.
2024-07-28 18:17:46,060:INFO:Set up index.
2024-07-28 18:18:19,164:INFO:Initializing plot_model()
2024-07-28 18:18:19,165:INFO:plot_model(plot=pca, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:18:19,165:INFO:Checking exceptions
2024-07-28 18:19:14,602:INFO:Initializing plot_model()
2024-07-28 18:19:14,602:INFO:plot_model(plot=pca, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:19:14,602:INFO:Checking exceptions
2024-07-28 18:19:48,637:INFO:Initializing plot_model()
2024-07-28 18:19:48,637:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:19:48,637:INFO:Checking exceptions
2024-07-28 18:19:48,642:INFO:Preloading libraries
2024-07-28 18:19:48,649:INFO:Copying training dataset
2024-07-28 18:19:48,650:INFO:Plot type: residuals
2024-07-28 18:19:49,183:INFO:Fitting Model
2024-07-28 18:19:49,263:INFO:Scoring test/hold-out set
2024-07-28 18:19:49,969:INFO:Visual Rendered Successfully
2024-07-28 18:19:50,387:INFO:plot_model() successfully completed......................................
2024-07-28 18:21:07,754:INFO:Initializing plot_model()
2024-07-28 18:21:07,754:INFO:plot_model(plot=pca, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:21:07,754:INFO:Checking exceptions
2024-07-28 18:23:40,227:INFO:Initializing plot_model()
2024-07-28 18:23:40,228:INFO:plot_model(plot=manifold, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:23:40,228:INFO:Checking exceptions
2024-07-28 18:23:40,233:INFO:Preloading libraries
2024-07-28 18:23:40,242:INFO:Copying training dataset
2024-07-28 18:23:40,242:INFO:Plot type: manifold
2024-07-28 18:23:40,776:INFO:Fitting & Transforming Model
2024-07-28 18:24:02,453:INFO:Visual Rendered Successfully
2024-07-28 18:24:02,825:INFO:plot_model() successfully completed......................................
2024-07-28 18:24:11,714:INFO:Initializing plot_model()
2024-07-28 18:24:11,714:INFO:plot_model(plot=rfe, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:24:11,714:INFO:Checking exceptions
2024-07-28 18:24:11,719:INFO:Preloading libraries
2024-07-28 18:24:11,727:INFO:Copying training dataset
2024-07-28 18:24:11,727:INFO:Plot type: rfe
2024-07-28 18:24:12,066:INFO:Fitting Model
2024-07-28 18:24:12,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2024-07-28 18:24:12,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,087:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:12,088:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:12,088:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-07-28 18:24:12,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,194:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:12,194:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:12,195:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2024-07-28 18:24:12,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,295:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:12,295:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:12,295:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,403:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-07-28 18:24:12,403:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,403:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:24:12,403:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:12,404:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2024-07-28 18:24:12,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,537:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:24:12,537:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:12,537:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-07-28 18:24:12,661:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,661:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:12,661:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:12,661:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-07-28 18:24:12,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,769:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:12,769:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:12,769:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:12,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-07-28 18:24:12,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:12,969:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:12,969:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:12,969:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:13,072:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-07-28 18:24:13,072:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,072:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:13,073:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-07-28 18:24:13,073:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:13,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-07-28 18:24:13,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,167:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:13,167:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-07-28 18:24:13,168:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:13,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000071 seconds.
2024-07-28 18:24:13,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,264:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:13,264:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 1
2024-07-28 18:24:13,264:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:13,358:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2024-07-28 18:24:13,358:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,358:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:13,358:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:13,359:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:13,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-07-28 18:24:13,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,473:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:13,473:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:13,473:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:13,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
2024-07-28 18:24:13,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,592:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:13,592:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:13,593:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:13,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-07-28 18:24:13,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,729:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:13,729:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:13,729:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:13,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:24:13,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,867:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:24:13,867:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:13,868:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:13,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2024-07-28 18:24:13,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:13,988:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:13,988:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:13,989:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:14,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-07-28 18:24:14,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,101:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:14,101:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:14,101:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:14,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-07-28 18:24:14,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,217:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:14,218:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:14,218:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:14,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-07-28 18:24:14,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,314:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:14,314:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-07-28 18:24:14,314:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:14,422:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.
2024-07-28 18:24:14,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,423:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:14,423:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-07-28 18:24:14,423:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:14,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.
2024-07-28 18:24:14,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,509:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:14,509:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 1
2024-07-28 18:24:14,511:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:14,604:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:24:14,604:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,605:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:14,605:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:14,605:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:14,709:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-07-28 18:24:14,709:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,709:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:14,709:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:14,709:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:14,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2024-07-28 18:24:14,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,814:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:14,814:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:14,816:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:14,953:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-07-28 18:24:14,953:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:14,953:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:14,953:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:14,954:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-07-28 18:24:15,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,084:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:15,084:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:15,084:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-07-28 18:24:15,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,191:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:15,191:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:15,191:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-07-28 18:24:15,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,315:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:15,315:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:15,315:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-07-28 18:24:15,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,426:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:15,427:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:15,427:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-07-28 18:24:15,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,543:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:15,543:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:15,543:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.
2024-07-28 18:24:15,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,639:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:15,639:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:15,639:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000061 seconds.
2024-07-28 18:24:15,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,732:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:15,732:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:15,732:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:15,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-07-28 18:24:15,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,821:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:15,821:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:15,821:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:15,944:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2024-07-28 18:24:15,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:15,945:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:15,945:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:15,945:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-07-28 18:24:16,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,083:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:16,083:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:16,084:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-07-28 18:24:16,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,232:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:16,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:16,232:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-07-28 18:24:16,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,343:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:16,343:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:16,343:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,451:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-07-28 18:24:16,451:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,451:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:16,451:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:16,452:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,585:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-07-28 18:24:16,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,586:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:16,586:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:16,586:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.
2024-07-28 18:24:16,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,696:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:16,696:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:16,697:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,791:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-07-28 18:24:16,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,791:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:16,792:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:16,792:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-07-28 18:24:16,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,899:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:16,899:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:16,899:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:16,992:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-07-28 18:24:16,992:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:16,992:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:16,992:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:16,993:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:17,090:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000601 seconds.
2024-07-28 18:24:17,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,090:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:17,090:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:17,091:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-07-28 18:24:17,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,231:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:17,231:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:17,231:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:24:17,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,394:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:17,394:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:17,395:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-07-28 18:24:17,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,526:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:24:17,526:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:17,526:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-07-28 18:24:17,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,634:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:24:17,635:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:17,635:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-07-28 18:24:17,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,746:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:17,746:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:17,747:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,855:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-07-28 18:24:17,855:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,855:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:17,856:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:17,856:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:17,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-07-28 18:24:17,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:17,969:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:17,969:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:17,970:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:18,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
2024-07-28 18:24:18,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,071:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:18,071:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:18,071:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:18,192:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-07-28 18:24:18,192:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-28 18:24:18,192:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-28 18:24:18,192:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:18,192:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:18,192:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:18,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.
2024-07-28 18:24:18,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,338:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:18,339:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:18,339:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:18,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.
2024-07-28 18:24:18,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,443:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:18,444:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:18,444:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:18,590:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
2024-07-28 18:24:18,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,591:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:18,591:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:18,591:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:18,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-07-28 18:24:18,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,704:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:18,704:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:18,704:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:18,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2024-07-28 18:24:18,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,816:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:18,816:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:18,816:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:18,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-07-28 18:24:18,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:18,926:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:18,926:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:18,926:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-07-28 18:24:19,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,042:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:19,043:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:19,043:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.
2024-07-28 18:24:19,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,162:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:19,162:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:19,163:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-07-28 18:24:19,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,266:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:19,267:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:19,267:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-07-28 18:24:19,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,362:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:19,362:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:19,363:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-07-28 18:24:19,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,466:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:19,466:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:19,467:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,555:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-07-28 18:24:19,555:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,555:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:19,556:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:19,556:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:19,648:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-07-28 18:24:19,648:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,648:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:24:19,648:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:19,648:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:19,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2024-07-28 18:24:19,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,790:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:24:19,790:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:19,790:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:19,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000272 seconds.
2024-07-28 18:24:19,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:19,903:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:24:19,904:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:19,904:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,023:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-07-28 18:24:20,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,024:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:24:20,024:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:20,024:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2024-07-28 18:24:20,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,134:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:24:20,134:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:20,134:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-07-28 18:24:20,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,263:INFO:[LightGBM] [Info] Total Bins 1312
2024-07-28 18:24:20,263:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:20,264:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,374:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-07-28 18:24:20,374:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,374:INFO:[LightGBM] [Info] Total Bins 1270
2024-07-28 18:24:20,375:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:20,375:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-07-28 18:24:20,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,476:INFO:[LightGBM] [Info] Total Bins 1015
2024-07-28 18:24:20,476:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:20,477:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-07-28 18:24:20,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,581:INFO:[LightGBM] [Info] Total Bins 760
2024-07-28 18:24:20,582:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:20,582:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-07-28 18:24:20,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,678:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:20,678:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:20,678:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.
2024-07-28 18:24:20,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,770:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:20,770:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:20,770:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:20,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2024-07-28 18:24:20,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:20,878:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:20,879:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:20,879:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-07-28 18:24:21,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,028:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:21,028:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:21,028:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,143:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-07-28 18:24:21,143:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,143:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:21,143:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:21,144:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2024-07-28 18:24:21,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,252:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:21,253:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:21,253:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,363:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-07-28 18:24:21,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,363:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:21,364:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:21,364:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-07-28 18:24:21,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,490:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:21,490:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:21,492:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-07-28 18:24:21,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,628:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:21,628:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:21,629:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.
2024-07-28 18:24:21,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,743:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:21,743:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:21,744:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2024-07-28 18:24:21,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,844:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:21,844:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:21,844:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:21,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-07-28 18:24:21,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:21,945:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:21,945:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:21,945:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:22,057:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2024-07-28 18:24:22,057:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,057:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:22,057:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:22,058:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:22,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
2024-07-28 18:24:22,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,178:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:22,178:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:22,179:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-07-28 18:24:22,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,294:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:22,294:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:22,295:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2024-07-28 18:24:22,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,412:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:22,413:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:22,413:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:24:22,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,526:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:22,526:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:22,526:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-07-28 18:24:22,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,638:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:24:22,638:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:22,639:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,755:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-07-28 18:24:22,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,755:INFO:[LightGBM] [Info] Total Bins 1313
2024-07-28 18:24:22,756:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:22,756:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-07-28 18:24:22,869:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,869:INFO:[LightGBM] [Info] Total Bins 1271
2024-07-28 18:24:22,869:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:22,869:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:22,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-07-28 18:24:22,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:22,974:INFO:[LightGBM] [Info] Total Bins 1016
2024-07-28 18:24:22,974:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:22,975:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:23,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-07-28 18:24:23,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,085:INFO:[LightGBM] [Info] Total Bins 761
2024-07-28 18:24:23,085:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:23,085:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:23,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-07-28 18:24:23,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,183:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:23,183:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:23,183:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:23,305:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-07-28 18:24:23,305:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,306:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:23,306:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:23,306:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:23,434:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
2024-07-28 18:24:23,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,434:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:23,434:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:23,435:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:23,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-07-28 18:24:23,549:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,549:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:23,549:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:23,550:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:23,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2024-07-28 18:24:23,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,659:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:24:23,659:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:23,659:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:23,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2024-07-28 18:24:23,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,772:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:24:23,773:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:23,773:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:23,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-07-28 18:24:23,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:23,893:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:23,894:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:23,894:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-07-28 18:24:24,031:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,031:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:24,031:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:24,031:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-07-28 18:24:24,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,146:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:24,146:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:24,147:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-07-28 18:24:24,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,257:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:24,257:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:24,258:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,353:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-07-28 18:24:24,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,353:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:24,353:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:24,353:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,478:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-07-28 18:24:24,478:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,479:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:24,479:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:24,479:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,597:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.
2024-07-28 18:24:24,597:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,597:INFO:[LightGBM] [Info] Total Bins 255
2024-07-28 18:24:24,597:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-07-28 18:24:24,598:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:24,697:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000567 seconds.
2024-07-28 18:24:24,697:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,697:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:24,698:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:24,698:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:24,806:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-07-28 18:24:24,806:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,806:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:24,807:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:24,807:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:24,921:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-07-28 18:24:24,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:24,922:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:24,922:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:24,922:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,041:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2024-07-28 18:24:25,041:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,041:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:24:25,041:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:25,042:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-07-28 18:24:25,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,169:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:24:25,169:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:25,170:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-07-28 18:24:25,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,286:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:25,286:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:25,287:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-07-28 18:24:25,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,396:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:25,396:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:25,396:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-07-28 18:24:25,506:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,506:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:25,506:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:25,506:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-07-28 18:24:25,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,612:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:25,613:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-07-28 18:24:25,613:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.
2024-07-28 18:24:25,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,739:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:25,740:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-07-28 18:24:25,740:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:25,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2024-07-28 18:24:25,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,872:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:25,872:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:25,872:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:25,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2024-07-28 18:24:25,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:25,979:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:25,979:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:25,980:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.
2024-07-28 18:24:26,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,093:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:26,093:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:26,093:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-07-28 18:24:26,206:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,206:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:26,206:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:26,206:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-07-28 18:24:26,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,317:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:24:26,317:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:26,318:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,437:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-07-28 18:24:26,437:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,437:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:26,437:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:26,438:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-07-28 18:24:26,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,578:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:26,579:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:26,579:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-07-28 18:24:26,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,686:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:26,686:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:26,686:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-07-28 18:24:26,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,820:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:26,820:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-07-28 18:24:26,821:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:26,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-07-28 18:24:26,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:26,984:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:26,985:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-07-28 18:24:26,985:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:27,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2024-07-28 18:24:27,123:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:27,123:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:27,123:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:27,123:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:27,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
2024-07-28 18:24:27,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:27,283:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:27,284:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:27,284:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:27,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
2024-07-28 18:24:27,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:27,504:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:27,505:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:27,505:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:27,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2024-07-28 18:24:27,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:27,645:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:27,645:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:27,645:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:27,771:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-07-28 18:24:27,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:27,771:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:27,771:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:27,772:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:27,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-07-28 18:24:27,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:27,903:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:27,903:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:27,904:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:28,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2024-07-28 18:24:28,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,044:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:28,045:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:28,045:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:28,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-07-28 18:24:28,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,249:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:28,249:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:28,250:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:28,416:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
2024-07-28 18:24:28,416:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,416:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:28,416:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:28,417:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:28,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.
2024-07-28 18:24:28,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,552:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:28,552:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:28,552:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:28,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.
2024-07-28 18:24:28,699:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,699:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:28,699:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:28,699:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:28,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2024-07-28 18:24:28,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,810:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:28,810:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:28,810:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:28,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-07-28 18:24:28,935:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:28,935:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:28,935:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:28,935:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2024-07-28 18:24:29,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,051:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:29,052:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:29,052:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2024-07-28 18:24:29,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,164:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:29,164:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:29,165:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-07-28 18:24:29,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,301:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:29,301:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:29,301:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-07-28 18:24:29,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,438:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:29,438:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:29,440:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,553:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.
2024-07-28 18:24:29,553:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,553:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:29,554:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:29,554:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2024-07-28 18:24:29,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,678:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:29,678:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:29,680:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
2024-07-28 18:24:29,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,777:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:29,777:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:29,778:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:29,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
2024-07-28 18:24:29,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,887:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:29,887:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:29,888:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:29,993:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-07-28 18:24:29,993:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:29,993:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:29,993:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:29,994:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2024-07-28 18:24:30,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,106:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:30,106:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:30,106:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,222:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-07-28 18:24:30,222:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,222:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:24:30,222:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:30,223:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,336:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-07-28 18:24:30,336:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,336:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:24:30,337:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:30,337:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-07-28 18:24:30,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,474:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:30,474:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:30,475:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2024-07-28 18:24:30,618:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,619:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:30,619:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:30,619:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.
2024-07-28 18:24:30,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,746:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:30,746:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:30,747:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:30,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-07-28 18:24:30,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:30,887:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:30,887:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:30,887:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:31,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
2024-07-28 18:24:31,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,030:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:31,030:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:31,031:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:31,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.
2024-07-28 18:24:31,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,167:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:31,167:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:31,167:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:31,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:24:31,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,279:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:31,279:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:31,280:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:31,391:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2024-07-28 18:24:31,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,392:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:31,392:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:31,392:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:31,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2024-07-28 18:24:31,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,575:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:31,575:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:31,575:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:31,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-07-28 18:24:31,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,714:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:31,714:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:31,714:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:31,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-07-28 18:24:31,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:31,853:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:31,853:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:31,853:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:32,006:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.
2024-07-28 18:24:32,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,007:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:32,007:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:32,007:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:32,149:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
2024-07-28 18:24:32,149:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,149:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:32,150:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:32,150:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:32,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-07-28 18:24:32,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,292:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:32,292:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:32,292:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:32,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.
2024-07-28 18:24:32,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,390:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:32,390:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:32,391:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:32,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2024-07-28 18:24:32,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,515:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:24:32,515:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:32,516:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:32,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-07-28 18:24:32,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,624:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:24:32,624:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:32,624:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:32,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-07-28 18:24:32,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,740:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:24:32,740:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:32,741:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:32,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2024-07-28 18:24:32,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:32,892:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:24:32,893:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:32,893:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,020:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-07-28 18:24:33,020:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,021:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:24:33,021:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:33,021:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-07-28 18:24:33,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,126:INFO:[LightGBM] [Info] Total Bins 1312
2024-07-28 18:24:33,126:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:33,126:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,242:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-07-28 18:24:33,242:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,242:INFO:[LightGBM] [Info] Total Bins 1270
2024-07-28 18:24:33,242:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:33,242:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-07-28 18:24:33,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,347:INFO:[LightGBM] [Info] Total Bins 1015
2024-07-28 18:24:33,347:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:33,347:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-07-28 18:24:33,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,453:INFO:[LightGBM] [Info] Total Bins 760
2024-07-28 18:24:33,453:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:33,454:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.
2024-07-28 18:24:33,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,564:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:33,564:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:33,564:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:33,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2024-07-28 18:24:33,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,671:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:33,672:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:33,672:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:33,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2024-07-28 18:24:33,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,801:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:33,801:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:33,802:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:33,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2024-07-28 18:24:33,932:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:33,932:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:33,932:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:33,932:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-07-28 18:24:34,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,100:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:34,100:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:34,100:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-07-28 18:24:34,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,232:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:34,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:34,232:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-07-28 18:24:34,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,362:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:34,362:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:34,362:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-07-28 18:24:34,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,480:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:34,480:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:34,480:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-07-28 18:24:34,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,586:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:34,587:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:34,587:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.
2024-07-28 18:24:34,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,688:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:34,689:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:34,689:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.
2024-07-28 18:24:34,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,789:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:34,789:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:34,790:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:34,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-07-28 18:24:34,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:34,903:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:34,903:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:34,903:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2024-07-28 18:24:35,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,015:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:35,015:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:35,016:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-07-28 18:24:35,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,126:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:35,126:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:35,126:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,261:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-07-28 18:24:35,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,261:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:35,261:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:35,262:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,403:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-07-28 18:24:35,403:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,403:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:24:35,403:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:35,404:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,522:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2024-07-28 18:24:35,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,523:INFO:[LightGBM] [Info] Total Bins 1313
2024-07-28 18:24:35,523:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:35,523:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-07-28 18:24:35,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,643:INFO:[LightGBM] [Info] Total Bins 1271
2024-07-28 18:24:35,643:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:35,644:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-07-28 18:24:35,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,745:INFO:[LightGBM] [Info] Total Bins 1016
2024-07-28 18:24:35,745:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:35,745:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-07-28 18:24:35,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,857:INFO:[LightGBM] [Info] Total Bins 761
2024-07-28 18:24:35,857:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:35,857:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:35,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-07-28 18:24:35,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:35,952:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:35,953:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:35,953:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:36,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
2024-07-28 18:24:36,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:36,074:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:36,075:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:36,075:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:36,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-07-28 18:24:36,181:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:36,181:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:36,181:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:36,182:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:36,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
2024-07-28 18:24:36,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:36,340:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:24:36,340:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:36,341:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:36,518:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-07-28 18:24:36,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:36,518:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:24:36,518:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:36,518:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:37,185:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-07-28 18:24:37,185:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:37,186:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:37,186:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:37,186:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:37,330:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-07-28 18:24:37,330:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:37,330:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:37,331:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:37,331:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:37,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-07-28 18:24:37,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:37,488:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:37,489:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:37,489:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:37,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-07-28 18:24:37,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:37,712:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:37,712:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:37,712:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:37,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.
2024-07-28 18:24:37,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:37,828:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:37,828:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:37,829:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:37,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-07-28 18:24:37,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:37,951:INFO:[LightGBM] [Info] Total Bins 510
2024-07-28 18:24:37,951:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-07-28 18:24:37,951:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:38,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2024-07-28 18:24:38,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,100:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:38,101:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:38,101:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:38,258:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000594 seconds.
2024-07-28 18:24:38,258:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,258:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:38,258:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:38,260:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:38,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-07-28 18:24:38,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,369:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:38,369:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:38,369:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:38,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-07-28 18:24:38,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,494:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:24:38,494:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:38,495:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:38,631:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2024-07-28 18:24:38,631:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,631:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:24:38,632:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:38,632:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:38,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2024-07-28 18:24:38,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,836:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:38,837:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:38,837:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:38,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-07-28 18:24:38,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:38,988:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:38,988:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:38,989:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:39,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-07-28 18:24:39,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,109:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:39,110:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:39,110:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:39,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-07-28 18:24:39,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,211:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:39,211:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-07-28 18:24:39,212:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:39,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
2024-07-28 18:24:39,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,324:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:39,324:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:39,325:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:39,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2024-07-28 18:24:39,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,450:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:39,450:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:39,450:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:39,633:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-07-28 18:24:39,633:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,633:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:39,633:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:39,634:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:39,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-07-28 18:24:39,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,815:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:39,815:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:39,815:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:39,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-07-28 18:24:39,932:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:39,932:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:24:39,932:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:39,932:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:40,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-07-28 18:24:40,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:40,120:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:40,120:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:40,120:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:40,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2024-07-28 18:24:40,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:40,289:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:40,289:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:40,290:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:40,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-07-28 18:24:40,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:40,436:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:40,436:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:40,437:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:40,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-07-28 18:24:40,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:40,643:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:40,644:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-07-28 18:24:40,644:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:40,761:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.
2024-07-28 18:24:40,761:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:40,761:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:40,761:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:40,761:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:40,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-07-28 18:24:40,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:40,867:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:40,868:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:40,868:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:41,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-07-28 18:24:41,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:41,028:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:41,028:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:41,030:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:41,218:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-07-28 18:24:41,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:41,218:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:41,218:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:41,218:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:41,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-07-28 18:24:41,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-28 18:24:41,399:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-28 18:24:41,399:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:41,400:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:41,400:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:41,590:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-07-28 18:24:41,590:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:41,590:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:41,591:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:41,591:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:41,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-07-28 18:24:41,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:41,737:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:41,737:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:41,738:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:41,879:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-07-28 18:24:41,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:41,879:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:41,879:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:41,880:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:42,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-07-28 18:24:42,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,012:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:42,012:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:42,012:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:42,128:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:24:42,128:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,129:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:42,129:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:42,129:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:42,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
2024-07-28 18:24:42,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,249:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:42,249:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:42,250:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:42,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-07-28 18:24:42,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,370:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:42,370:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:42,370:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:42,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-07-28 18:24:42,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,501:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:42,501:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:42,502:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:42,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:24:42,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,645:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:42,645:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:42,646:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:42,774:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-07-28 18:24:42,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,774:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:42,774:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:42,775:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:42,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.
2024-07-28 18:24:42,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:42,893:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:42,893:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:42,894:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:43,023:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-07-28 18:24:43,023:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,023:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:43,023:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:43,024:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:43,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-07-28 18:24:43,130:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,130:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:43,130:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:43,130:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:43,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2024-07-28 18:24:43,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,271:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:43,271:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:43,272:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:43,407:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2024-07-28 18:24:43,407:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,407:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:43,407:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:43,407:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:43,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2024-07-28 18:24:43,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,568:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:43,568:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:43,569:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:43,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-07-28 18:24:43,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,728:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:24:43,728:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:43,728:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:43,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-07-28 18:24:43,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,861:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:24:43,861:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:43,861:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:43,977:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-07-28 18:24:43,977:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:43,977:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:43,978:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:43,978:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:44,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-07-28 18:24:44,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,098:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:44,099:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:44,099:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:44,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-07-28 18:24:44,210:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,210:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:44,210:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:44,210:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:44,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-07-28 18:24:44,320:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,320:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:44,320:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:44,320:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:44,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:24:44,433:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,433:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:44,433:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:44,433:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:44,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-07-28 18:24:44,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,538:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:44,538:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:44,538:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:44,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-07-28 18:24:44,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,656:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:44,656:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:44,656:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:44,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:24:44,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,768:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:44,768:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:44,768:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:44,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-07-28 18:24:44,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:44,961:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:44,961:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:44,962:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:45,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:24:45,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,130:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:45,130:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:45,130:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:45,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-07-28 18:24:45,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,271:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:45,272:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:45,272:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:45,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-07-28 18:24:45,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,396:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:45,396:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:45,396:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:45,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-07-28 18:24:45,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,505:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:45,505:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:45,505:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:45,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-07-28 18:24:45,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,620:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:24:45,620:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:45,620:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:45,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-07-28 18:24:45,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,738:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:24:45,739:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:45,739:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:45,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2024-07-28 18:24:45,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,852:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:24:45,852:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:45,852:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:45,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:24:45,960:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:45,960:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:24:45,960:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:45,960:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:46,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-07-28 18:24:46,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,084:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:24:46,084:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:46,084:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:46,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-07-28 18:24:46,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,240:INFO:[LightGBM] [Info] Total Bins 1312
2024-07-28 18:24:46,240:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:46,240:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:46,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-07-28 18:24:46,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,352:INFO:[LightGBM] [Info] Total Bins 1270
2024-07-28 18:24:46,352:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:46,352:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:46,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-07-28 18:24:46,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,463:INFO:[LightGBM] [Info] Total Bins 1015
2024-07-28 18:24:46,463:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:46,463:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:46,598:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-07-28 18:24:46,598:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,599:INFO:[LightGBM] [Info] Total Bins 760
2024-07-28 18:24:46,599:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:46,599:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:46,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-07-28 18:24:46,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,712:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:46,713:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:46,713:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:46,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-07-28 18:24:46,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,817:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:46,817:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:46,817:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:46,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2024-07-28 18:24:46,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:46,925:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:46,926:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:46,926:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,040:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2024-07-28 18:24:47,040:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,040:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:47,040:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:47,041:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-07-28 18:24:47,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,151:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:47,151:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:47,152:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,293:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000528 seconds.
2024-07-28 18:24:47,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,294:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:47,294:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:47,294:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,435:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-07-28 18:24:47,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,436:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:47,436:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:47,436:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2024-07-28 18:24:47,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,544:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:47,545:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:47,545:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-07-28 18:24:47,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,645:INFO:[LightGBM] [Info] Total Bins 763
2024-07-28 18:24:47,645:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:47,645:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:47,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-07-28 18:24:47,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,756:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:47,756:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:47,757:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:47,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-07-28 18:24:47,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:47,882:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:47,882:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:47,883:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.
2024-07-28 18:24:48,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,008:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:48,009:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:48,010:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,123:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
2024-07-28 18:24:48,123:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,123:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:48,123:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:48,123:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.
2024-07-28 18:24:48,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,232:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:24:48,233:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:48,233:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:24:48,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,365:INFO:[LightGBM] [Info] Total Bins 1313
2024-07-28 18:24:48,365:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:48,365:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-07-28 18:24:48,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,552:INFO:[LightGBM] [Info] Total Bins 1271
2024-07-28 18:24:48,552:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:48,552:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-07-28 18:24:48,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,708:INFO:[LightGBM] [Info] Total Bins 1016
2024-07-28 18:24:48,709:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:48,709:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,841:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-07-28 18:24:48,841:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,841:INFO:[LightGBM] [Info] Total Bins 761
2024-07-28 18:24:48,841:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:48,842:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:48,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-07-28 18:24:48,971:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:48,971:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:48,971:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:48,972:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2024-07-28 18:24:49,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,082:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:49,082:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:49,083:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,189:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2024-07-28 18:24:49,189:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,189:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:24:49,189:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:49,189:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2024-07-28 18:24:49,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,301:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:24:49,301:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:49,301:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-07-28 18:24:49,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,421:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:49,421:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:49,421:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,530:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-07-28 18:24:49,531:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,531:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:49,531:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:49,531:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-07-28 18:24:49,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,658:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:49,658:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:49,659:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,791:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-07-28 18:24:49,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,791:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:49,792:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:49,792:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:49,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-07-28 18:24:49,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:49,895:INFO:[LightGBM] [Info] Total Bins 762
2024-07-28 18:24:49,895:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-07-28 18:24:49,895:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:50,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000868 seconds.
2024-07-28 18:24:50,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,005:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:50,005:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:50,005:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2024-07-28 18:24:50,132:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,132:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:50,132:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:50,132:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-07-28 18:24:50,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,237:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:50,237:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:50,237:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
2024-07-28 18:24:50,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,354:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:24:50,354:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:50,355:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-07-28 18:24:50,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,475:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:24:50,475:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:50,476:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,593:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-07-28 18:24:50,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,593:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:50,593:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:50,593:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-07-28 18:24:50,709:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,709:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:50,709:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:50,709:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2024-07-28 18:24:50,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,817:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:50,817:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:50,818:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:50,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-07-28 18:24:50,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:50,964:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:50,964:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:50,964:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-07-28 18:24:51,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,084:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:51,084:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:51,084:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000524 seconds.
2024-07-28 18:24:51,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,200:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:51,200:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:51,200:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,307:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2024-07-28 18:24:51,307:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,308:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:51,308:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:24:51,308:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-07-28 18:24:51,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,421:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:24:51,422:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:24:51,422:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-07-28 18:24:51,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,560:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:51,561:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:24:51,561:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-07-28 18:24:51,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,688:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:51,688:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:24:51,690:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-07-28 18:24:51,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,787:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:51,787:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-07-28 18:24:51,787:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:24:51,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-07-28 18:24:51,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:51,901:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:51,901:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:51,902:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,020:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-07-28 18:24:52,020:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,020:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:52,021:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:52,021:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2024-07-28 18:24:52,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,167:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:52,167:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:52,167:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-07-28 18:24:52,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,297:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:52,297:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:52,297:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.
2024-07-28 18:24:52,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,410:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:52,410:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:52,410:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.
2024-07-28 18:24:52,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,524:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:52,524:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:52,525:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-07-28 18:24:52,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,639:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:52,639:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:52,639:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,752:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-07-28 18:24:52,752:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,752:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:52,752:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:52,752:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:24:52,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2024-07-28 18:24:52,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,872:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:52,872:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:52,873:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:52,983:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-07-28 18:24:52,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:52,984:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:52,984:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:52,984:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-07-28 18:24:53,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,095:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:53,095:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:53,096:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,214:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-07-28 18:24:53,214:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,214:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:53,215:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:53,215:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,358:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-07-28 18:24:53,358:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,358:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:53,359:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:53,359:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-07-28 18:24:53,495:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,495:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:53,495:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:53,495:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,606:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-07-28 18:24:53,606:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,606:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:53,607:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:53,607:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2024-07-28 18:24:53,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,718:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:53,718:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:53,718:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:24:53,850:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-07-28 18:24:53,850:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,850:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:53,851:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:53,851:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:53,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-07-28 18:24:53,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:53,955:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:53,955:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:53,955:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-07-28 18:24:54,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,064:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:54,065:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:54,065:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,200:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-07-28 18:24:54,200:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,200:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:24:54,200:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:54,200:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.
2024-07-28 18:24:54,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,313:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:24:54,313:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:54,313:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.
2024-07-28 18:24:54,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,443:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:54,444:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:54,444:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-07-28 18:24:54,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,589:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:54,589:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:54,590:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-07-28 18:24:54,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,703:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:54,704:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:54,704:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:24:54,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-07-28 18:24:54,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,826:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:54,826:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:54,826:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:54,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:24:54,931:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:54,931:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:54,931:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:54,932:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.
2024-07-28 18:24:55,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,044:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:55,044:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:55,044:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-07-28 18:24:55,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,167:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:24:55,167:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:55,167:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-07-28 18:24:55,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,287:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:55,287:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:55,287:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2024-07-28 18:24:55,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,406:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:55,407:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:55,407:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,531:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-07-28 18:24:55,531:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,531:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:55,532:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:55,532:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-07-28 18:24:55,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,651:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:55,651:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:55,652:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:24:55,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2024-07-28 18:24:55,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,797:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:24:55,797:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:55,797:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:55,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-07-28 18:24:55,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:55,903:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:24:55,903:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:55,903:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-07-28 18:24:56,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,017:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:24:56,017:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:56,017:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-07-28 18:24:56,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,131:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:24:56,131:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:56,131:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,241:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-07-28 18:24:56,242:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,242:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:24:56,242:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:56,242:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-07-28 18:24:56,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,366:INFO:[LightGBM] [Info] Total Bins 1312
2024-07-28 18:24:56,366:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:56,366:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,487:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-07-28 18:24:56,487:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,487:INFO:[LightGBM] [Info] Total Bins 1270
2024-07-28 18:24:56,487:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:56,489:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,621:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2024-07-28 18:24:56,621:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,621:INFO:[LightGBM] [Info] Total Bins 1015
2024-07-28 18:24:56,621:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:56,621:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:24:56,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
2024-07-28 18:24:56,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,738:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:56,738:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:56,739:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:56,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-07-28 18:24:56,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:56,867:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:56,869:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:56,869:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2024-07-28 18:24:57,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,016:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:57,016:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:57,016:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-07-28 18:24:57,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,131:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:24:57,131:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:57,131:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-07-28 18:24:57,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,250:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:24:57,250:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:57,250:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-07-28 18:24:57,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,370:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:24:57,370:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:57,371:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,492:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-07-28 18:24:57,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,493:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:24:57,493:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:57,493:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-07-28 18:24:57,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,600:INFO:[LightGBM] [Info] Total Bins 1018
2024-07-28 18:24:57,600:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:57,600:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:24:57,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2024-07-28 18:24:57,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,716:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:24:57,717:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:57,717:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:57,835:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-07-28 18:24:57,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,836:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:24:57,836:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:57,836:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:57,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
2024-07-28 18:24:57,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:57,956:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:24:57,957:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:57,957:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:58,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.
2024-07-28 18:24:58,123:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,123:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:24:58,123:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:58,123:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:58,256:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-07-28 18:24:58,256:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,257:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:24:58,257:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:58,257:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:58,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-07-28 18:24:58,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,385:INFO:[LightGBM] [Info] Total Bins 1313
2024-07-28 18:24:58,385:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:58,385:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:58,503:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-07-28 18:24:58,503:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,503:INFO:[LightGBM] [Info] Total Bins 1271
2024-07-28 18:24:58,503:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:58,503:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:58,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-07-28 18:24:58,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,612:INFO:[LightGBM] [Info] Total Bins 1016
2024-07-28 18:24:58,613:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:58,613:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:24:58,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
2024-07-28 18:24:58,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,729:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:24:58,729:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:24:58,729:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:58,838:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-07-28 18:24:58,838:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,838:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:24:58,839:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:24:58,839:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:58,971:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:24:58,971:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:58,971:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:24:58,971:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:24:58,972:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:59,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-07-28 18:24:59,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,106:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:24:59,107:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:24:59,107:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:59,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-07-28 18:24:59,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,233:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:24:59,234:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:24:59,234:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:59,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-07-28 18:24:59,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,392:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:24:59,393:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:24:59,393:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:59,516:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-07-28 18:24:59,516:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,516:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:24:59,517:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:24:59,517:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:59,624:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-07-28 18:24:59,624:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,624:INFO:[LightGBM] [Info] Total Bins 1017
2024-07-28 18:24:59,625:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-07-28 18:24:59,625:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:24:59,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2024-07-28 18:24:59,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,747:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:24:59,747:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:24:59,747:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:59,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-07-28 18:24:59,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,864:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:24:59,864:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:24:59,864:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:24:59,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:24:59,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:24:59,974:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:24:59,974:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:24:59,974:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:00,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.
2024-07-28 18:25:00,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,099:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:25:00,099:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:00,099:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:00,210:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-07-28 18:25:00,210:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,210:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:25:00,210:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:25:00,210:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:00,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-07-28 18:25:00,328:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,328:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:00,328:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:25:00,328:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:00,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-07-28 18:25:00,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,465:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:25:00,466:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:25:00,466:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:00,614:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2024-07-28 18:25:00,614:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,614:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:00,615:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:00,615:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:00,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2024-07-28 18:25:00,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,728:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:00,729:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:00,729:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:00,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-07-28 18:25:00,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,866:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:00,866:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:00,866:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:00,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-07-28 18:25:00,985:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:00,985:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:00,985:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:00,985:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:01,099:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2024-07-28 18:25:01,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,099:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:25:01,100:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:25:01,100:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:01,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-07-28 18:25:01,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,226:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:01,226:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:25:01,227:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:01,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-07-28 18:25:01,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,340:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:25:01,340:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-07-28 18:25:01,341:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:01,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-07-28 18:25:01,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,466:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:01,466:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:01,467:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:01,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-07-28 18:25:01,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,590:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:01,590:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:01,590:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:01,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-07-28 18:25:01,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,734:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:01,734:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:01,734:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:01,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-07-28 18:25:01,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,868:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:01,868:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:01,868:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:01,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-07-28 18:25:01,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:01,987:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:01,987:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:01,987:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:02,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
2024-07-28 18:25:02,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,115:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:02,115:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:02,116:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:02,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-07-28 18:25:02,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,230:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:25:02,230:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:02,231:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:02,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-07-28 18:25:02,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,350:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:02,350:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:02,350:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:02,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-07-28 18:25:02,470:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,470:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:02,470:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:02,470:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:02,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.
2024-07-28 18:25:02,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,596:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:02,596:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:02,596:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:02,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2024-07-28 18:25:02,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,703:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:02,703:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:02,703:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:02,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:25:02,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,826:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:25:02,827:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:02,827:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:02,977:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-07-28 18:25:02,977:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:02,977:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:02,977:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:02,977:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:03,091:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2024-07-28 18:25:03,091:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,091:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:25:03,091:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:03,091:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:03,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2024-07-28 18:25:03,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,205:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:03,205:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:03,205:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:03,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:25:03,309:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,309:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:03,309:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:03,310:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:03,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:25:03,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,420:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:03,421:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:03,421:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:03,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:25:03,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,533:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:25:03,533:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:03,534:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:03,646:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.
2024-07-28 18:25:03,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-28 18:25:03,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-28 18:25:03,646:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:25:03,647:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:03,647:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:03,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-07-28 18:25:03,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,818:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:03,818:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:03,818:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:03,940:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-07-28 18:25:03,940:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:03,940:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:25:03,940:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:03,941:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:04,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.
2024-07-28 18:25:04,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,094:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:04,094:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:04,095:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-07-28 18:25:04,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,243:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:04,243:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:04,244:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-07-28 18:25:04,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,351:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:04,351:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:04,352:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2024-07-28 18:25:04,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,466:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:04,467:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:04,467:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-07-28 18:25:04,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,579:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:04,579:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:04,579:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,697:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-07-28 18:25:04,697:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,697:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:04,697:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:04,698:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-07-28 18:25:04,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,808:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:25:04,809:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:04,809:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:04,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-07-28 18:25:04,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:04,929:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:04,930:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:04,930:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,035:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:25:05,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,036:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:25:05,036:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:05,036:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-07-28 18:25:05,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,142:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:25:05,142:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:05,142:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-07-28 18:25:05,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,271:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:25:05,271:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:05,272:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,411:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.
2024-07-28 18:25:05,411:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,411:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:25:05,412:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:05,412:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-07-28 18:25:05,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,532:INFO:[LightGBM] [Info] Total Bins 1312
2024-07-28 18:25:05,532:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:05,533:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-07-28 18:25:05,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,638:INFO:[LightGBM] [Info] Total Bins 1270
2024-07-28 18:25:05,639:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:05,639:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:05,758:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-07-28 18:25:05,758:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,759:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:05,759:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:05,759:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:05,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:25:05,870:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,870:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:05,871:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:05,871:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:05,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.
2024-07-28 18:25:05,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:05,979:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:05,980:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:05,980:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:06,097:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-07-28 18:25:06,097:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:06,097:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:06,097:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:06,098:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:06,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-07-28 18:25:06,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:06,206:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:06,206:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:06,206:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:06,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-07-28 18:25:06,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:06,325:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:06,325:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:06,326:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:06,471:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-07-28 18:25:06,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:06,472:INFO:[LightGBM] [Info] Total Bins 1273
2024-07-28 18:25:06,472:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:06,473:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:06,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-07-28 18:25:06,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:06,628:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:06,628:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:06,628:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:06,783:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007636 seconds.
2024-07-28 18:25:06,783:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-28 18:25:06,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-28 18:25:06,784:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:06,784:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:06,784:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:06,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-07-28 18:25:06,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:06,948:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:06,949:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:06,949:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:07,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-07-28 18:25:07,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,067:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:07,067:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:07,067:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:07,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-07-28 18:25:07,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,182:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:25:07,183:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:07,183:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:07,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-07-28 18:25:07,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,304:INFO:[LightGBM] [Info] Total Bins 1313
2024-07-28 18:25:07,305:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:07,305:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:07,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-07-28 18:25:07,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,430:INFO:[LightGBM] [Info] Total Bins 1271
2024-07-28 18:25:07,430:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:07,431:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:07,554:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
2024-07-28 18:25:07,554:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,554:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:07,555:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:07,555:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:07,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.
2024-07-28 18:25:07,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,692:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:07,693:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:07,693:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:07,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:25:07,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,828:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:25:07,828:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:07,829:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:07,949:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-07-28 18:25:07,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:07,950:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:25:07,950:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:07,950:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:08,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-07-28 18:25:08,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,066:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:25:08,067:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:08,067:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:08,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-07-28 18:25:08,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,213:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:08,213:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:08,213:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:08,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.
2024-07-28 18:25:08,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,330:INFO:[LightGBM] [Info] Total Bins 1272
2024-07-28 18:25:08,330:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-07-28 18:25:08,330:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:08,462:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2024-07-28 18:25:08,462:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,462:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:08,462:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:08,463:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:08,593:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-07-28 18:25:08,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,593:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:08,593:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:08,594:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:08,720:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-07-28 18:25:08,720:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,721:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:08,721:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:08,721:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:08,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-07-28 18:25:08,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:08,937:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:25:08,937:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:08,937:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:09,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-07-28 18:25:09,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,083:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:25:09,083:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:25:09,084:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:09,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-07-28 18:25:09,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,231:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:09,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:25:09,232:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:09,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2024-07-28 18:25:09,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,357:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:09,357:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:09,357:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:09,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.
2024-07-28 18:25:09,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,474:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:09,474:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:09,475:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:09,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2024-07-28 18:25:09,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,597:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:09,597:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:09,598:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:09,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-07-28 18:25:09,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,717:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:09,717:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:09,717:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:09,869:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-07-28 18:25:09,869:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,869:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:25:09,869:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:25:09,869:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:09,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.
2024-07-28 18:25:09,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:09,987:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:09,987:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-07-28 18:25:09,987:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:10,168:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
2024-07-28 18:25:10,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,169:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:10,169:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:10,169:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:10,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-07-28 18:25:10,300:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,300:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:10,300:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:10,301:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:10,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-07-28 18:25:10,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,425:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:10,425:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:10,426:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:10,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2024-07-28 18:25:10,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,559:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:10,559:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:10,559:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:10,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2024-07-28 18:25:10,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,675:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:10,676:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:10,676:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:10,800:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-07-28 18:25:10,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,801:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:10,801:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:10,801:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:10,927:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-07-28 18:25:10,927:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:10,927:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:10,927:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:10,927:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:11,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2024-07-28 18:25:11,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,049:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:11,050:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:11,050:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:11,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2024-07-28 18:25:11,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,165:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:11,166:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:11,166:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:11,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-07-28 18:25:11,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,296:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:11,296:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:11,296:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:11,451:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-07-28 18:25:11,451:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,451:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:25:11,451:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:11,452:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:11,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.
2024-07-28 18:25:11,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,589:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:11,590:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:11,590:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:11,707:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-07-28 18:25:11,707:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,707:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:11,708:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:11,708:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:11,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-07-28 18:25:11,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,829:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:11,830:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:11,830:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:11,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-07-28 18:25:11,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:11,943:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:11,943:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:11,944:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:12,061:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2024-07-28 18:25:12,061:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,061:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:25:12,061:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:12,062:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:12,174:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-07-28 18:25:12,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,174:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:25:12,175:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:12,175:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:12,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-07-28 18:25:12,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,282:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:12,282:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:12,283:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:12,404:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000554 seconds.
2024-07-28 18:25:12,404:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,404:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:12,404:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:12,405:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:12,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
2024-07-28 18:25:12,548:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,548:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:12,548:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:12,548:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:12,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2024-07-28 18:25:12,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,679:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:12,680:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:12,680:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:12,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-07-28 18:25:12,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,874:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:12,874:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:12,874:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:12,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.
2024-07-28 18:25:12,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:12,988:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:12,989:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:12,989:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:13,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-07-28 18:25:13,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,109:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:13,109:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:13,109:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:13,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.
2024-07-28 18:25:13,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,231:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:13,231:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:13,232:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:13,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-07-28 18:25:13,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,351:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:25:13,351:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:13,352:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:13,462:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-07-28 18:25:13,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,463:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:25:13,463:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:13,463:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:13,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-07-28 18:25:13,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,591:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:25:13,592:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:13,592:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:13,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-07-28 18:25:13,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,744:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:25:13,744:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:13,744:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:13,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-07-28 18:25:13,870:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:13,870:INFO:[LightGBM] [Info] Total Bins 1312
2024-07-28 18:25:13,870:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:13,871:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:14,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
2024-07-28 18:25:14,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,004:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:14,005:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:14,005:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:14,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2024-07-28 18:25:14,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,114:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:14,115:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:14,115:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:14,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
2024-07-28 18:25:14,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,266:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:14,268:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:14,268:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:14,399:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-07-28 18:25:14,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,399:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:14,399:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:14,400:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:14,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:25:14,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,515:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:14,515:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:14,516:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:14,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2024-07-28 18:25:14,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,634:INFO:[LightGBM] [Info] Total Bins 1315
2024-07-28 18:25:14,634:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:14,635:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:14,762:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.
2024-07-28 18:25:14,762:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,762:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:14,763:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:14,763:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:14,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-07-28 18:25:14,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:14,920:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:14,920:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:14,920:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:15,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-07-28 18:25:15,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,054:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:15,054:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:15,054:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:15,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2024-07-28 18:25:15,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,185:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:15,185:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:15,185:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:15,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-07-28 18:25:15,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,308:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:25:15,308:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:15,308:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:15,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-07-28 18:25:15,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,422:INFO:[LightGBM] [Info] Total Bins 1313
2024-07-28 18:25:15,422:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:15,422:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:15,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2024-07-28 18:25:15,549:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,549:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:15,550:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:15,550:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:15,654:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-07-28 18:25:15,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,655:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:15,655:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:15,655:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:15,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2024-07-28 18:25:15,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,776:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:25:15,776:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:15,776:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:15,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-07-28 18:25:15,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:15,892:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:25:15,892:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:15,893:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:16,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-07-28 18:25:16,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,012:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:25:16,013:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:16,013:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:16,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.
2024-07-28 18:25:16,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,166:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:16,166:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-07-28 18:25:16,166:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:16,299:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-07-28 18:25:16,299:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,299:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:16,299:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:16,300:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:16,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2024-07-28 18:25:16,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,409:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:16,410:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:16,410:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:16,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2024-07-28 18:25:16,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,543:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:16,543:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:16,543:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:16,666:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-07-28 18:25:16,668:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,668:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:25:16,668:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:16,668:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:16,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-07-28 18:25:16,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,783:INFO:[LightGBM] [Info] Total Bins 1331
2024-07-28 18:25:16,783:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:25:16,783:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:16,913:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-07-28 18:25:16,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:16,914:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:16,914:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:16,914:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:17,040:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
2024-07-28 18:25:17,040:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,040:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:17,041:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:17,041:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:17,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:25:17,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,158:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:17,158:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:17,158:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:17,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-07-28 18:25:17,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,329:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:17,329:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:17,330:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:17,458:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-07-28 18:25:17,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,458:INFO:[LightGBM] [Info] Total Bins 1341
2024-07-28 18:25:17,458:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-07-28 18:25:17,459:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:17,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-07-28 18:25:17,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,584:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:17,584:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:17,584:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:17,697:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-07-28 18:25:17,697:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,697:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:17,697:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:17,698:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:17,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.
2024-07-28 18:25:17,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,804:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:17,804:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:17,805:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:17,921:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-07-28 18:25:17,921:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:17,921:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:17,921:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:17,921:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:18,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-07-28 18:25:18,039:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,039:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:18,039:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:18,040:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:18,153:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:25:18,153:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,153:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:18,153:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:18,154:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:18,264:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-07-28 18:25:18,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,265:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:18,265:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:18,265:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:18,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-07-28 18:25:18,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,397:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:18,397:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:18,397:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:18,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-07-28 18:25:18,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,573:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:18,574:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:18,574:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:18,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-07-28 18:25:18,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,695:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:25:18,695:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:18,696:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:18,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:25:18,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,819:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:18,819:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:18,819:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:18,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.
2024-07-28 18:25:18,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:18,943:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:18,943:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:18,943:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:19,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-07-28 18:25:19,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,060:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:19,061:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:19,061:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:19,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-07-28 18:25:19,176:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,176:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:25:19,176:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:19,176:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:19,306:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2024-07-28 18:25:19,306:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,306:INFO:[LightGBM] [Info] Total Bins 1342
2024-07-28 18:25:19,306:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:19,308:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:19,439:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-07-28 18:25:19,439:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,439:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:19,440:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:19,440:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:19,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-07-28 18:25:19,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,560:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:19,560:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:19,560:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:19,689:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-07-28 18:25:19,689:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,689:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:19,689:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:19,690:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:19,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:25:19,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,840:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:19,840:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:19,841:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:19,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:25:19,959:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:19,959:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:19,959:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:19,959:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:20,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-07-28 18:25:20,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,083:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:20,083:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:20,083:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:20,190:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.
2024-07-28 18:25:20,190:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,191:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:25:20,191:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:20,191:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:20,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
2024-07-28 18:25:20,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,303:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:25:20,304:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:20,304:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:20,434:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-07-28 18:25:20,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,434:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:25:20,434:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:20,435:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:20,552:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-07-28 18:25:20,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,552:INFO:[LightGBM] [Info] Total Bins 1344
2024-07-28 18:25:20,553:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:20,553:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:20,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-07-28 18:25:20,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,747:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:20,747:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:20,747:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:20,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2024-07-28 18:25:20,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:20,872:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:20,872:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:20,872:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:21,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-07-28 18:25:21,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,013:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:21,013:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:21,014:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:21,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-07-28 18:25:21,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,131:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:21,131:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:21,132:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:21,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-07-28 18:25:21,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,243:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:21,243:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:21,243:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:21,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-07-28 18:25:21,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,362:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:21,362:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:21,362:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:21,485:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-07-28 18:25:21,485:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,485:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:21,485:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:21,486:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:21,615:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-07-28 18:25:21,616:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,616:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:21,616:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:21,616:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:21,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-07-28 18:25:21,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,738:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:21,738:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:21,739:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:21,848:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-07-28 18:25:21,848:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,848:INFO:[LightGBM] [Info] Total Bins 1345
2024-07-28 18:25:21,848:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:21,848:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:21,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.
2024-07-28 18:25:21,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:21,974:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:21,975:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:21,975:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:22,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.
2024-07-28 18:25:22,119:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,119:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:22,120:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:22,120:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:22,250:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-07-28 18:25:22,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,250:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:25:22,250:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:22,251:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:22,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-07-28 18:25:22,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,359:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:25:22,359:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:22,360:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:22,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-07-28 18:25:22,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,473:INFO:[LightGBM] [Info] Total Bins 1346
2024-07-28 18:25:22,473:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-07-28 18:25:22,474:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:22,593:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2024-07-28 18:25:22,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,594:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:22,594:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:22,594:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:22,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2024-07-28 18:25:22,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,703:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:22,703:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:22,704:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:22,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-07-28 18:25:22,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,815:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:22,815:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:22,815:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:22,921:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-07-28 18:25:22,921:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:22,921:INFO:[LightGBM] [Info] Total Bins 1358
2024-07-28 18:25:22,922:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:22,922:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:23,048:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2024-07-28 18:25:23,048:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,048:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:23,049:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:23,049:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:23,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
2024-07-28 18:25:23,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,160:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:23,160:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:23,161:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:23,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2024-07-28 18:25:23,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,303:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:23,303:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:23,304:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:23,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-07-28 18:25:23,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,446:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:23,446:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-07-28 18:25:23,446:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:23,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-07-28 18:25:23,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,576:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:23,576:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:23,576:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:23,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-07-28 18:25:23,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,683:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:23,684:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:23,684:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:23,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-07-28 18:25:23,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,795:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:23,795:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:23,795:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:23,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-07-28 18:25:23,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:23,902:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:23,902:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:23,902:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:24,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-07-28 18:25:24,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,024:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:24,024:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:24,024:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:24,136:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-07-28 18:25:24,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,138:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:24,138:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:24,138:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:24,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2024-07-28 18:25:24,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,255:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:24,256:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:24,256:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:24,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-07-28 18:25:24,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,385:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:24,385:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:24,385:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:24,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-07-28 18:25:24,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,543:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:24,543:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:24,544:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:24,665:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-07-28 18:25:24,665:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,665:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:24,665:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:24,666:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:24,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-07-28 18:25:24,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,778:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:24,778:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:24,779:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:24,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-07-28 18:25:24,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:24,904:INFO:[LightGBM] [Info] Total Bins 1375
2024-07-28 18:25:24,904:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:24,904:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:25,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2024-07-28 18:25:25,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,029:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:25,029:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:25,029:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:25,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-07-28 18:25:25,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,138:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:25,139:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:25,139:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:25,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-07-28 18:25:25,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,253:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:25,254:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:25,254:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:25,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-07-28 18:25:25,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,366:INFO:[LightGBM] [Info] Total Bins 1374
2024-07-28 18:25:25,366:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:25,367:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:25,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-07-28 18:25:25,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,479:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:25,480:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:25,480:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:25,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
2024-07-28 18:25:25,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,592:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:25:25,592:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:25,593:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:25,730:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2024-07-28 18:25:25,730:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,730:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:25:25,731:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:25,731:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:25,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-07-28 18:25:25,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,860:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-28 18:25:25,860:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:25,860:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:25,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-07-28 18:25:25,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:25,975:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:25,975:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:25,976:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:26,086:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-07-28 18:25:26,086:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,086:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:26,087:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:26,087:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:26,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-07-28 18:25:26,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,195:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:26,195:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:26,195:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:26,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-07-28 18:25:26,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,316:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:26,316:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:26,316:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:26,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:25:26,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,443:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:26,443:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:26,443:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:26,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-07-28 18:25:26,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,564:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:26,564:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:26,564:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:26,680:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-07-28 18:25:26,681:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,681:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:26,681:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:26,681:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:26,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:25:26,806:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,806:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-28 18:25:26,806:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:26,806:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:26,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.
2024-07-28 18:25:26,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:26,973:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:26,973:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:26,974:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:27,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-07-28 18:25:27,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,104:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:27,104:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:27,104:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:27,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-07-28 18:25:27,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,229:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:25:27,229:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:27,230:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:27,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-07-28 18:25:27,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,340:INFO:[LightGBM] [Info] Total Bins 1373
2024-07-28 18:25:27,340:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-07-28 18:25:27,340:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:27,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-07-28 18:25:27,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,465:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:27,465:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:27,465:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:27,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-07-28 18:25:27,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,575:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:27,575:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:27,575:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:27,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-07-28 18:25:27,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,688:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:27,689:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:27,689:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:27,806:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2024-07-28 18:25:27,806:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,806:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:27,806:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:27,807:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:27,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-07-28 18:25:27,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:27,916:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:27,916:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:27,917:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:28,035:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-07-28 18:25:28,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,036:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:28,036:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-07-28 18:25:28,036:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:28,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-07-28 18:25:28,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,194:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:28,194:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:28,195:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:28,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-07-28 18:25:28,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,310:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:28,310:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:28,310:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:28,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-07-28 18:25:28,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,414:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:28,415:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:28,415:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:28,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2024-07-28 18:25:28,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,547:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:28,547:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:28,547:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:28,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-07-28 18:25:28,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,716:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:28,716:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:28,717:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:28,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-07-28 18:25:28,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,829:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:28,829:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:28,830:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:28,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-07-28 18:25:28,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:28,951:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:28,951:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:28,951:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:29,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-07-28 18:25:29,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,059:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:29,060:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:29,060:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:29,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.
2024-07-28 18:25:29,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,182:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:29,182:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:29,182:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:29,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2024-07-28 18:25:29,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,381:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:29,381:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:29,382:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:29,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-07-28 18:25:29,522:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,522:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:29,522:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:29,523:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:29,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2024-07-28 18:25:29,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,652:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:29,652:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:29,652:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:29,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2024-07-28 18:25:29,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,785:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:29,785:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:29,786:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:29,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2024-07-28 18:25:29,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:29,898:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:25:29,898:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:29,898:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:30,010:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-07-28 18:25:30,010:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,010:INFO:[LightGBM] [Info] Total Bins 1387
2024-07-28 18:25:30,011:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:30,011:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:30,128:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2024-07-28 18:25:30,128:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,128:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:30,128:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:30,128:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:30,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-07-28 18:25:30,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,231:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:30,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:30,232:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:30,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-07-28 18:25:30,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,346:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:30,346:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:30,346:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:30,487:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
2024-07-28 18:25:30,487:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,487:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:30,487:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:30,488:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:30,653:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2024-07-28 18:25:30,654:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,654:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:30,654:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:30,654:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:30,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2024-07-28 18:25:30,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,789:INFO:[LightGBM] [Info] Total Bins 1388
2024-07-28 18:25:30,790:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:30,790:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:30,944:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2024-07-28 18:25:30,944:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:30,944:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:30,944:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:30,945:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:31,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-07-28 18:25:31,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,083:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:31,083:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:31,084:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:31,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-07-28 18:25:31,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,199:INFO:[LightGBM] [Info] Total Bins 1389
2024-07-28 18:25:31,199:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-07-28 18:25:31,200:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:31,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2024-07-28 18:25:31,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,329:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:31,329:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:31,330:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:31,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2024-07-28 18:25:31,455:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,455:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:31,456:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:31,456:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:31,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.
2024-07-28 18:25:31,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,608:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:31,609:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:31,609:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:31,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000533 seconds.
2024-07-28 18:25:31,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,766:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:31,767:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-07-28 18:25:31,767:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:31,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-07-28 18:25:31,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:31,902:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:31,903:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:31,903:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:32,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2024-07-28 18:25:32,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,012:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:32,012:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:32,013:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:32,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-07-28 18:25:32,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,140:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:32,140:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:32,140:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:32,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.
2024-07-28 18:25:32,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,256:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:32,256:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:32,256:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:32,371:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-28 18:25:32,371:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,371:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:32,371:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:32,372:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:32,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-07-28 18:25:32,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,476:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:32,476:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:32,476:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:32,597:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-07-28 18:25:32,597:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,597:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:32,598:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:32,598:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:32,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2024-07-28 18:25:32,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,732:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:32,733:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:32,733:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:32,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.
2024-07-28 18:25:32,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:32,975:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:32,975:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:32,975:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:33,190:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
2024-07-28 18:25:33,190:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:33,190:INFO:[LightGBM] [Info] Total Bins 1406
2024-07-28 18:25:33,191:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:33,191:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:33,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-07-28 18:25:33,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:33,425:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:33,425:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:33,426:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:33,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-07-28 18:25:33,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:33,532:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:33,532:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:33,533:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:33,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-07-28 18:25:33,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:33,655:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:33,656:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:33,656:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:33,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-07-28 18:25:33,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:33,767:INFO:[LightGBM] [Info] Total Bins 1407
2024-07-28 18:25:33,767:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:33,767:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:33,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2024-07-28 18:25:33,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:33,930:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:33,930:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:33,930:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:34,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000809 seconds.
2024-07-28 18:25:34,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:34,059:INFO:[LightGBM] [Info] Total Bins 1408
2024-07-28 18:25:34,059:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-07-28 18:25:34,059:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:34,207:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
2024-07-28 18:25:34,207:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:34,208:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:34,208:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:34,208:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-07-28 18:25:34,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2024-07-28 18:25:34,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:34,350:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:34,351:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-07-28 18:25:34,351:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-07-28 18:25:34,470:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-07-28 18:25:34,470:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:34,470:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:34,470:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:34,471:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-07-28 18:25:34,640:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-07-28 18:25:34,640:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:34,640:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:34,640:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:34,642:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-07-28 18:25:34,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.
2024-07-28 18:25:34,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:34,836:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:34,836:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:34,838:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-07-28 18:25:35,035:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
2024-07-28 18:25:35,035:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:35,035:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:35,037:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:35,037:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-07-28 18:25:35,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.
2024-07-28 18:25:35,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:35,240:INFO:[LightGBM] [Info] Total Bins 1414
2024-07-28 18:25:35,240:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:35,241:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-07-28 18:25:35,445:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-07-28 18:25:35,445:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:35,446:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:35,446:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:35,446:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-07-28 18:25:35,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.
2024-07-28 18:25:35,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:35,687:INFO:[LightGBM] [Info] Total Bins 1415
2024-07-28 18:25:35,688:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:35,688:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-07-28 18:25:35,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-07-28 18:25:35,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:35,867:INFO:[LightGBM] [Info] Total Bins 1416
2024-07-28 18:25:35,867:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-07-28 18:25:35,868:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-07-28 18:25:36,014:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-07-28 18:25:36,014:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:36,014:INFO:[LightGBM] [Info] Total Bins 1417
2024-07-28 18:25:36,014:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 11
2024-07-28 18:25:36,015:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:25:36,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-07-28 18:25:36,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:36,142:INFO:[LightGBM] [Info] Total Bins 1409
2024-07-28 18:25:36,142:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 10
2024-07-28 18:25:36,142:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:25:36,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2024-07-28 18:25:36,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:36,250:INFO:[LightGBM] [Info] Total Bins 1390
2024-07-28 18:25:36,250:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 9
2024-07-28 18:25:36,250:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:25:36,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-07-28 18:25:36,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:36,376:INFO:[LightGBM] [Info] Total Bins 1363
2024-07-28 18:25:36,376:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 8
2024-07-28 18:25:36,376:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:25:36,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2024-07-28 18:25:36,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:36,550:INFO:[LightGBM] [Info] Total Bins 1347
2024-07-28 18:25:36,551:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 7
2024-07-28 18:25:36,551:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:25:36,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-07-28 18:25:36,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-28 18:25:36,760:INFO:[LightGBM] [Info] Total Bins 1314
2024-07-28 18:25:36,760:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 6
2024-07-28 18:25:36,761:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-07-28 18:25:37,063:INFO:Visual Rendered Successfully
2024-07-28 18:25:37,446:INFO:plot_model() successfully completed......................................
2024-07-28 18:26:04,342:INFO:Initializing plot_model()
2024-07-28 18:26:04,342:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001ABB2ABB310>, system=True)
2024-07-28 18:26:04,342:INFO:Checking exceptions
2024-07-28 18:26:04,348:INFO:Preloading libraries
2024-07-28 18:26:04,362:INFO:Copying training dataset
2024-07-28 18:26:04,362:INFO:Plot type: feature
2024-07-28 18:26:04,362:WARNING:No coef_ found. Trying feature_importances_
2024-07-28 18:26:04,652:INFO:Visual Rendered Successfully
2024-07-28 18:26:05,030:INFO:plot_model() successfully completed......................................
2024-08-02 21:36:53,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-02 21:36:53,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-02 21:36:53,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-02 21:36:53,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-02 21:36:54,403:INFO:PyCaret RegressionExperiment
2024-08-02 21:36:54,403:INFO:Logging name: reg-default-name
2024-08-02 21:36:54,404:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-02 21:36:54,404:INFO:version 3.2.0
2024-08-02 21:36:54,404:INFO:Initializing setup()
2024-08-02 21:36:54,404:INFO:self.USI: 5a8f
2024-08-02 21:36:54,404:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'pipeline', 'idx', '_available_plots', 'exp_id', 'memory', 'X_train', 'seed', 'fold_generator', 'fold_groups_param', 'exp_name_log', 'y', 'X', 'transform_target_param', 'y_test', 'USI', 'html_param', 'gpu_param', 'fold_shuffle_param', 'X_test', 'y_train', 'log_plots_param', '_ml_usecase', 'data', 'target_param'}
2024-08-02 21:36:54,404:INFO:Checking environment
2024-08-02 21:36:54,404:INFO:python_version: 3.8.10
2024-08-02 21:36:54,404:INFO:python_build: ('tags/v3.8.10:3d8993a', 'May  3 2021 11:48:03')
2024-08-02 21:36:54,404:INFO:machine: AMD64
2024-08-02 21:36:54,404:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-02 21:36:54,404:INFO:Memory: svmem(total=34308190208, available=21519486976, percent=37.3, used=12788703232, free=21519486976)
2024-08-02 21:36:54,404:INFO:Physical Core: 8
2024-08-02 21:36:54,404:INFO:Logical Core: 16
2024-08-02 21:36:54,404:INFO:Checking libraries
2024-08-02 21:36:54,404:INFO:System:
2024-08-02 21:36:54,404:INFO:    python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]
2024-08-02 21:36:54,404:INFO:executable: C:\Users\chima\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\python.exe
2024-08-02 21:36:54,405:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-02 21:36:54,405:INFO:PyCaret required dependencies:
2024-08-02 21:36:54,545:INFO:                 pip: 21.1.1
2024-08-02 21:36:54,545:INFO:          setuptools: 56.0.0
2024-08-02 21:36:54,545:INFO:             pycaret: 3.2.0
2024-08-02 21:36:54,545:INFO:             IPython: 8.4.0
2024-08-02 21:36:54,545:INFO:          ipywidgets: 8.1.3
2024-08-02 21:36:54,545:INFO:                tqdm: 4.65.0
2024-08-02 21:36:54,545:INFO:               numpy: 1.24.4
2024-08-02 21:36:54,545:INFO:              pandas: 1.5.0
2024-08-02 21:36:54,545:INFO:              jinja2: 3.1.4
2024-08-02 21:36:54,545:INFO:               scipy: 1.10.1
2024-08-02 21:36:54,546:INFO:              joblib: 1.2.0
2024-08-02 21:36:54,546:INFO:             sklearn: 1.2.2
2024-08-02 21:36:54,546:INFO:                pyod: 2.0.1
2024-08-02 21:36:54,546:INFO:            imblearn: 0.12.3
2024-08-02 21:36:54,546:INFO:   category_encoders: 2.6.3
2024-08-02 21:36:54,546:INFO:            lightgbm: 4.5.0
2024-08-02 21:36:54,546:INFO:               numba: 0.58.1
2024-08-02 21:36:54,546:INFO:            requests: 2.32.3
2024-08-02 21:36:54,546:INFO:          matplotlib: 3.6.0
2024-08-02 21:36:54,546:INFO:          scikitplot: 0.3.7
2024-08-02 21:36:54,546:INFO:         yellowbrick: 1.5
2024-08-02 21:36:54,546:INFO:              plotly: 5.23.0
2024-08-02 21:36:54,546:INFO:    plotly-resampler: Not installed
2024-08-02 21:36:54,546:INFO:             kaleido: 0.2.1
2024-08-02 21:36:54,546:INFO:           schemdraw: 0.15
2024-08-02 21:36:54,546:INFO:         statsmodels: 0.14.1
2024-08-02 21:36:54,546:INFO:              sktime: 0.21.1
2024-08-02 21:36:54,546:INFO:               tbats: 1.1.3
2024-08-02 21:36:54,546:INFO:            pmdarima: 2.0.4
2024-08-02 21:36:54,546:INFO:              psutil: 5.9.1
2024-08-02 21:36:54,547:INFO:          markupsafe: 2.1.5
2024-08-02 21:36:54,547:INFO:             pickle5: Not installed
2024-08-02 21:36:54,547:INFO:         cloudpickle: 3.0.0
2024-08-02 21:36:54,547:INFO:         deprecation: 2.1.0
2024-08-02 21:36:54,547:INFO:              xxhash: 3.4.1
2024-08-02 21:36:54,547:INFO:           wurlitzer: Not installed
2024-08-02 21:36:54,547:INFO:PyCaret optional dependencies:
2024-08-02 21:36:54,574:INFO:                shap: Not installed
2024-08-02 21:36:54,575:INFO:           interpret: Not installed
2024-08-02 21:36:54,575:INFO:                umap: Not installed
2024-08-02 21:36:54,575:INFO:     ydata_profiling: Not installed
2024-08-02 21:36:54,575:INFO:  explainerdashboard: Not installed
2024-08-02 21:36:54,575:INFO:             autoviz: Not installed
2024-08-02 21:36:54,575:INFO:           fairlearn: Not installed
2024-08-02 21:36:54,575:INFO:          deepchecks: Not installed
2024-08-02 21:36:54,575:INFO:             xgboost: Not installed
2024-08-02 21:36:54,575:INFO:            catboost: Not installed
2024-08-02 21:36:54,575:INFO:              kmodes: Not installed
2024-08-02 21:36:54,575:INFO:             mlxtend: Not installed
2024-08-02 21:36:54,575:INFO:       statsforecast: Not installed
2024-08-02 21:36:54,575:INFO:        tune_sklearn: Not installed
2024-08-02 21:36:54,575:INFO:                 ray: Not installed
2024-08-02 21:36:54,575:INFO:            hyperopt: Not installed
2024-08-02 21:36:54,575:INFO:              optuna: Not installed
2024-08-02 21:36:54,575:INFO:               skopt: Not installed
2024-08-02 21:36:54,575:INFO:              mlflow: Not installed
2024-08-02 21:36:54,575:INFO:              gradio: Not installed
2024-08-02 21:36:54,575:INFO:             fastapi: Not installed
2024-08-02 21:36:54,576:INFO:             uvicorn: Not installed
2024-08-02 21:36:54,576:INFO:              m2cgen: Not installed
2024-08-02 21:36:54,576:INFO:           evidently: Not installed
2024-08-02 21:36:54,576:INFO:               fugue: Not installed
2024-08-02 21:36:54,576:INFO:           streamlit: Not installed
2024-08-02 21:36:54,576:INFO:             prophet: Not installed
2024-08-02 21:36:54,576:INFO:None
2024-08-02 21:36:54,576:INFO:Set up data.
2024-08-02 21:36:54,592:INFO:Set up folding strategy.
2024-08-02 21:36:54,592:INFO:Set up train/test split.
2024-08-02 21:36:54,602:INFO:Set up index.
2024-08-02 21:36:54,603:INFO:Assigning column types.
2024-08-02 21:36:54,607:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-02 21:36:54,607:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:54,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:54,775:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,782:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:54,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:54,935:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-02 21:36:54,941:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 21:36:54,948:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:55,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:55,100:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:55,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:55,251:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-02 21:36:55,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:55,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:55,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:55,425:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,084:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-02 21:36:56,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,354:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,419:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-02 21:36:56,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 21:36:56,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,737:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-02 21:36:56,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:56,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,067:INFO:Preparing preprocessing pipeline...
2024-08-02 21:36:57,067:INFO:Set up simple imputation.
2024-08-02 21:36:57,073:INFO:Set up encoding of categorical features.
2024-08-02 21:36:57,074:INFO:Set up column name cleaning.
2024-08-02 21:36:57,206:INFO:Finished creating preprocessing pipeline.
2024-08-02 21:36:57,221:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chima\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-08-02 21:36:57,221:INFO:Creating final display dataframe.
2024-08-02 21:36:57,541:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    Rating Average
2                   Target type        Regression
3           Original data shape        (8861, 12)
4        Transformed data shape        (8861, 12)
5   Transformed train set shape        (6202, 12)
6    Transformed test set shape        (2659, 12)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values              4.4%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              5a8f
2024-08-02 21:36:57,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 21:36:57,873:INFO:setup() successfully completed in 3.49s...............
2024-08-02 21:36:57,893:INFO:Initializing compare_models()
2024-08-02 21:36:57,893:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-08-02 21:36:57,894:INFO:Checking exceptions
2024-08-02 21:36:57,896:INFO:Preparing display monitor
2024-08-02 21:36:57,934:INFO:Initializing Linear Regression
2024-08-02 21:36:57,934:INFO:Total runtime is 0.0 minutes
2024-08-02 21:36:57,938:INFO:SubProcess create_model() called ==================================
2024-08-02 21:36:57,938:INFO:Initializing create_model()
2024-08-02 21:36:57,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:36:57,939:INFO:Checking exceptions
2024-08-02 21:36:57,939:INFO:Importing libraries
2024-08-02 21:36:57,939:INFO:Copying training dataset
2024-08-02 21:36:57,944:INFO:Defining folds
2024-08-02 21:36:57,944:INFO:Declaring metric variables
2024-08-02 21:36:57,948:INFO:Importing untrained model
2024-08-02 21:36:57,953:INFO:Linear Regression Imported successfully
2024-08-02 21:36:57,960:INFO:Starting cross validation
2024-08-02 21:36:57,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:05,025:INFO:Calculating mean and std
2024-08-02 21:37:05,027:INFO:Creating metrics dataframe
2024-08-02 21:37:05,032:INFO:Uploading results into container
2024-08-02 21:37:05,033:INFO:Uploading model into container now
2024-08-02 21:37:05,034:INFO:_master_model_container: 1
2024-08-02 21:37:05,034:INFO:_display_container: 2
2024-08-02 21:37:05,035:INFO:LinearRegression(n_jobs=-1)
2024-08-02 21:37:05,035:INFO:create_model() successfully completed......................................
2024-08-02 21:37:05,804:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:05,804:INFO:Creating metrics dataframe
2024-08-02 21:37:05,814:INFO:Initializing Lasso Regression
2024-08-02 21:37:05,814:INFO:Total runtime is 0.1313406268755595 minutes
2024-08-02 21:37:05,818:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:05,818:INFO:Initializing create_model()
2024-08-02 21:37:05,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:05,819:INFO:Checking exceptions
2024-08-02 21:37:05,819:INFO:Importing libraries
2024-08-02 21:37:05,819:INFO:Copying training dataset
2024-08-02 21:37:05,825:INFO:Defining folds
2024-08-02 21:37:05,826:INFO:Declaring metric variables
2024-08-02 21:37:05,829:INFO:Importing untrained model
2024-08-02 21:37:05,834:INFO:Lasso Regression Imported successfully
2024-08-02 21:37:05,840:INFO:Starting cross validation
2024-08-02 21:37:05,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:08,412:INFO:Calculating mean and std
2024-08-02 21:37:08,414:INFO:Creating metrics dataframe
2024-08-02 21:37:08,424:INFO:Uploading results into container
2024-08-02 21:37:08,425:INFO:Uploading model into container now
2024-08-02 21:37:08,426:INFO:_master_model_container: 2
2024-08-02 21:37:08,427:INFO:_display_container: 2
2024-08-02 21:37:08,427:INFO:Lasso(random_state=123)
2024-08-02 21:37:08,427:INFO:create_model() successfully completed......................................
2024-08-02 21:37:08,677:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:08,677:INFO:Creating metrics dataframe
2024-08-02 21:37:08,688:INFO:Initializing Ridge Regression
2024-08-02 21:37:08,688:INFO:Total runtime is 0.17924063205718996 minutes
2024-08-02 21:37:08,691:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:08,692:INFO:Initializing create_model()
2024-08-02 21:37:08,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:08,693:INFO:Checking exceptions
2024-08-02 21:37:08,693:INFO:Importing libraries
2024-08-02 21:37:08,693:INFO:Copying training dataset
2024-08-02 21:37:08,699:INFO:Defining folds
2024-08-02 21:37:08,699:INFO:Declaring metric variables
2024-08-02 21:37:08,703:INFO:Importing untrained model
2024-08-02 21:37:08,707:INFO:Ridge Regression Imported successfully
2024-08-02 21:37:08,713:INFO:Starting cross validation
2024-08-02 21:37:08,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:08,923:INFO:Calculating mean and std
2024-08-02 21:37:08,925:INFO:Creating metrics dataframe
2024-08-02 21:37:08,928:INFO:Uploading results into container
2024-08-02 21:37:08,929:INFO:Uploading model into container now
2024-08-02 21:37:08,929:INFO:_master_model_container: 3
2024-08-02 21:37:08,929:INFO:_display_container: 2
2024-08-02 21:37:08,930:INFO:Ridge(random_state=123)
2024-08-02 21:37:08,930:INFO:create_model() successfully completed......................................
2024-08-02 21:37:09,157:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:09,157:INFO:Creating metrics dataframe
2024-08-02 21:37:09,168:INFO:Initializing Elastic Net
2024-08-02 21:37:09,168:INFO:Total runtime is 0.1872406085332235 minutes
2024-08-02 21:37:09,171:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:09,171:INFO:Initializing create_model()
2024-08-02 21:37:09,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:09,172:INFO:Checking exceptions
2024-08-02 21:37:09,172:INFO:Importing libraries
2024-08-02 21:37:09,172:INFO:Copying training dataset
2024-08-02 21:37:09,179:INFO:Defining folds
2024-08-02 21:37:09,179:INFO:Declaring metric variables
2024-08-02 21:37:09,183:INFO:Importing untrained model
2024-08-02 21:37:09,187:INFO:Elastic Net Imported successfully
2024-08-02 21:37:09,194:INFO:Starting cross validation
2024-08-02 21:37:09,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:09,416:INFO:Calculating mean and std
2024-08-02 21:37:09,418:INFO:Creating metrics dataframe
2024-08-02 21:37:09,422:INFO:Uploading results into container
2024-08-02 21:37:09,422:INFO:Uploading model into container now
2024-08-02 21:37:09,423:INFO:_master_model_container: 4
2024-08-02 21:37:09,423:INFO:_display_container: 2
2024-08-02 21:37:09,423:INFO:ElasticNet(random_state=123)
2024-08-02 21:37:09,424:INFO:create_model() successfully completed......................................
2024-08-02 21:37:09,649:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:09,649:INFO:Creating metrics dataframe
2024-08-02 21:37:09,659:INFO:Initializing Least Angle Regression
2024-08-02 21:37:09,659:INFO:Total runtime is 0.1954239885012309 minutes
2024-08-02 21:37:09,662:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:09,663:INFO:Initializing create_model()
2024-08-02 21:37:09,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:09,663:INFO:Checking exceptions
2024-08-02 21:37:09,663:INFO:Importing libraries
2024-08-02 21:37:09,663:INFO:Copying training dataset
2024-08-02 21:37:09,671:INFO:Defining folds
2024-08-02 21:37:09,671:INFO:Declaring metric variables
2024-08-02 21:37:09,675:INFO:Importing untrained model
2024-08-02 21:37:09,678:INFO:Least Angle Regression Imported successfully
2024-08-02 21:37:09,686:INFO:Starting cross validation
2024-08-02 21:37:09,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:09,911:INFO:Calculating mean and std
2024-08-02 21:37:09,913:INFO:Creating metrics dataframe
2024-08-02 21:37:09,917:INFO:Uploading results into container
2024-08-02 21:37:09,918:INFO:Uploading model into container now
2024-08-02 21:37:09,918:INFO:_master_model_container: 5
2024-08-02 21:37:09,918:INFO:_display_container: 2
2024-08-02 21:37:09,918:INFO:Lars(random_state=123)
2024-08-02 21:37:09,919:INFO:create_model() successfully completed......................................
2024-08-02 21:37:10,143:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:10,143:INFO:Creating metrics dataframe
2024-08-02 21:37:10,154:INFO:Initializing Lasso Least Angle Regression
2024-08-02 21:37:10,154:INFO:Total runtime is 0.20367396672566734 minutes
2024-08-02 21:37:10,158:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:10,158:INFO:Initializing create_model()
2024-08-02 21:37:10,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:10,158:INFO:Checking exceptions
2024-08-02 21:37:10,159:INFO:Importing libraries
2024-08-02 21:37:10,159:INFO:Copying training dataset
2024-08-02 21:37:10,165:INFO:Defining folds
2024-08-02 21:37:10,166:INFO:Declaring metric variables
2024-08-02 21:37:10,170:INFO:Importing untrained model
2024-08-02 21:37:10,173:INFO:Lasso Least Angle Regression Imported successfully
2024-08-02 21:37:10,180:INFO:Starting cross validation
2024-08-02 21:37:10,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:10,381:INFO:Calculating mean and std
2024-08-02 21:37:10,383:INFO:Creating metrics dataframe
2024-08-02 21:37:10,387:INFO:Uploading results into container
2024-08-02 21:37:10,387:INFO:Uploading model into container now
2024-08-02 21:37:10,388:INFO:_master_model_container: 6
2024-08-02 21:37:10,388:INFO:_display_container: 2
2024-08-02 21:37:10,388:INFO:LassoLars(random_state=123)
2024-08-02 21:37:10,388:INFO:create_model() successfully completed......................................
2024-08-02 21:37:10,614:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:10,614:INFO:Creating metrics dataframe
2024-08-02 21:37:10,625:INFO:Initializing Orthogonal Matching Pursuit
2024-08-02 21:37:10,625:INFO:Total runtime is 0.2115239461263021 minutes
2024-08-02 21:37:10,628:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:10,628:INFO:Initializing create_model()
2024-08-02 21:37:10,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:10,629:INFO:Checking exceptions
2024-08-02 21:37:10,629:INFO:Importing libraries
2024-08-02 21:37:10,629:INFO:Copying training dataset
2024-08-02 21:37:10,636:INFO:Defining folds
2024-08-02 21:37:10,636:INFO:Declaring metric variables
2024-08-02 21:37:10,640:INFO:Importing untrained model
2024-08-02 21:37:10,644:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-02 21:37:10,651:INFO:Starting cross validation
2024-08-02 21:37:10,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:10,861:INFO:Calculating mean and std
2024-08-02 21:37:10,863:INFO:Creating metrics dataframe
2024-08-02 21:37:10,867:INFO:Uploading results into container
2024-08-02 21:37:10,868:INFO:Uploading model into container now
2024-08-02 21:37:10,869:INFO:_master_model_container: 7
2024-08-02 21:37:10,869:INFO:_display_container: 2
2024-08-02 21:37:10,869:INFO:OrthogonalMatchingPursuit()
2024-08-02 21:37:10,869:INFO:create_model() successfully completed......................................
2024-08-02 21:37:11,102:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:11,103:INFO:Creating metrics dataframe
2024-08-02 21:37:11,113:INFO:Initializing Bayesian Ridge
2024-08-02 21:37:11,114:INFO:Total runtime is 0.2196739713350932 minutes
2024-08-02 21:37:11,118:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:11,118:INFO:Initializing create_model()
2024-08-02 21:37:11,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:11,118:INFO:Checking exceptions
2024-08-02 21:37:11,119:INFO:Importing libraries
2024-08-02 21:37:11,119:INFO:Copying training dataset
2024-08-02 21:37:11,125:INFO:Defining folds
2024-08-02 21:37:11,125:INFO:Declaring metric variables
2024-08-02 21:37:11,129:INFO:Importing untrained model
2024-08-02 21:37:11,133:INFO:Bayesian Ridge Imported successfully
2024-08-02 21:37:11,140:INFO:Starting cross validation
2024-08-02 21:37:11,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:11,353:INFO:Calculating mean and std
2024-08-02 21:37:11,355:INFO:Creating metrics dataframe
2024-08-02 21:37:11,359:INFO:Uploading results into container
2024-08-02 21:37:11,359:INFO:Uploading model into container now
2024-08-02 21:37:11,360:INFO:_master_model_container: 8
2024-08-02 21:37:11,360:INFO:_display_container: 2
2024-08-02 21:37:11,360:INFO:BayesianRidge()
2024-08-02 21:37:11,360:INFO:create_model() successfully completed......................................
2024-08-02 21:37:11,594:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:11,594:INFO:Creating metrics dataframe
2024-08-02 21:37:11,606:INFO:Initializing Passive Aggressive Regressor
2024-08-02 21:37:11,606:INFO:Total runtime is 0.22787394126256308 minutes
2024-08-02 21:37:11,609:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:11,610:INFO:Initializing create_model()
2024-08-02 21:37:11,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:11,610:INFO:Checking exceptions
2024-08-02 21:37:11,610:INFO:Importing libraries
2024-08-02 21:37:11,610:INFO:Copying training dataset
2024-08-02 21:37:11,618:INFO:Defining folds
2024-08-02 21:37:11,618:INFO:Declaring metric variables
2024-08-02 21:37:11,622:INFO:Importing untrained model
2024-08-02 21:37:11,626:INFO:Passive Aggressive Regressor Imported successfully
2024-08-02 21:37:11,633:INFO:Starting cross validation
2024-08-02 21:37:11,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:11,856:INFO:Calculating mean and std
2024-08-02 21:37:11,858:INFO:Creating metrics dataframe
2024-08-02 21:37:11,861:INFO:Uploading results into container
2024-08-02 21:37:11,862:INFO:Uploading model into container now
2024-08-02 21:37:11,862:INFO:_master_model_container: 9
2024-08-02 21:37:11,862:INFO:_display_container: 2
2024-08-02 21:37:11,863:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-02 21:37:11,863:INFO:create_model() successfully completed......................................
2024-08-02 21:37:12,101:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:12,101:INFO:Creating metrics dataframe
2024-08-02 21:37:12,113:INFO:Initializing Huber Regressor
2024-08-02 21:37:12,113:INFO:Total runtime is 0.23632394870122275 minutes
2024-08-02 21:37:12,116:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:12,117:INFO:Initializing create_model()
2024-08-02 21:37:12,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:12,117:INFO:Checking exceptions
2024-08-02 21:37:12,117:INFO:Importing libraries
2024-08-02 21:37:12,117:INFO:Copying training dataset
2024-08-02 21:37:12,128:INFO:Defining folds
2024-08-02 21:37:12,128:INFO:Declaring metric variables
2024-08-02 21:37:12,133:INFO:Importing untrained model
2024-08-02 21:37:12,139:INFO:Huber Regressor Imported successfully
2024-08-02 21:37:12,146:INFO:Starting cross validation
2024-08-02 21:37:12,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:12,382:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,385:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,395:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,417:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,437:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,449:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,466:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,487:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,494:WARNING:C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-02 21:37:12,521:INFO:Calculating mean and std
2024-08-02 21:37:12,523:INFO:Creating metrics dataframe
2024-08-02 21:37:12,526:INFO:Uploading results into container
2024-08-02 21:37:12,527:INFO:Uploading model into container now
2024-08-02 21:37:12,527:INFO:_master_model_container: 10
2024-08-02 21:37:12,527:INFO:_display_container: 2
2024-08-02 21:37:12,527:INFO:HuberRegressor()
2024-08-02 21:37:12,527:INFO:create_model() successfully completed......................................
2024-08-02 21:37:12,753:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:12,753:INFO:Creating metrics dataframe
2024-08-02 21:37:12,765:INFO:Initializing K Neighbors Regressor
2024-08-02 21:37:12,766:INFO:Total runtime is 0.24720730384190878 minutes
2024-08-02 21:37:12,769:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:12,770:INFO:Initializing create_model()
2024-08-02 21:37:12,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:12,770:INFO:Checking exceptions
2024-08-02 21:37:12,770:INFO:Importing libraries
2024-08-02 21:37:12,770:INFO:Copying training dataset
2024-08-02 21:37:12,776:INFO:Defining folds
2024-08-02 21:37:12,777:INFO:Declaring metric variables
2024-08-02 21:37:12,780:INFO:Importing untrained model
2024-08-02 21:37:12,784:INFO:K Neighbors Regressor Imported successfully
2024-08-02 21:37:12,791:INFO:Starting cross validation
2024-08-02 21:37:12,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:13,030:INFO:Calculating mean and std
2024-08-02 21:37:13,032:INFO:Creating metrics dataframe
2024-08-02 21:37:13,036:INFO:Uploading results into container
2024-08-02 21:37:13,036:INFO:Uploading model into container now
2024-08-02 21:37:13,037:INFO:_master_model_container: 11
2024-08-02 21:37:13,037:INFO:_display_container: 2
2024-08-02 21:37:13,037:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-02 21:37:13,037:INFO:create_model() successfully completed......................................
2024-08-02 21:37:13,287:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:13,287:INFO:Creating metrics dataframe
2024-08-02 21:37:13,300:INFO:Initializing Decision Tree Regressor
2024-08-02 21:37:13,301:INFO:Total runtime is 0.25612396399180093 minutes
2024-08-02 21:37:13,304:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:13,304:INFO:Initializing create_model()
2024-08-02 21:37:13,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:13,305:INFO:Checking exceptions
2024-08-02 21:37:13,305:INFO:Importing libraries
2024-08-02 21:37:13,305:INFO:Copying training dataset
2024-08-02 21:37:13,311:INFO:Defining folds
2024-08-02 21:37:13,311:INFO:Declaring metric variables
2024-08-02 21:37:13,315:INFO:Importing untrained model
2024-08-02 21:37:13,319:INFO:Decision Tree Regressor Imported successfully
2024-08-02 21:37:13,326:INFO:Starting cross validation
2024-08-02 21:37:13,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:13,581:INFO:Calculating mean and std
2024-08-02 21:37:13,583:INFO:Creating metrics dataframe
2024-08-02 21:37:13,587:INFO:Uploading results into container
2024-08-02 21:37:13,588:INFO:Uploading model into container now
2024-08-02 21:37:13,588:INFO:_master_model_container: 12
2024-08-02 21:37:13,589:INFO:_display_container: 2
2024-08-02 21:37:13,589:INFO:DecisionTreeRegressor(random_state=123)
2024-08-02 21:37:13,589:INFO:create_model() successfully completed......................................
2024-08-02 21:37:13,815:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:13,816:INFO:Creating metrics dataframe
2024-08-02 21:37:13,828:INFO:Initializing Random Forest Regressor
2024-08-02 21:37:13,828:INFO:Total runtime is 0.2649072925249735 minutes
2024-08-02 21:37:13,832:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:13,833:INFO:Initializing create_model()
2024-08-02 21:37:13,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:13,833:INFO:Checking exceptions
2024-08-02 21:37:13,833:INFO:Importing libraries
2024-08-02 21:37:13,833:INFO:Copying training dataset
2024-08-02 21:37:13,840:INFO:Defining folds
2024-08-02 21:37:13,840:INFO:Declaring metric variables
2024-08-02 21:37:13,843:INFO:Importing untrained model
2024-08-02 21:37:13,847:INFO:Random Forest Regressor Imported successfully
2024-08-02 21:37:13,854:INFO:Starting cross validation
2024-08-02 21:37:13,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:18,283:INFO:Calculating mean and std
2024-08-02 21:37:18,285:INFO:Creating metrics dataframe
2024-08-02 21:37:18,289:INFO:Uploading results into container
2024-08-02 21:37:18,290:INFO:Uploading model into container now
2024-08-02 21:37:18,290:INFO:_master_model_container: 13
2024-08-02 21:37:18,291:INFO:_display_container: 2
2024-08-02 21:37:18,291:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-02 21:37:18,291:INFO:create_model() successfully completed......................................
2024-08-02 21:37:18,530:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:18,530:INFO:Creating metrics dataframe
2024-08-02 21:37:18,544:INFO:Initializing Extra Trees Regressor
2024-08-02 21:37:18,545:INFO:Total runtime is 0.3435239712397257 minutes
2024-08-02 21:37:18,548:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:18,549:INFO:Initializing create_model()
2024-08-02 21:37:18,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:18,549:INFO:Checking exceptions
2024-08-02 21:37:18,549:INFO:Importing libraries
2024-08-02 21:37:18,549:INFO:Copying training dataset
2024-08-02 21:37:18,557:INFO:Defining folds
2024-08-02 21:37:18,557:INFO:Declaring metric variables
2024-08-02 21:37:18,561:INFO:Importing untrained model
2024-08-02 21:37:18,565:INFO:Extra Trees Regressor Imported successfully
2024-08-02 21:37:18,572:INFO:Starting cross validation
2024-08-02 21:37:18,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:20,529:INFO:Calculating mean and std
2024-08-02 21:37:20,531:INFO:Creating metrics dataframe
2024-08-02 21:37:20,536:INFO:Uploading results into container
2024-08-02 21:37:20,537:INFO:Uploading model into container now
2024-08-02 21:37:20,537:INFO:_master_model_container: 14
2024-08-02 21:37:20,538:INFO:_display_container: 2
2024-08-02 21:37:20,538:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-02 21:37:20,538:INFO:create_model() successfully completed......................................
2024-08-02 21:37:20,778:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:20,778:INFO:Creating metrics dataframe
2024-08-02 21:37:20,792:INFO:Initializing AdaBoost Regressor
2024-08-02 21:37:20,792:INFO:Total runtime is 0.38097393910090127 minutes
2024-08-02 21:37:20,795:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:20,795:INFO:Initializing create_model()
2024-08-02 21:37:20,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:20,796:INFO:Checking exceptions
2024-08-02 21:37:20,796:INFO:Importing libraries
2024-08-02 21:37:20,796:INFO:Copying training dataset
2024-08-02 21:37:20,803:INFO:Defining folds
2024-08-02 21:37:20,803:INFO:Declaring metric variables
2024-08-02 21:37:20,807:INFO:Importing untrained model
2024-08-02 21:37:20,810:INFO:AdaBoost Regressor Imported successfully
2024-08-02 21:37:20,817:INFO:Starting cross validation
2024-08-02 21:37:20,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:21,588:INFO:Calculating mean and std
2024-08-02 21:37:21,590:INFO:Creating metrics dataframe
2024-08-02 21:37:21,593:INFO:Uploading results into container
2024-08-02 21:37:21,594:INFO:Uploading model into container now
2024-08-02 21:37:21,595:INFO:_master_model_container: 15
2024-08-02 21:37:21,595:INFO:_display_container: 2
2024-08-02 21:37:21,595:INFO:AdaBoostRegressor(random_state=123)
2024-08-02 21:37:21,595:INFO:create_model() successfully completed......................................
2024-08-02 21:37:21,858:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:21,859:INFO:Creating metrics dataframe
2024-08-02 21:37:21,873:INFO:Initializing Gradient Boosting Regressor
2024-08-02 21:37:21,873:INFO:Total runtime is 0.3989906350771586 minutes
2024-08-02 21:37:21,876:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:21,877:INFO:Initializing create_model()
2024-08-02 21:37:21,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:21,877:INFO:Checking exceptions
2024-08-02 21:37:21,877:INFO:Importing libraries
2024-08-02 21:37:21,877:INFO:Copying training dataset
2024-08-02 21:37:21,886:INFO:Defining folds
2024-08-02 21:37:21,886:INFO:Declaring metric variables
2024-08-02 21:37:21,891:INFO:Importing untrained model
2024-08-02 21:37:21,895:INFO:Gradient Boosting Regressor Imported successfully
2024-08-02 21:37:21,907:INFO:Starting cross validation
2024-08-02 21:37:21,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:23,567:INFO:Calculating mean and std
2024-08-02 21:37:23,569:INFO:Creating metrics dataframe
2024-08-02 21:37:23,573:INFO:Uploading results into container
2024-08-02 21:37:23,574:INFO:Uploading model into container now
2024-08-02 21:37:23,574:INFO:_master_model_container: 16
2024-08-02 21:37:23,574:INFO:_display_container: 2
2024-08-02 21:37:23,575:INFO:GradientBoostingRegressor(random_state=123)
2024-08-02 21:37:23,575:INFO:create_model() successfully completed......................................
2024-08-02 21:37:23,801:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:23,801:INFO:Creating metrics dataframe
2024-08-02 21:37:23,816:INFO:Initializing Light Gradient Boosting Machine
2024-08-02 21:37:23,816:INFO:Total runtime is 0.4313740134239197 minutes
2024-08-02 21:37:23,820:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:23,820:INFO:Initializing create_model()
2024-08-02 21:37:23,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:23,820:INFO:Checking exceptions
2024-08-02 21:37:23,820:INFO:Importing libraries
2024-08-02 21:37:23,820:INFO:Copying training dataset
2024-08-02 21:37:23,827:INFO:Defining folds
2024-08-02 21:37:23,827:INFO:Declaring metric variables
2024-08-02 21:37:23,830:INFO:Importing untrained model
2024-08-02 21:37:23,835:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-02 21:37:23,841:INFO:Starting cross validation
2024-08-02 21:37:23,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:26,390:INFO:Calculating mean and std
2024-08-02 21:37:26,392:INFO:Creating metrics dataframe
2024-08-02 21:37:26,396:INFO:Uploading results into container
2024-08-02 21:37:26,396:INFO:Uploading model into container now
2024-08-02 21:37:26,397:INFO:_master_model_container: 17
2024-08-02 21:37:26,397:INFO:_display_container: 2
2024-08-02 21:37:26,398:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 21:37:26,398:INFO:create_model() successfully completed......................................
2024-08-02 21:37:26,654:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:26,655:INFO:Creating metrics dataframe
2024-08-02 21:37:26,668:INFO:Initializing Dummy Regressor
2024-08-02 21:37:26,669:INFO:Total runtime is 0.47892396052678426 minutes
2024-08-02 21:37:26,672:INFO:SubProcess create_model() called ==================================
2024-08-02 21:37:26,672:INFO:Initializing create_model()
2024-08-02 21:37:26,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B964F45790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:26,673:INFO:Checking exceptions
2024-08-02 21:37:26,673:INFO:Importing libraries
2024-08-02 21:37:26,673:INFO:Copying training dataset
2024-08-02 21:37:26,679:INFO:Defining folds
2024-08-02 21:37:26,680:INFO:Declaring metric variables
2024-08-02 21:37:26,684:INFO:Importing untrained model
2024-08-02 21:37:26,687:INFO:Dummy Regressor Imported successfully
2024-08-02 21:37:26,694:INFO:Starting cross validation
2024-08-02 21:37:26,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 21:37:26,895:INFO:Calculating mean and std
2024-08-02 21:37:26,897:INFO:Creating metrics dataframe
2024-08-02 21:37:26,901:INFO:Uploading results into container
2024-08-02 21:37:26,902:INFO:Uploading model into container now
2024-08-02 21:37:26,902:INFO:_master_model_container: 18
2024-08-02 21:37:26,902:INFO:_display_container: 2
2024-08-02 21:37:26,902:INFO:DummyRegressor()
2024-08-02 21:37:26,903:INFO:create_model() successfully completed......................................
2024-08-02 21:37:27,138:INFO:SubProcess create_model() end ==================================
2024-08-02 21:37:27,138:INFO:Creating metrics dataframe
2024-08-02 21:37:27,163:INFO:Initializing create_model()
2024-08-02 21:37:27,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:27,163:INFO:Checking exceptions
2024-08-02 21:37:27,166:INFO:Importing libraries
2024-08-02 21:37:27,166:INFO:Copying training dataset
2024-08-02 21:37:27,172:INFO:Defining folds
2024-08-02 21:37:27,172:INFO:Declaring metric variables
2024-08-02 21:37:27,172:INFO:Importing untrained model
2024-08-02 21:37:27,172:INFO:Declaring custom model
2024-08-02 21:37:27,173:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-02 21:37:27,174:INFO:Cross validation set to False
2024-08-02 21:37:27,174:INFO:Fitting Model
2024-08-02 21:37:27,243:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-02 21:37:27,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.
2024-08-02 21:37:27,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:27,244:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:37:27,244:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 11
2024-08-02 21:37:27,245:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:37:27,353:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 21:37:27,353:INFO:create_model() successfully completed......................................
2024-08-02 21:37:27,643:INFO:_master_model_container: 18
2024-08-02 21:37:27,643:INFO:_display_container: 2
2024-08-02 21:37:27,643:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 21:37:27,644:INFO:compare_models() successfully completed......................................
2024-08-02 21:37:27,678:INFO:Initializing finalize_model()
2024-08-02 21:37:27,678:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-02 21:37:27,678:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 21:37:27,682:INFO:Initializing create_model()
2024-08-02 21:37:27,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 21:37:27,682:INFO:Checking exceptions
2024-08-02 21:37:27,684:INFO:Importing libraries
2024-08-02 21:37:27,685:INFO:Copying training dataset
2024-08-02 21:37:27,685:INFO:Defining folds
2024-08-02 21:37:27,685:INFO:Declaring metric variables
2024-08-02 21:37:27,685:INFO:Importing untrained model
2024-08-02 21:37:27,685:INFO:Declaring custom model
2024-08-02 21:37:27,687:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-02 21:37:27,689:INFO:Cross validation set to False
2024-08-02 21:37:27,689:INFO:Fitting Model
2024-08-02 21:37:27,774:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-02 21:37:27,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.
2024-08-02 21:37:27,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:27,775:INFO:[LightGBM] [Info] Total Bins 1420
2024-08-02 21:37:27,775:INFO:[LightGBM] [Info] Number of data points in the train set: 8861, number of used features: 11
2024-08-02 21:37:27,776:INFO:[LightGBM] [Info] Start training from score 6.629909
2024-08-02 21:37:27,929:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-02 21:37:27,929:INFO:create_model() successfully completed......................................
2024-08-02 21:37:28,179:INFO:_master_model_container: 18
2024-08-02 21:37:28,179:INFO:_display_container: 2
2024-08-02 21:37:28,188:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-02 21:37:28,188:INFO:finalize_model() successfully completed......................................
2024-08-02 21:37:28,425:INFO:Initializing predict_model()
2024-08-02 21:37:28,425:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B91ACC2B80>)
2024-08-02 21:37:28,425:INFO:Checking exceptions
2024-08-02 21:37:28,426:INFO:Preloading libraries
2024-08-02 21:37:28,428:INFO:Set up data.
2024-08-02 21:37:28,443:INFO:Set up index.
2024-08-02 21:37:28,808:INFO:Initializing plot_model()
2024-08-02 21:37:28,808:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, system=True)
2024-08-02 21:37:28,808:INFO:Checking exceptions
2024-08-02 21:37:28,813:INFO:Preloading libraries
2024-08-02 21:37:28,820:INFO:Copying training dataset
2024-08-02 21:37:28,820:INFO:Plot type: residuals
2024-08-02 21:37:29,311:INFO:Fitting Model
2024-08-02 21:37:29,383:INFO:Scoring test/hold-out set
2024-08-02 21:37:30,108:INFO:Visual Rendered Successfully
2024-08-02 21:37:30,343:INFO:plot_model() successfully completed......................................
2024-08-02 21:37:30,359:INFO:Initializing plot_model()
2024-08-02 21:37:30,359:INFO:plot_model(plot=manifold, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, system=True)
2024-08-02 21:37:30,359:INFO:Checking exceptions
2024-08-02 21:37:30,364:INFO:Preloading libraries
2024-08-02 21:37:30,371:INFO:Copying training dataset
2024-08-02 21:37:30,371:INFO:Plot type: manifold
2024-08-02 21:37:30,865:INFO:Fitting & Transforming Model
2024-08-02 21:37:52,637:INFO:Visual Rendered Successfully
2024-08-02 21:37:52,865:INFO:plot_model() successfully completed......................................
2024-08-02 21:37:52,905:INFO:Initializing plot_model()
2024-08-02 21:37:52,905:INFO:plot_model(plot=rfe, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, system=True)
2024-08-02 21:37:52,905:INFO:Checking exceptions
2024-08-02 21:37:52,909:INFO:Preloading libraries
2024-08-02 21:37:52,917:INFO:Copying training dataset
2024-08-02 21:37:52,917:INFO:Plot type: rfe
2024-08-02 21:37:53,263:INFO:Fitting Model
2024-08-02 21:37:53,285:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
2024-08-02 21:37:53,285:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,285:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:37:53,285:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:37:53,285:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:53,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000622 seconds.
2024-08-02 21:37:53,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,383:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:37:53,383:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:37:53,383:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:53,500:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2024-08-02 21:37:53,500:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,500:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:37:53,501:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:37:53,501:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:53,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-08-02 21:37:53,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,600:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:37:53,600:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:37:53,601:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:53,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2024-08-02 21:37:53,698:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,698:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:37:53,699:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:37:53,699:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:53,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-08-02 21:37:53,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,797:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:37:53,797:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:37:53,798:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:53,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-08-02 21:37:53,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:53,903:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:37:53,903:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:37:53,903:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:54,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-02 21:37:54,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,068:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:37:54,068:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:37:54,068:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:54,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.
2024-08-02 21:37:54,193:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,193:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:37:54,193:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-08-02 21:37:54,193:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:54,307:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-08-02 21:37:54,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,308:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:37:54,308:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-08-02 21:37:54,308:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:54,403:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.
2024-08-02 21:37:54,403:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,404:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:37:54,404:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 1
2024-08-02 21:37:54,404:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:37:54,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2024-08-02 21:37:54,485:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,485:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:37:54,485:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:37:54,485:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:54,621:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-08-02 21:37:54,622:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,622:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:37:54,622:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:37:54,622:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:54,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-08-02 21:37:54,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,724:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:37:54,724:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:37:54,725:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:54,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2024-08-02 21:37:54,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,834:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:37:54,834:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:37:54,834:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:54,940:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-08-02 21:37:54,940:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:54,940:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:37:54,941:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:37:54,941:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-02 21:37:55,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,044:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:37:55,044:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:37:55,044:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,159:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-08-02 21:37:55,159:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,159:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:37:55,159:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:37:55,159:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2024-08-02 21:37:55,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,291:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:37:55,291:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:37:55,292:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-08-02 21:37:55,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,384:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:37:55,384:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-08-02 21:37:55,385:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.
2024-08-02 21:37:55,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,476:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:37:55,476:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-08-02 21:37:55,477:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.
2024-08-02 21:37:55,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,571:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:37:55,571:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 1
2024-08-02 21:37:55,572:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:37:55,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:37:55,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,663:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:37:55,663:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:37:55,664:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:55,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-08-02 21:37:55,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,783:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:37:55,783:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:37:55,783:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:55,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-08-02 21:37:55,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:55,901:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:37:55,902:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:37:55,902:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2024-08-02 21:37:56,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,023:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:37:56,023:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:37:56,023:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-08-02 21:37:56,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,136:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:37:56,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:37:56,136:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-02 21:37:56,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,243:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:37:56,244:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:37:56,244:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,361:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-02 21:37:56,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,361:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:37:56,362:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:37:56,362:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-02 21:37:56,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,463:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:37:56,464:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:37:56,464:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.
2024-08-02 21:37:56,551:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,551:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:37:56,552:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:37:56,552:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-08-02 21:37:56,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,651:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:37:56,651:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:37:56,652:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.
2024-08-02 21:37:56,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,757:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:37:56,758:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:37:56,758:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:37:56,850:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-08-02 21:37:56,850:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,850:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:37:56,850:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:37:56,850:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:56,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-08-02 21:37:56,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:56,948:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:37:56,948:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:37:56,948:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-08-02 21:37:57,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,064:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:37:57,064:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:37:57,065:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-08-02 21:37:57,168:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,168:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:37:57,168:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:37:57,168:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2024-08-02 21:37:57,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,282:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:37:57,283:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:37:57,283:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-02 21:37:57,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,390:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:37:57,390:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:37:57,390:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2024-08-02 21:37:57,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,526:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:37:57,526:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:37:57,526:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-02 21:37:57,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,634:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:37:57,634:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:37:57,635:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.
2024-08-02 21:37:57,736:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,736:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:37:57,736:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:37:57,736:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,839:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-08-02 21:37:57,839:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,839:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:37:57,839:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:37:57,839:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:57,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.
2024-08-02 21:37:57,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:57,943:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:37:57,943:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:37:57,943:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:37:58,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-08-02 21:37:58,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,030:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:37:58,030:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:37:58,030:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2024-08-02 21:37:58,137:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,137:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:37:58,137:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:37:58,138:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,239:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-08-02 21:37:58,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,240:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:37:58,240:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:37:58,240:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-08-02 21:37:58,345:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,345:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:37:58,345:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:37:58,345:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-08-02 21:37:58,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,466:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:37:58,466:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:37:58,466:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-02 21:37:58,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,589:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:37:58,590:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:37:58,590:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-08-02 21:37:58,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,705:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:37:58,705:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:37:58,705:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,807:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2024-08-02 21:37:58,807:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,807:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:37:58,807:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:37:58,808:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:58,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-08-02 21:37:58,911:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:58,911:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:37:58,911:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:37:58,911:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:59,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-08-02 21:37:59,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,028:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:37:59,028:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:37:59,028:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:59,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.
2024-08-02 21:37:59,119:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,119:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:37:59,119:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:37:59,120:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:37:59,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
2024-08-02 21:37:59,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,205:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:37:59,206:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:37:59,206:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:37:59,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-08-02 21:37:59,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,313:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:37:59,313:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:37:59,313:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:37:59,429:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-08-02 21:37:59,429:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,429:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:37:59,429:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:37:59,430:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:37:59,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2024-08-02 21:37:59,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,536:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:37:59,536:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:37:59,536:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:37:59,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-08-02 21:37:59,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,650:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:37:59,650:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:37:59,650:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:37:59,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-08-02 21:37:59,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,783:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:37:59,783:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:37:59,784:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:37:59,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-08-02 21:37:59,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:37:59,910:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:37:59,911:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:37:59,911:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:00,007:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-02 21:38:00,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,007:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:00,008:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:00,008:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:00,136:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.
2024-08-02 21:38:00,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,136:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:00,137:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:00,137:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:00,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-08-02 21:38:00,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,243:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:00,243:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:00,243:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:00,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.
2024-08-02 21:38:00,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,334:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:38:00,334:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:38:00,334:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:00,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2024-08-02 21:38:00,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,420:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:00,420:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:00,420:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:00,534:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2024-08-02 21:38:00,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,535:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:00,535:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:00,535:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:00,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:00,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,644:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:00,645:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:00,645:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:00,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:00,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:00,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:00,751:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:00,751:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:00,751:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:00,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-08-02 21:38:00,917:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:00,917:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:00,918:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:00,918:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
2024-08-02 21:38:01,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,032:INFO:[LightGBM] [Info] Total Bins 1312
2024-08-02 21:38:01,032:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:01,033:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-08-02 21:38:01,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,148:INFO:[LightGBM] [Info] Total Bins 1270
2024-08-02 21:38:01,149:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:01,149:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-08-02 21:38:01,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,268:INFO:[LightGBM] [Info] Total Bins 1015
2024-08-02 21:38:01,269:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:01,269:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,365:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-08-02 21:38:01,365:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:01,365:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:01,365:INFO:[LightGBM] [Info] Total Bins 760
2024-08-02 21:38:01,365:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:01,365:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.
2024-08-02 21:38:01,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,506:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:01,506:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:01,506:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.
2024-08-02 21:38:01,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,595:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:38:01,595:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:38:01,595:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:01,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2024-08-02 21:38:01,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,696:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:01,696:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:01,697:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:01,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-08-02 21:38:01,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,805:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:01,806:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:01,806:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:01,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.
2024-08-02 21:38:01,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:01,936:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:01,936:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:01,936:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
2024-08-02 21:38:02,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,046:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:02,046:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:02,046:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,174:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-08-02 21:38:02,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,175:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:02,175:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:02,175:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-02 21:38:02,302:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,302:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:02,303:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:02,303:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,424:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-08-02 21:38:02,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,424:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:02,424:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:02,424:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-02 21:38:02,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,525:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:02,525:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:02,525:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-02 21:38:02,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,629:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:02,629:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:02,629:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.
2024-08-02 21:38:02,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,717:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:02,717:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:02,718:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.
2024-08-02 21:38:02,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,834:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:38:02,834:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:38:02,834:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:02,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2024-08-02 21:38:02,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:02,934:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:02,934:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:02,934:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,056:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-08-02 21:38:03,056:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,056:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:03,056:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:03,057:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2024-08-02 21:38:03,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,161:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:03,162:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:03,162:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,275:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-08-02 21:38:03,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,276:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:03,276:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:03,276:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2024-08-02 21:38:03,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,395:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:03,396:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:03,396:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-02 21:38:03,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,524:INFO:[LightGBM] [Info] Total Bins 1313
2024-08-02 21:38:03,524:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:03,524:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-02 21:38:03,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,638:INFO:[LightGBM] [Info] Total Bins 1271
2024-08-02 21:38:03,638:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:03,638:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
2024-08-02 21:38:03,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,741:INFO:[LightGBM] [Info] Total Bins 1016
2024-08-02 21:38:03,741:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:03,742:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,838:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-08-02 21:38:03,838:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,838:INFO:[LightGBM] [Info] Total Bins 761
2024-08-02 21:38:03,839:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:03,839:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:03,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.
2024-08-02 21:38:03,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:03,941:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:03,941:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:03,941:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:04,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.
2024-08-02 21:38:04,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,037:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:38:04,037:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:38:04,037:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:04,136:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-08-02 21:38:04,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,136:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:04,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:04,136:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-08-02 21:38:04,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,274:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:04,274:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:04,274:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2024-08-02 21:38:04,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,379:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:04,380:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:04,380:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,495:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-08-02 21:38:04,495:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,495:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:38:04,495:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:04,495:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-08-02 21:38:04,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,611:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:04,611:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:04,611:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,719:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-02 21:38:04,719:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,719:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:04,719:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:04,720:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,842:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.
2024-08-02 21:38:04,842:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,842:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:04,842:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:04,843:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:04,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2024-08-02 21:38:04,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:04,941:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:04,941:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:04,942:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:05,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-02 21:38:05,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,042:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:05,042:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:05,042:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:05,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-08-02 21:38:05,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,144:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:05,144:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:05,145:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:05,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.
2024-08-02 21:38:05,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,252:INFO:[LightGBM] [Info] Total Bins 255
2024-08-02 21:38:05,253:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 1
2024-08-02 21:38:05,253:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:05,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2024-08-02 21:38:05,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,344:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:05,344:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:05,345:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:05,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-08-02 21:38:05,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,450:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:05,451:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:05,451:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:05,561:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:38:05,561:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,561:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:05,561:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:05,561:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:05,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-08-02 21:38:05,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,688:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:38:05,688:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:05,689:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:05,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2024-08-02 21:38:05,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,797:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:38:05,798:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:05,798:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:05,907:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2024-08-02 21:38:05,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:05,908:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:05,908:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:05,908:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:06,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-08-02 21:38:06,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,028:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:06,028:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:06,029:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:06,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-08-02 21:38:06,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,129:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:06,130:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:38:06,130:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:06,234:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2024-08-02 21:38:06,234:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,234:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:06,235:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-08-02 21:38:06,235:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:06,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.
2024-08-02 21:38:06,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,340:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:06,340:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-08-02 21:38:06,341:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:06,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2024-08-02 21:38:06,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,463:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:06,463:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:06,464:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:06,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-08-02 21:38:06,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,572:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:06,572:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:06,572:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:06,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-08-02 21:38:06,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,694:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:06,694:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:06,694:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:06,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.
2024-08-02 21:38:06,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,818:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:06,818:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:06,818:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:06,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.
2024-08-02 21:38:06,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:06,943:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:38:06,943:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:06,944:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:07,068:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-08-02 21:38:07,068:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,068:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:07,068:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:07,069:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:07,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-08-02 21:38:07,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,182:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:07,182:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:07,183:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:07,353:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.
2024-08-02 21:38:07,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,354:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:07,354:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:38:07,354:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:07,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-08-02 21:38:07,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,469:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:07,469:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-08-02 21:38:07,470:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:07,585:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
2024-08-02 21:38:07,585:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,585:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:07,586:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 2
2024-08-02 21:38:07,586:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:07,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2024-08-02 21:38:07,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,696:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:07,696:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:07,696:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:07,807:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2024-08-02 21:38:07,807:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,807:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:07,808:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:07,808:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:07,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:38:07,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:07,943:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:07,943:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:07,943:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,056:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-08-02 21:38:08,056:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,057:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:08,057:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:08,057:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-08-02 21:38:08,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,161:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:08,161:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:08,162:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2024-08-02 21:38:08,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,282:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:08,282:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:08,282:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,405:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-02 21:38:08,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,406:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:08,406:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:08,406:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,507:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-02 21:38:08,507:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,507:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:08,507:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:08,508:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,624:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-08-02 21:38:08,624:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,624:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:08,624:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:08,625:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-08-02 21:38:08,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,735:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:08,736:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:08,736:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:08,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-08-02 21:38:08,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,843:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:08,843:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:08,843:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:08,953:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000482 seconds.
2024-08-02 21:38:08,953:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:08,953:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:08,953:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:08,954:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2024-08-02 21:38:09,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,084:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:09,084:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:09,085:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2024-08-02 21:38:09,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,191:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:09,191:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:09,191:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
2024-08-02 21:38:09,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,317:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:09,317:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:09,318:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,439:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-02 21:38:09,439:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,439:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:09,439:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:09,440:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-02 21:38:09,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,540:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:09,540:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:09,540:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-08-02 21:38:09,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,656:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:09,657:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:09,657:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-08-02 21:38:09,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,781:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:09,781:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:09,781:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.
2024-08-02 21:38:09,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,885:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:09,885:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:09,885:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:09,991:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-08-02 21:38:09,991:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:09,991:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:09,992:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:09,992:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,115:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:38:10,115:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:10,115:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:10,115:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:10,115:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:10,116:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-08-02 21:38:10,267:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,267:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:10,267:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:10,267:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,371:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2024-08-02 21:38:10,371:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,371:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:38:10,371:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:10,372:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2024-08-02 21:38:10,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,473:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:38:10,474:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:10,474:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-08-02 21:38:10,620:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,620:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:10,620:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:10,620:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-08-02 21:38:10,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,742:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:10,742:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:10,743:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-02 21:38:10,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,864:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:10,864:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:10,864:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:10,971:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-02 21:38:10,971:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:10,971:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:10,971:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:10,971:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:11,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.
2024-08-02 21:38:11,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,089:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:11,089:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:11,090:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:11,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2024-08-02 21:38:11,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,218:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:11,218:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:11,218:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:11,322:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:38:11,322:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,322:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:11,322:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:11,323:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:11,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.
2024-08-02 21:38:11,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,443:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:11,443:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:11,444:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:11,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-08-02 21:38:11,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,591:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:11,592:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:11,592:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:11,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-08-02 21:38:11,702:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,702:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:11,703:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:11,703:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:11,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-02 21:38:11,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,818:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:11,818:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:11,819:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:11,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-02 21:38:11,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:11,961:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:11,962:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:11,962:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:12,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-02 21:38:12,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,063:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:12,064:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:12,064:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:12,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-02 21:38:12,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,158:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:12,158:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:12,158:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:12,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.
2024-08-02 21:38:12,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,288:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:12,288:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:12,289:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:12,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:12,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,411:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:12,411:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:12,411:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:12,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:38:12,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,529:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:12,529:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:12,529:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:12,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2024-08-02 21:38:12,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,636:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:12,636:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:12,636:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:12,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2024-08-02 21:38:12,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,740:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:12,741:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:12,741:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:12,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.
2024-08-02 21:38:12,850:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,850:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:12,850:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:12,850:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:12,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-02 21:38:12,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:12,976:INFO:[LightGBM] [Info] Total Bins 1312
2024-08-02 21:38:12,976:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:12,977:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:13,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-02 21:38:13,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,096:INFO:[LightGBM] [Info] Total Bins 1270
2024-08-02 21:38:13,096:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:13,096:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:13,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-08-02 21:38:13,192:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,192:INFO:[LightGBM] [Info] Total Bins 1015
2024-08-02 21:38:13,193:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:13,193:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:13,289:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-08-02 21:38:13,289:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,289:INFO:[LightGBM] [Info] Total Bins 760
2024-08-02 21:38:13,289:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:13,289:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:13,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
2024-08-02 21:38:13,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,406:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:13,406:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:13,407:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:13,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2024-08-02 21:38:13,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,515:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:13,515:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:13,516:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:13,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-08-02 21:38:13,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,634:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:13,634:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:13,634:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:13,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-08-02 21:38:13,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,742:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:13,742:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:13,742:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:13,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-08-02 21:38:13,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,852:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:13,852:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:13,852:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:13,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-08-02 21:38:13,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:13,967:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:13,967:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:13,967:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:14,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-02 21:38:14,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,094:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:14,094:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:14,094:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:14,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-08-02 21:38:14,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,229:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:14,229:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:14,229:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:14,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-02 21:38:14,327:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,327:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:14,328:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:14,328:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:14,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.
2024-08-02 21:38:14,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,420:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:14,421:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:14,421:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:14,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
2024-08-02 21:38:14,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,526:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:14,526:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:14,526:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:14,635:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2024-08-02 21:38:14,635:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,635:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:14,635:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:14,636:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:14,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-08-02 21:38:14,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,748:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:14,748:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:14,748:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:14,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2024-08-02 21:38:14,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,867:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:14,867:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:14,868:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:14,977:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-08-02 21:38:14,977:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:14,977:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:14,977:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:14,977:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,079:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-08-02 21:38:15,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,079:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:15,079:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:15,079:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-08-02 21:38:15,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,182:INFO:[LightGBM] [Info] Total Bins 1313
2024-08-02 21:38:15,182:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:15,183:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-08-02 21:38:15,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,322:INFO:[LightGBM] [Info] Total Bins 1271
2024-08-02 21:38:15,322:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:15,322:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-02 21:38:15,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,425:INFO:[LightGBM] [Info] Total Bins 1016
2024-08-02 21:38:15,425:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:15,426:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-02 21:38:15,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,533:INFO:[LightGBM] [Info] Total Bins 761
2024-08-02 21:38:15,533:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:15,534:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.
2024-08-02 21:38:15,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,651:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:15,651:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:15,651:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:15,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-08-02 21:38:15,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,754:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:15,755:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:15,755:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:15,858:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-08-02 21:38:15,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,859:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:15,859:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:15,859:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:15,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2024-08-02 21:38:15,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:15,964:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:15,965:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:15,965:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,068:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-08-02 21:38:16,068:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,068:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:38:16,069:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:16,069:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
2024-08-02 21:38:16,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,178:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:16,178:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:16,178:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,306:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-08-02 21:38:16,306:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,306:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:16,306:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:16,307:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-02 21:38:16,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,428:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:16,428:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:16,428:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-08-02 21:38:16,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,523:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:16,523:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:16,524:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,621:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.
2024-08-02 21:38:16,621:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,621:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:16,621:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:16,621:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.
2024-08-02 21:38:16,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,745:INFO:[LightGBM] [Info] Total Bins 510
2024-08-02 21:38:16,745:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 2
2024-08-02 21:38:16,746:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:16,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-08-02 21:38:16,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,876:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:16,876:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:16,876:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:16,985:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2024-08-02 21:38:16,985:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:16,985:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:16,986:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:16,986:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,091:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-08-02 21:38:17,091:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,091:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:17,091:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:17,092:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,198:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.
2024-08-02 21:38:17,198:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:17,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:17,199:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:38:17,199:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:17,199:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-08-02 21:38:17,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,333:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:38:17,333:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:17,333:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,458:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-02 21:38:17,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,458:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:17,458:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:17,459:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2024-08-02 21:38:17,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,577:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:17,577:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:17,577:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-02 21:38:17,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,678:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:17,678:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:38:17,678:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-02 21:38:17,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,782:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:17,782:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-08-02 21:38:17,783:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:17,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2024-08-02 21:38:17,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:17,912:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:17,912:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:17,913:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,020:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-08-02 21:38:18,020:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,020:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:18,021:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:18,021:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-08-02 21:38:18,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,126:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:18,126:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:18,126:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-08-02 21:38:18,245:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,245:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:18,245:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:18,245:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-08-02 21:38:18,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,351:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:38:18,351:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:18,352:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,464:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-02 21:38:18,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,465:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:18,465:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:18,465:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-02 21:38:18,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,596:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:18,596:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:18,596:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-08-02 21:38:18,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,693:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:18,694:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:38:18,694:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,799:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-08-02 21:38:18,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,799:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:18,799:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 3
2024-08-02 21:38:18,800:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:18,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2024-08-02 21:38:18,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:18,906:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:18,907:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:18,907:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2024-08-02 21:38:19,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,030:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:19,030:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:19,030:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2024-08-02 21:38:19,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,140:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:19,140:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:19,140:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,248:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2024-08-02 21:38:19,248:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,248:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:19,248:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:19,249:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.
2024-08-02 21:38:19,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,359:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:19,359:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:19,360:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-08-02 21:38:19,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,484:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:19,485:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:19,485:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-02 21:38:19,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,596:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:19,596:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:19,597:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-08-02 21:38:19,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,717:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:19,717:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:19,717:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-08-02 21:38:19,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,820:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:19,821:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:19,821:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:19,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-08-02 21:38:19,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:19,937:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:19,937:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:19,937:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2024-08-02 21:38:20,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,067:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:20,067:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:20,067:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-08-02 21:38:20,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,178:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:20,178:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:20,178:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2024-08-02 21:38:20,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,288:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:20,288:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:20,288:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2024-08-02 21:38:20,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,394:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:20,394:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:20,394:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,510:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2024-08-02 21:38:20,510:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,510:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:20,510:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:20,511:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-08-02 21:38:20,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,619:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:20,619:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:20,619:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2024-08-02 21:38:20,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,732:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:20,732:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:20,733:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,842:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-02 21:38:20,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,843:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:20,843:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:20,843:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:20,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2024-08-02 21:38:20,959:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:20,959:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:20,960:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:20,960:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2024-08-02 21:38:21,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,066:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:21,066:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:21,067:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2024-08-02 21:38:21,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,182:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:21,183:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:21,183:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2024-08-02 21:38:21,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,294:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:38:21,295:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:21,295:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:38:21,399:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,399:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:38:21,399:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:21,399:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-02 21:38:21,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,517:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:21,517:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:21,517:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,629:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-02 21:38:21,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,629:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:21,629:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:21,630:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-08-02 21:38:21,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,730:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:21,730:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:21,730:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.
2024-08-02 21:38:21,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,826:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:21,827:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:21,827:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:21,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:38:21,959:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:21,959:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:21,959:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:21,960:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.
2024-08-02 21:38:22,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,085:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:22,085:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:22,085:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,198:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2024-08-02 21:38:22,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,198:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:22,198:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:22,199:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.
2024-08-02 21:38:22,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,332:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:22,333:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:22,333:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-08-02 21:38:22,460:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,460:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:22,460:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:22,461:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-02 21:38:22,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,571:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:22,571:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:22,571:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
2024-08-02 21:38:22,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,717:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:22,717:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:22,717:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-08-02 21:38:22,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,849:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:22,850:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:22,851:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:22,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-08-02 21:38:22,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:22,954:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:22,954:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:22,954:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:23,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-08-02 21:38:23,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,074:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:23,075:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:23,075:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,180:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-08-02 21:38:23,180:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,180:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:23,180:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:23,180:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,285:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-08-02 21:38:23,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,286:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:23,286:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:23,286:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,411:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-08-02 21:38:23,411:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,411:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:23,411:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:23,411:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,530:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-08-02 21:38:23,530:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,530:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:23,530:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:23,531:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,647:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-08-02 21:38:23,647:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,647:INFO:[LightGBM] [Info] Total Bins 1312
2024-08-02 21:38:23,648:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:23,648:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2024-08-02 21:38:23,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,759:INFO:[LightGBM] [Info] Total Bins 1270
2024-08-02 21:38:23,759:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:23,760:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-02 21:38:23,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,858:INFO:[LightGBM] [Info] Total Bins 1015
2024-08-02 21:38:23,858:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:23,858:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:23,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-02 21:38:23,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:23,956:INFO:[LightGBM] [Info] Total Bins 760
2024-08-02 21:38:23,956:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:23,956:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:24,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-08-02 21:38:24,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,082:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:24,082:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:24,082:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,197:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-08-02 21:38:24,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,198:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:24,198:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:24,198:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,306:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2024-08-02 21:38:24,307:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,307:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:24,307:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:24,307:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-08-02 21:38:24,413:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,413:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:24,413:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:24,414:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.
2024-08-02 21:38:24,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,538:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:24,538:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:24,538:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-08-02 21:38:24,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,650:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:24,651:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:24,651:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,762:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-02 21:38:24,762:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,762:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:24,763:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:24,763:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,862:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-02 21:38:24,862:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,862:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:24,862:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:24,862:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:24,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-08-02 21:38:24,968:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:24,969:INFO:[LightGBM] [Info] Total Bins 763
2024-08-02 21:38:24,969:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:24,969:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:25,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2024-08-02 21:38:25,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,089:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:25,089:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:25,090:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,202:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2024-08-02 21:38:25,202:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,202:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:25,202:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:25,203:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-08-02 21:38:25,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,313:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:25,313:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:25,314:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,419:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-08-02 21:38:25,419:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,419:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:25,420:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:25,420:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2024-08-02 21:38:25,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,534:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:25,534:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:25,534:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-08-02 21:38:25,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,684:INFO:[LightGBM] [Info] Total Bins 1313
2024-08-02 21:38:25,685:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:25,685:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,798:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-08-02 21:38:25,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,799:INFO:[LightGBM] [Info] Total Bins 1271
2024-08-02 21:38:25,799:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:25,799:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:25,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.
2024-08-02 21:38:25,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:25,903:INFO:[LightGBM] [Info] Total Bins 1016
2024-08-02 21:38:25,903:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:25,903:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:26,002:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.
2024-08-02 21:38:26,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,003:INFO:[LightGBM] [Info] Total Bins 761
2024-08-02 21:38:26,003:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:26,003:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:26,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-08-02 21:38:26,121:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,121:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:26,122:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:26,122:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-08-02 21:38:26,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,231:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:26,231:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:26,232:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2024-08-02 21:38:26,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,354:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:26,354:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:26,354:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-08-02 21:38:26,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,472:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:38:26,472:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:26,473:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2024-08-02 21:38:26,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,578:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:26,578:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:26,579:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-08-02 21:38:26,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,691:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:26,692:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:26,692:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-08-02 21:38:26,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,821:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:26,822:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:26,822:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:26,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-02 21:38:26,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:26,921:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:26,921:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:26,921:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:27,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-08-02 21:38:27,018:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,018:INFO:[LightGBM] [Info] Total Bins 762
2024-08-02 21:38:27,019:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 3
2024-08-02 21:38:27,019:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:27,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-08-02 21:38:27,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,136:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:27,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:27,136:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-08-02 21:38:27,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,254:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:27,255:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:27,255:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,371:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:38:27,371:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,371:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:27,372:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:27,372:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2024-08-02 21:38:27,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,494:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:38:27,494:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:27,494:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-08-02 21:38:27,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,601:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:38:27,601:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:27,601:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,709:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
2024-08-02 21:38:27,709:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,709:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:27,709:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:27,710:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-02 21:38:27,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,822:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:27,822:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:27,822:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:27,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-08-02 21:38:27,931:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:27,931:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:27,932:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:38:27,932:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:28,039:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:38:28,040:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,040:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:28,040:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:28,040:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,147:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2024-08-02 21:38:28,147:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,147:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:28,147:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:28,147:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-08-02 21:38:28,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,257:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:28,257:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:28,257:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.
2024-08-02 21:38:28,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,365:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:28,365:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:28,365:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-08-02 21:38:28,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,472:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:38:28,472:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:28,472:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-08-02 21:38:28,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,601:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:28,601:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:28,602:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-02 21:38:28,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,718:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:28,718:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:28,719:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-08-02 21:38:28,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,819:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:28,819:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 4
2024-08-02 21:38:28,819:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:28,927:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2024-08-02 21:38:28,927:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:28,927:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:28,927:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:28,928:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,047:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2024-08-02 21:38:29,047:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,047:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:29,047:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:29,048:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-08-02 21:38:29,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,163:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:29,163:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:29,164:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2024-08-02 21:38:29,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,296:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:29,296:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:29,297:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,405:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-08-02 21:38:29,405:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,405:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:29,406:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:29,406:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-08-02 21:38:29,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,515:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:29,516:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:29,516:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-08-02 21:38:29,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,636:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:29,636:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:29,637:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,750:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-02 21:38:29,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,750:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:29,751:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:29,751:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:29,866:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-08-02 21:38:29,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,866:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:29,866:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:29,866:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:29,975:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2024-08-02 21:38:29,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:29,976:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:29,976:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:29,976:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-08-02 21:38:30,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,116:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:30,116:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:30,116:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2024-08-02 21:38:30,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,226:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:30,226:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:30,227:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-08-02 21:38:30,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,334:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:30,334:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:30,334:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-02 21:38:30,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:30,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:30,465:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:30,465:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:30,466:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,609:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-08-02 21:38:30,609:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,609:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:30,609:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:30,610:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
2024-08-02 21:38:30,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,711:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:30,711:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:30,711:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:30,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-08-02 21:38:30,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,857:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:30,857:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:30,857:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:30,967:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2024-08-02 21:38:30,967:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:30,967:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:30,968:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:30,968:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,079:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2024-08-02 21:38:31,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,079:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:31,080:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:31,080:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-08-02 21:38:31,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,217:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:38:31,217:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:31,217:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,322:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-08-02 21:38:31,323:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,323:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:38:31,323:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:31,323:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-08-02 21:38:31,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,444:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:31,444:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:31,445:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-02 21:38:31,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,568:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:31,568:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:31,568:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,666:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2024-08-02 21:38:31,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,666:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:31,666:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:31,667:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:31,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2024-08-02 21:38:31,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,772:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:31,773:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:31,773:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:31,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-08-02 21:38:31,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:31,894:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:31,894:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:31,895:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-08-02 21:38:32,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,077:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:32,077:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:32,077:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-08-02 21:38:32,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,184:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:32,185:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:32,185:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-08-02 21:38:32,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,311:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:32,311:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:32,311:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:32,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,440:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:32,441:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:32,441:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-02 21:38:32,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,576:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:32,577:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:32,577:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-08-02 21:38:32,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,686:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:32,687:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:32,687:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:32,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2024-08-02 21:38:32,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,810:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:32,810:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:32,810:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:32,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2024-08-02 21:38:32,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:32,928:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:32,928:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:32,928:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-08-02 21:38:33,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,066:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:33,067:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:33,067:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-08-02 21:38:33,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,203:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:33,204:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:33,204:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-08-02 21:38:33,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,308:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:33,309:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:33,309:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-02 21:38:33,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,443:INFO:[LightGBM] [Info] Total Bins 1312
2024-08-02 21:38:33,443:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:33,443:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-02 21:38:33,585:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,585:INFO:[LightGBM] [Info] Total Bins 1270
2024-08-02 21:38:33,585:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:33,585:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-02 21:38:33,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,683:INFO:[LightGBM] [Info] Total Bins 1015
2024-08-02 21:38:33,683:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:33,683:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:33,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-08-02 21:38:33,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,797:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:33,797:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:33,797:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:33,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2024-08-02 21:38:33,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:33,952:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:33,952:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:33,952:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,079:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:38:34,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,079:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:34,079:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:34,079:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:38:34,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,197:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:34,197:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:34,197:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,319:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-08-02 21:38:34,319:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,320:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:34,320:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:34,320:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:38:34,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,434:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:34,434:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:34,434:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-02 21:38:34,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,562:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:34,562:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:34,563:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,670:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-02 21:38:34,670:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,671:INFO:[LightGBM] [Info] Total Bins 1018
2024-08-02 21:38:34,671:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:34,671:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:34,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-08-02 21:38:34,803:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,803:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:34,803:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:34,803:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:34,911:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-08-02 21:38:34,911:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:34,911:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:34,911:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:34,911:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.
2024-08-02 21:38:35,035:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,035:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:35,035:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:35,035:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,214:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2024-08-02 21:38:35,214:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,214:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:35,215:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:35,215:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-08-02 21:38:35,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,326:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:35,326:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:35,326:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-02 21:38:35,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,442:INFO:[LightGBM] [Info] Total Bins 1313
2024-08-02 21:38:35,442:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:35,442:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,565:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:38:35,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,566:INFO:[LightGBM] [Info] Total Bins 1271
2024-08-02 21:38:35,566:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:35,567:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,676:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.
2024-08-02 21:38:35,676:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,677:INFO:[LightGBM] [Info] Total Bins 1016
2024-08-02 21:38:35,677:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:35,677:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:35,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.
2024-08-02 21:38:35,793:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,793:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:35,793:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:35,793:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:35,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-08-02 21:38:35,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:35,925:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:35,926:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:35,926:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-08-02 21:38:36,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,034:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:36,034:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:36,034:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:38:36,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,145:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:38:36,145:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:36,145:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-08-02 21:38:36,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,274:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:36,275:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:36,275:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-08-02 21:38:36,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,394:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:36,394:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:36,394:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-02 21:38:36,502:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,502:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:36,503:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:36,503:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-02 21:38:36,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,608:INFO:[LightGBM] [Info] Total Bins 1017
2024-08-02 21:38:36,608:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 4
2024-08-02 21:38:36,608:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:36,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2024-08-02 21:38:36,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,741:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:36,741:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:36,741:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:36,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:36,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,848:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:36,848:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:36,848:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:36,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-08-02 21:38:36,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:36,956:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:36,956:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:36,956:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:37,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-08-02 21:38:37,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,065:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:38:37,065:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:37,065:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:37,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.
2024-08-02 21:38:37,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,187:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:38:37,187:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:37,187:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:37,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-02 21:38:37,302:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,302:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:37,302:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:37,303:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:37,424:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-08-02 21:38:37,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,424:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:37,424:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:37,425:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:37,539:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-08-02 21:38:37,539:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,539:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:37,539:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:37,539:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:37,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-08-02 21:38:37,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,675:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:37,675:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:37,675:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:37,800:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-08-02 21:38:37,800:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,800:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:37,801:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:37,801:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:37,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-08-02 21:38:37,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:37,917:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:37,917:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:37,917:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:38,025:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
2024-08-02 21:38:38,025:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,026:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:38:38,026:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:38,026:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:38,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2024-08-02 21:38:38,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,152:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:38,152:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:38,152:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:38,269:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-02 21:38:38,269:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,269:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:38,269:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 5
2024-08-02 21:38:38,269:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:38,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2024-08-02 21:38:38,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,379:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:38,379:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:38,379:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:38,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-08-02 21:38:38,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,495:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:38,495:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:38,495:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:38,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-08-02 21:38:38,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,631:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:38,631:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:38,631:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:38,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
2024-08-02 21:38:38,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,749:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:38,749:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:38,749:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:38,855:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2024-08-02 21:38:38,855:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,855:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:38,855:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:38,856:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:38,993:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-08-02 21:38:38,993:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:38,993:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:38,994:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:38,994:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:39,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-02 21:38:39,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,110:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:39,110:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:39,110:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:39,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:38:39,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,229:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:39,229:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:39,229:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:39,335:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-08-02 21:38:39,335:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,335:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:39,336:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:39,336:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:39,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-08-02 21:38:39,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,454:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:39,454:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:39,454:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:39,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-08-02 21:38:39,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,562:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:39,562:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:39,562:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:39,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-08-02 21:38:39,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,686:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:39,686:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:39,686:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:39,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-02 21:38:39,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,796:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:39,796:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:39,797:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:39,911:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-02 21:38:39,911:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:39,911:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:39,911:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:39,912:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:40,047:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
2024-08-02 21:38:40,047:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,047:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:40,047:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:40,048:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-08-02 21:38:40,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,203:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:40,204:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:40,204:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:38:40,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,343:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:40,343:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:40,344:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2024-08-02 21:38:40,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,466:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:38:40,467:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:40,467:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,613:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-08-02 21:38:40,614:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,614:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:38:40,614:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:40,614:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-08-02 21:38:40,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,740:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:40,740:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:40,741:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-02 21:38:40,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,851:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:40,852:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:40,852:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:40,993:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-08-02 21:38:40,993:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:40,993:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:40,993:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:40,994:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2024-08-02 21:38:41,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,135:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:41,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:41,136:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-08-02 21:38:41,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,279:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:41,280:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:41,280:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2024-08-02 21:38:41,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,410:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:41,410:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:41,410:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2024-08-02 21:38:41,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,547:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:41,547:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:41,548:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-08-02 21:38:41,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,678:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:41,678:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:41,679:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-08-02 21:38:41,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,787:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:41,787:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:41,788:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:41,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2024-08-02 21:38:41,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:41,916:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:41,916:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:41,917:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-08-02 21:38:42,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,024:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:42,025:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:42,025:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000616 seconds.
2024-08-02 21:38:42,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,134:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:42,134:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:42,135:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-08-02 21:38:42,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,257:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:42,258:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:42,258:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2024-08-02 21:38:42,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,376:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:42,377:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:42,377:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,496:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-02 21:38:42,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,497:INFO:[LightGBM] [Info] Total Bins 1312
2024-08-02 21:38:42,497:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:42,497:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-02 21:38:42,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,639:INFO:[LightGBM] [Info] Total Bins 1270
2024-08-02 21:38:42,640:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:42,640:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:42,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-08-02 21:38:42,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,772:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:42,773:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:42,773:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:42,895:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-08-02 21:38:42,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:42,895:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:42,896:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:42,896:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:43,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.
2024-08-02 21:38:43,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,060:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:43,061:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:43,061:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:43,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-08-02 21:38:43,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,183:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:43,183:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:43,183:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:43,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2024-08-02 21:38:43,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,312:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:43,312:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:43,312:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:43,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-02 21:38:43,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,443:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:43,443:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:43,443:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:43,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-08-02 21:38:43,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,550:INFO:[LightGBM] [Info] Total Bins 1273
2024-08-02 21:38:43,551:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:43,551:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:43,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2024-08-02 21:38:43,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,669:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:43,669:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:43,670:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:43,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-08-02 21:38:43,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,785:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:43,785:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:43,786:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:43,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-08-02 21:38:43,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:43,987:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:43,987:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:43,988:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:44,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-08-02 21:38:44,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,113:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:44,114:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:44,114:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:44,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-08-02 21:38:44,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,223:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:44,224:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:44,224:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:44,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.
2024-08-02 21:38:44,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,338:INFO:[LightGBM] [Info] Total Bins 1313
2024-08-02 21:38:44,338:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:44,339:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:44,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-02 21:38:44,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,454:INFO:[LightGBM] [Info] Total Bins 1271
2024-08-02 21:38:44,454:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:44,454:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:44,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:38:44,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,580:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:44,580:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:44,581:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:44,690:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2024-08-02 21:38:44,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,691:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:44,691:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:44,691:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:44,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-08-02 21:38:44,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,811:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:44,811:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:44,812:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:44,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-08-02 21:38:44,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:44,924:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:38:44,925:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:44,925:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:45,033:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2024-08-02 21:38:45,033:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,033:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:45,033:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:45,034:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:45,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-08-02 21:38:45,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,156:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:45,156:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:45,157:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:45,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-08-02 21:38:45,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,283:INFO:[LightGBM] [Info] Total Bins 1272
2024-08-02 21:38:45,284:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 5
2024-08-02 21:38:45,284:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:45,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
2024-08-02 21:38:45,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,410:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:45,410:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:45,411:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:45,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-08-02 21:38:45,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,525:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:45,525:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:45,525:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:45,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.
2024-08-02 21:38:45,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,649:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:45,649:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:45,650:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:45,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-08-02 21:38:45,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,760:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:38:45,760:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:45,760:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:45,866:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2024-08-02 21:38:45,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,866:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:38:45,867:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:45,867:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:45,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-08-02 21:38:45,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:45,978:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:45,978:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:45,979:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:46,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-08-02 21:38:46,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,088:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:46,088:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:46,088:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:46,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
2024-08-02 21:38:46,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,199:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:46,200:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:46,200:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:46,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2024-08-02 21:38:46,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,326:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:46,326:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:46,326:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:46,431:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-08-02 21:38:46,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,432:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:46,432:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:46,432:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:46,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-08-02 21:38:46,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,537:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:38:46,537:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:46,538:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:46,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2024-08-02 21:38:46,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,645:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:46,645:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 6
2024-08-02 21:38:46,645:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:46,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2024-08-02 21:38:46,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,790:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:46,790:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:46,790:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:46,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-08-02 21:38:46,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:46,898:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:46,898:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:46,898:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:47,007:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-08-02 21:38:47,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,008:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:47,008:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:47,008:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:47,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-08-02 21:38:47,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,114:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:47,114:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:47,114:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:47,220:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-08-02 21:38:47,220:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,220:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:47,220:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:47,221:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:47,326:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-02 21:38:47,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,326:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:47,326:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:47,327:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:47,457:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-08-02 21:38:47,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,458:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:47,458:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:47,458:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:47,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-08-02 21:38:47,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,563:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:47,564:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:47,564:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:47,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-08-02 21:38:47,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,691:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:47,692:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:47,692:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:47,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
2024-08-02 21:38:47,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,829:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:47,829:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:47,830:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:47,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-08-02 21:38:47,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:47,942:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:47,942:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:47,942:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:48,048:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-08-02 21:38:48,048:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,048:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:48,048:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:48,049:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:48,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-08-02 21:38:48,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,160:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:48,160:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:48,161:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:48,272:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:38:48,272:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,272:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:48,273:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:48,273:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:48,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-08-02 21:38:48,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,406:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:48,406:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:48,407:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:48,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-08-02 21:38:48,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,540:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:38:48,540:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:48,541:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:48,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-08-02 21:38:48,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,643:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:38:48,644:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:48,644:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:48,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-02 21:38:48,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,760:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:48,760:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:48,761:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:48,905:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2024-08-02 21:38:48,905:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:48,905:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:48,905:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:48,906:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:49,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-08-02 21:38:49,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,026:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:49,027:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:49,027:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:49,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-08-02 21:38:49,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,146:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:49,147:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:49,147:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:49,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-08-02 21:38:49,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,253:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:49,253:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:49,253:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:49,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-08-02 21:38:49,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,366:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:49,366:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:49,367:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:49,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-08-02 21:38:49,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,493:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:49,493:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:49,494:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:49,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2024-08-02 21:38:49,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,623:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:49,624:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:49,624:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:49,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-08-02 21:38:49,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:49,759:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:49,759:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:49,760:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:49,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2024-08-02 21:38:49,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:49,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:49,898:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:49,899:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:49,899:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:50,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-08-02 21:38:50,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,070:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:50,070:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:50,071:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:50,208:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-08-02 21:38:50,208:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,208:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:50,208:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:50,209:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:50,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2024-08-02 21:38:50,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,346:INFO:[LightGBM] [Info] Total Bins 1312
2024-08-02 21:38:50,346:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:50,346:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:50,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2024-08-02 21:38:50,485:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,485:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:50,485:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:50,485:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:50,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2024-08-02 21:38:50,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,612:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:50,613:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:50,613:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:50,751:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-08-02 21:38:50,751:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,751:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:50,752:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:50,752:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:50,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-08-02 21:38:50,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:50,885:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:50,885:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:50,886:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:51,003:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.
2024-08-02 21:38:51,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,003:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:51,004:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:51,004:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:51,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-02 21:38:51,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,136:INFO:[LightGBM] [Info] Total Bins 1315
2024-08-02 21:38:51,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:51,136:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:51,349:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
2024-08-02 21:38:51,349:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,349:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:51,349:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:51,350:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:51,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-08-02 21:38:51,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,475:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:51,475:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:51,476:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:51,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2024-08-02 21:38:51,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,591:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:51,591:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:51,591:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:51,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2024-08-02 21:38:51,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,737:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:51,738:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:51,738:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:51,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-08-02 21:38:51,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:51,878:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:51,878:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:51,879:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:52,000:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-02 21:38:52,000:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,000:INFO:[LightGBM] [Info] Total Bins 1313
2024-08-02 21:38:52,000:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:52,001:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:52,135:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2024-08-02 21:38:52,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,136:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:52,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:52,137:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:52,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-08-02 21:38:52,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,282:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:52,282:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:52,283:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:52,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-08-02 21:38:52,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,430:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:52,430:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:52,430:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:52,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-08-02 21:38:52,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,650:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:38:52,651:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:52,651:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:52,798:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-08-02 21:38:52,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,799:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:52,799:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:52,799:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:52,938:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-02 21:38:52,939:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:52,939:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:38:52,939:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 6
2024-08-02 21:38:52,939:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:53,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-08-02 21:38:53,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,069:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:53,069:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:53,070:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:53,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:53,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,200:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:53,200:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:53,200:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:53,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
2024-08-02 21:38:53,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,326:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:53,326:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:53,326:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:53,457:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-08-02 21:38:53,457:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,458:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:38:53,458:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:53,458:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:53,588:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-08-02 21:38:53,588:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,588:INFO:[LightGBM] [Info] Total Bins 1331
2024-08-02 21:38:53,588:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:53,589:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:38:53,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2024-08-02 21:38:53,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,770:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:53,771:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:38:53,771:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:53,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-08-02 21:38:53,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:53,893:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:53,893:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:38:53,893:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:54,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-08-02 21:38:54,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,008:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:54,008:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:38:54,009:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:54,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-08-02 21:38:54,125:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,125:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:54,125:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:38:54,125:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:54,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2024-08-02 21:38:54,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,246:INFO:[LightGBM] [Info] Total Bins 1341
2024-08-02 21:38:54,246:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 7
2024-08-02 21:38:54,246:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:38:54,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2024-08-02 21:38:54,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,427:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:54,428:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:54,428:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:54,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-08-02 21:38:54,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,629:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:54,629:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:54,629:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:54,771:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-08-02 21:38:54,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,772:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:54,772:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:54,772:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:54,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-08-02 21:38:54,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:54,912:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:54,913:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:54,913:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:55,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:38:55,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:55,079:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:55,079:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:55,079:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:38:55,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
2024-08-02 21:38:55,300:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:55,300:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:55,300:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:55,352:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:55,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-08-02 21:38:55,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:55,528:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:55,528:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:55,529:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:55,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-08-02 21:38:55,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:55,679:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:55,680:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:55,680:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:55,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-08-02 21:38:55,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:55,810:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:55,810:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:55,811:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:55,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:55,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:55,943:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:38:55,944:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:55,944:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:38:56,075:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:38:56,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:56,075:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:56,075:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:56,075:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:56,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2024-08-02 21:38:56,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:56,199:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:56,200:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:56,200:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:56,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-08-02 21:38:56,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:56,343:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:56,344:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:56,344:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:56,511:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2024-08-02 21:38:56,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:56,511:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:38:56,511:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:56,512:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:56,632:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.
2024-08-02 21:38:56,632:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:56,632:INFO:[LightGBM] [Info] Total Bins 1342
2024-08-02 21:38:56,632:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:56,632:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:38:56,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-08-02 21:38:56,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:38:56,769:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:38:56,769:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:56,770:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:56,770:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:56,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-08-02 21:38:56,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:56,970:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:56,970:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:56,970:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:57,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-08-02 21:38:57,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,113:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:57,113:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:57,113:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:57,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2024-08-02 21:38:57,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,246:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:38:57,247:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:57,247:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:57,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-08-02 21:38:57,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,396:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:57,396:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:57,396:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:38:57,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2024-08-02 21:38:57,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,550:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:38:57,550:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:57,551:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:57,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2024-08-02 21:38:57,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,687:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:38:57,687:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:57,688:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:57,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:38:57,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,821:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:38:57,821:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:57,822:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:57,981:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-08-02 21:38:57,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:57,981:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:38:57,981:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:57,981:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:58,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-02 21:38:58,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,139:INFO:[LightGBM] [Info] Total Bins 1344
2024-08-02 21:38:58,140:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:58,140:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:38:58,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000576 seconds.
2024-08-02 21:38:58,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,282:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:38:58,282:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:58,282:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:58,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2024-08-02 21:38:58,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,421:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:38:58,421:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:58,421:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:58,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2024-08-02 21:38:58,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,563:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:38:58,563:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:58,564:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:58,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-08-02 21:38:58,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,686:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:38:58,686:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:58,686:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:58,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-08-02 21:38:58,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,804:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:38:58,805:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:58,805:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:38:58,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
2024-08-02 21:38:58,930:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:58,930:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:38:58,930:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:58,931:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:59,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2024-08-02 21:38:59,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,066:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:38:59,066:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:59,067:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:59,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009663 seconds.
2024-08-02 21:38:59,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,231:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:38:59,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:59,232:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:59,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2024-08-02 21:38:59,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,373:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:38:59,373:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:38:59,373:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:59,500:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-08-02 21:38:59,500:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,501:INFO:[LightGBM] [Info] Total Bins 1345
2024-08-02 21:38:59,501:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:38:59,501:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:38:59,635:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2024-08-02 21:38:59,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,636:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:38:59,636:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:38:59,636:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:59,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-08-02 21:38:59,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,765:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:38:59,765:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:38:59,766:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:38:59,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-08-02 21:38:59,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:38:59,887:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:38:59,887:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:38:59,887:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:00,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-08-02 21:39:00,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,006:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:39:00,006:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:00,006:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:00,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2024-08-02 21:39:00,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,148:INFO:[LightGBM] [Info] Total Bins 1346
2024-08-02 21:39:00,148:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 7
2024-08-02 21:39:00,148:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:00,276:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2024-08-02 21:39:00,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,276:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:00,277:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:00,277:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:00,402:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-08-02 21:39:00,402:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,402:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:00,403:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:39:00,403:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:00,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-08-02 21:39:00,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,532:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:00,532:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:39:00,532:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:00,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-08-02 21:39:00,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,664:INFO:[LightGBM] [Info] Total Bins 1358
2024-08-02 21:39:00,664:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:39:00,664:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:00,803:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:39:00,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,804:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:00,804:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:00,804:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:00,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-08-02 21:39:00,930:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:00,930:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:00,930:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:39:00,931:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:01,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2024-08-02 21:39:01,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,060:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:01,061:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:39:01,061:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:01,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-08-02 21:39:01,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,192:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:39:01,192:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 8
2024-08-02 21:39:01,192:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:01,322:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2024-08-02 21:39:01,322:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,322:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:01,322:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:01,323:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:01,441:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-08-02 21:39:01,441:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,442:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:01,442:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:01,442:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:01,565:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2024-08-02 21:39:01,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,566:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:01,566:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:01,566:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:01,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2024-08-02 21:39:01,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,703:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:39:01,703:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:01,704:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:01,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.
2024-08-02 21:39:01,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:01,840:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:01,841:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:01,841:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:02,025:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-08-02 21:39:02,025:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,025:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:39:02,026:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:02,026:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:02,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-08-02 21:39:02,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,155:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:39:02,155:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:02,155:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:02,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:39:02,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,292:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:39:02,293:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:02,293:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:02,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-08-02 21:39:02,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,454:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:02,454:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:02,455:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:02,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-08-02 21:39:02,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,577:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:39:02,577:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:02,578:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:02,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2024-08-02 21:39:02,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,712:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:02,713:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:02,713:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:02,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2024-08-02 21:39:02,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:02,857:INFO:[LightGBM] [Info] Total Bins 1375
2024-08-02 21:39:02,857:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:02,858:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:03,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2024-08-02 21:39:03,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:03,019:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:03,019:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:03,020:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:03,172:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-08-02 21:39:03,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:03,172:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:03,172:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:03,172:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:03,320:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2024-08-02 21:39:03,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:03,321:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:03,321:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:03,321:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:03,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-08-02 21:39:03,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:03,490:INFO:[LightGBM] [Info] Total Bins 1374
2024-08-02 21:39:03,490:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:03,491:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:03,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
2024-08-02 21:39:03,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:03,651:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:39:03,652:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:03,652:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:03,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-08-02 21:39:03,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:03,775:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:39:03,775:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:03,776:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:03,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:39:03,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-02 21:39:03,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-02 21:39:03,899:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:39:03,899:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:03,900:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:04,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2024-08-02 21:39:04,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:04,118:INFO:[LightGBM] [Info] Total Bins 1360
2024-08-02 21:39:04,119:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:04,119:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:04,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2024-08-02 21:39:04,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:04,249:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:04,250:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:04,250:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:04,400:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2024-08-02 21:39:04,400:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:04,400:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:04,400:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:04,401:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:04,567:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2024-08-02 21:39:04,567:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:04,567:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:04,567:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:04,568:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:04,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-08-02 21:39:04,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:04,689:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:39:04,689:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:04,689:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:04,824:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2024-08-02 21:39:04,824:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:04,825:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:04,825:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:04,825:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:05,010:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-08-02 21:39:05,010:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,010:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:39:05,010:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:05,011:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:05,150:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-08-02 21:39:05,150:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,150:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:39:05,150:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:05,151:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:05,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-08-02 21:39:05,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,296:INFO:[LightGBM] [Info] Total Bins 1361
2024-08-02 21:39:05,296:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:05,297:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:05,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-08-02 21:39:05,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,428:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:05,429:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:05,429:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:05,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-08-02 21:39:05,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,558:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:39:05,558:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:05,558:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:05,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2024-08-02 21:39:05,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,692:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:39:05,692:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:05,693:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:05,814:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-08-02 21:39:05,814:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,814:INFO:[LightGBM] [Info] Total Bins 1373
2024-08-02 21:39:05,814:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 8
2024-08-02 21:39:05,814:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:05,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-08-02 21:39:05,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:05,945:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:05,945:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:05,946:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:06,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-08-02 21:39:06,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,070:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:06,071:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:39:06,071:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:06,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-08-02 21:39:06,193:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,193:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:06,194:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:39:06,194:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:06,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2024-08-02 21:39:06,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,355:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:06,355:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:06,355:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:06,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2024-08-02 21:39:06,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,480:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:06,480:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:39:06,481:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:06,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-08-02 21:39:06,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,601:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:06,601:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 9
2024-08-02 21:39:06,602:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:06,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2024-08-02 21:39:06,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,729:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:06,730:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:06,730:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:06,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-08-02 21:39:06,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:06,868:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:06,868:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:06,868:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:07,009:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-08-02 21:39:07,009:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,009:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:07,009:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:07,009:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:07,159:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2024-08-02 21:39:07,159:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,159:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:07,159:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:07,159:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:07,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:39:07,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,295:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:39:07,296:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:07,296:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:07,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-08-02 21:39:07,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,436:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:39:07,437:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:07,437:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:07,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2024-08-02 21:39:07,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,579:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:07,579:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:07,580:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:07,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2024-08-02 21:39:07,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,717:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:39:07,718:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:07,718:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:07,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.
2024-08-02 21:39:07,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,858:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:07,858:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:07,858:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:07,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-08-02 21:39:07,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:07,995:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:07,995:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:07,995:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:08,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2024-08-02 21:39:08,121:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,122:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:08,122:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:08,122:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:08,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-08-02 21:39:08,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,231:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:08,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:08,232:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:08,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-08-02 21:39:08,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,346:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:39:08,346:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:08,346:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:08,458:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-08-02 21:39:08,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,458:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:39:08,458:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:08,459:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:08,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-08-02 21:39:08,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,579:INFO:[LightGBM] [Info] Total Bins 1387
2024-08-02 21:39:08,579:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:08,580:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:08,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-08-02 21:39:08,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,695:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:08,695:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:08,696:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:08,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-08-02 21:39:08,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,804:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:08,805:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:08,805:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:08,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-08-02 21:39:08,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:08,925:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:08,925:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:08,925:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:09,056:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-02 21:39:09,056:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,057:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:09,057:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:09,057:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:09,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-08-02 21:39:09,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,163:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:39:09,164:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:09,164:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:09,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2024-08-02 21:39:09,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,274:INFO:[LightGBM] [Info] Total Bins 1388
2024-08-02 21:39:09,274:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:09,274:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:09,387:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-08-02 21:39:09,387:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,387:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:09,387:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:09,387:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:09,489:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2024-08-02 21:39:09,489:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,489:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:39:09,490:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:09,490:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:09,602:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2024-08-02 21:39:09,602:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,602:INFO:[LightGBM] [Info] Total Bins 1389
2024-08-02 21:39:09,602:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 9
2024-08-02 21:39:09,603:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:09,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-08-02 21:39:09,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,723:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:09,723:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:09,723:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:09,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-08-02 21:39:09,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,831:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:09,831:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:39:09,831:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:09,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
2024-08-02 21:39:09,944:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:09,944:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:09,944:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:09,944:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:10,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2024-08-02 21:39:10,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,064:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:10,065:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 10
2024-08-02 21:39:10,065:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:10,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
2024-08-02 21:39:10,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,252:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:10,252:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:10,253:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:10,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-08-02 21:39:10,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,363:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:10,363:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:10,363:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:10,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-08-02 21:39:10,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,479:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:10,479:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:10,480:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:10,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.
2024-08-02 21:39:10,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,581:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:39:10,582:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:10,582:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:10,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
2024-08-02 21:39:10,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,703:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:10,703:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:10,704:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:10,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
2024-08-02 21:39:10,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,811:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:39:10,811:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:10,812:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:10,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-08-02 21:39:10,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:10,941:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:10,941:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:10,941:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:11,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-08-02 21:39:11,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,055:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:11,056:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:11,056:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:11,174:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2024-08-02 21:39:11,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,174:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:39:11,174:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:11,174:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:11,309:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
2024-08-02 21:39:11,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,310:INFO:[LightGBM] [Info] Total Bins 1406
2024-08-02 21:39:11,310:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:11,310:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:11,457:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2024-08-02 21:39:11,457:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,458:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:11,458:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:11,458:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:11,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-08-02 21:39:11,588:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,588:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:11,588:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:11,588:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:11,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.
2024-08-02 21:39:11,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,701:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:11,701:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:11,702:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:11,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2024-08-02 21:39:11,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,811:INFO:[LightGBM] [Info] Total Bins 1407
2024-08-02 21:39:11,811:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:11,812:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:11,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.
2024-08-02 21:39:11,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:11,934:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:11,934:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:11,934:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:12,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-02 21:39:12,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,039:INFO:[LightGBM] [Info] Total Bins 1408
2024-08-02 21:39:12,039:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 10
2024-08-02 21:39:12,039:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:12,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-08-02 21:39:12,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,162:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:12,162:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:12,163:INFO:[LightGBM] [Info] Start training from score 6.623098
2024-08-02 21:39:12,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.
2024-08-02 21:39:12,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,282:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:12,282:INFO:[LightGBM] [Info] Number of data points in the train set: 5581, number of used features: 11
2024-08-02 21:39:12,282:INFO:[LightGBM] [Info] Start training from score 6.618660
2024-08-02 21:39:12,411:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2024-08-02 21:39:12,411:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,412:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:12,412:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:12,412:INFO:[LightGBM] [Info] Start training from score 6.625061
2024-08-02 21:39:12,553:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2024-08-02 21:39:12,553:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,553:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:12,553:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:12,554:INFO:[LightGBM] [Info] Start training from score 6.631430
2024-08-02 21:39:12,690:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2024-08-02 21:39:12,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,691:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:12,691:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:12,691:INFO:[LightGBM] [Info] Start training from score 6.627465
2024-08-02 21:39:12,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2024-08-02 21:39:12,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,811:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:12,811:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:12,812:INFO:[LightGBM] [Info] Start training from score 6.621315
2024-08-02 21:39:12,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2024-08-02 21:39:12,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:12,946:INFO:[LightGBM] [Info] Total Bins 1414
2024-08-02 21:39:12,947:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:12,947:INFO:[LightGBM] [Info] Start training from score 6.628941
2024-08-02 21:39:13,075:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2024-08-02 21:39:13,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,075:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:13,075:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:13,076:INFO:[LightGBM] [Info] Start training from score 6.627949
2024-08-02 21:39:13,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-08-02 21:39:13,192:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,192:INFO:[LightGBM] [Info] Total Bins 1415
2024-08-02 21:39:13,192:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:13,192:INFO:[LightGBM] [Info] Start training from score 6.628891
2024-08-02 21:39:13,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2024-08-02 21:39:13,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,308:INFO:[LightGBM] [Info] Total Bins 1416
2024-08-02 21:39:13,308:INFO:[LightGBM] [Info] Number of data points in the train set: 5582, number of used features: 11
2024-08-02 21:39:13,309:INFO:[LightGBM] [Info] Start training from score 6.626863
2024-08-02 21:39:13,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-08-02 21:39:13,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,428:INFO:[LightGBM] [Info] Total Bins 1417
2024-08-02 21:39:13,428:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 11
2024-08-02 21:39:13,428:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:39:13,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-08-02 21:39:13,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,558:INFO:[LightGBM] [Info] Total Bins 1409
2024-08-02 21:39:13,558:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 10
2024-08-02 21:39:13,559:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:39:13,668:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-08-02 21:39:13,668:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,668:INFO:[LightGBM] [Info] Total Bins 1390
2024-08-02 21:39:13,668:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 9
2024-08-02 21:39:13,669:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:39:13,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-08-02 21:39:13,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,786:INFO:[LightGBM] [Info] Total Bins 1363
2024-08-02 21:39:13,786:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 8
2024-08-02 21:39:13,786:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:39:13,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-08-02 21:39:13,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:13,894:INFO:[LightGBM] [Info] Total Bins 1347
2024-08-02 21:39:13,894:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 7
2024-08-02 21:39:13,894:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:39:14,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
2024-08-02 21:39:14,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 21:39:14,006:INFO:[LightGBM] [Info] Total Bins 1314
2024-08-02 21:39:14,006:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 6
2024-08-02 21:39:14,006:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 21:39:14,307:INFO:Visual Rendered Successfully
2024-08-02 21:39:14,556:INFO:plot_model() successfully completed......................................
2024-08-02 21:39:14,663:INFO:Initializing plot_model()
2024-08-02 21:39:14,663:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B974979D00>, system=True)
2024-08-02 21:39:14,663:INFO:Checking exceptions
2024-08-02 21:39:14,667:INFO:Preloading libraries
2024-08-02 21:39:14,681:INFO:Copying training dataset
2024-08-02 21:39:14,681:INFO:Plot type: feature
2024-08-02 21:39:14,681:WARNING:No coef_ found. Trying feature_importances_
2024-08-02 21:39:14,943:INFO:Visual Rendered Successfully
2024-08-02 21:39:15,178:INFO:plot_model() successfully completed......................................
2024-08-02 23:07:32,653:WARNING:C:\Users\chima\AppData\Local\Temp\ipykernel_6200\1382177597.py:5: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = new_df.corr()

2024-08-02 23:07:33,618:INFO:PyCaret RegressionExperiment
2024-08-02 23:07:33,618:INFO:Logging name: reg-default-name
2024-08-02 23:07:33,618:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-02 23:07:33,618:INFO:version 3.2.0
2024-08-02 23:07:33,618:INFO:Initializing setup()
2024-08-02 23:07:33,619:INFO:self.USI: 3d5f
2024-08-02 23:07:33,619:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'pipeline', 'idx', '_available_plots', 'exp_id', 'memory', 'X_train', 'seed', 'fold_generator', 'fold_groups_param', 'exp_name_log', 'y', 'X', 'transform_target_param', 'y_test', 'USI', 'html_param', 'gpu_param', 'fold_shuffle_param', 'X_test', 'y_train', 'log_plots_param', '_ml_usecase', 'data', 'target_param'}
2024-08-02 23:07:33,619:INFO:Checking environment
2024-08-02 23:07:33,619:INFO:python_version: 3.8.10
2024-08-02 23:07:33,619:INFO:python_build: ('tags/v3.8.10:3d8993a', 'May  3 2021 11:48:03')
2024-08-02 23:07:33,619:INFO:machine: AMD64
2024-08-02 23:07:33,619:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-02 23:07:33,619:INFO:Memory: svmem(total=34308190208, available=19193380864, percent=44.1, used=15114809344, free=19193380864)
2024-08-02 23:07:33,620:INFO:Physical Core: 8
2024-08-02 23:07:33,620:INFO:Logical Core: 16
2024-08-02 23:07:33,620:INFO:Checking libraries
2024-08-02 23:07:33,620:INFO:System:
2024-08-02 23:07:33,620:INFO:    python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]
2024-08-02 23:07:33,620:INFO:executable: C:\Users\chima\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\python.exe
2024-08-02 23:07:33,620:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-02 23:07:33,620:INFO:PyCaret required dependencies:
2024-08-02 23:07:33,620:INFO:                 pip: 21.1.1
2024-08-02 23:07:33,621:INFO:          setuptools: 56.0.0
2024-08-02 23:07:33,621:INFO:             pycaret: 3.2.0
2024-08-02 23:07:33,621:INFO:             IPython: 8.4.0
2024-08-02 23:07:33,621:INFO:          ipywidgets: 8.1.3
2024-08-02 23:07:33,621:INFO:                tqdm: 4.65.0
2024-08-02 23:07:33,621:INFO:               numpy: 1.24.4
2024-08-02 23:07:33,621:INFO:              pandas: 1.5.0
2024-08-02 23:07:33,621:INFO:              jinja2: 3.1.4
2024-08-02 23:07:33,621:INFO:               scipy: 1.10.1
2024-08-02 23:07:33,621:INFO:              joblib: 1.2.0
2024-08-02 23:07:33,621:INFO:             sklearn: 1.2.2
2024-08-02 23:07:33,621:INFO:                pyod: 2.0.1
2024-08-02 23:07:33,621:INFO:            imblearn: 0.12.3
2024-08-02 23:07:33,622:INFO:   category_encoders: 2.6.3
2024-08-02 23:07:33,622:INFO:            lightgbm: 4.5.0
2024-08-02 23:07:33,622:INFO:               numba: 0.58.1
2024-08-02 23:07:33,622:INFO:            requests: 2.32.3
2024-08-02 23:07:33,622:INFO:          matplotlib: 3.6.0
2024-08-02 23:07:33,622:INFO:          scikitplot: 0.3.7
2024-08-02 23:07:33,622:INFO:         yellowbrick: 1.5
2024-08-02 23:07:33,622:INFO:              plotly: 5.23.0
2024-08-02 23:07:33,622:INFO:    plotly-resampler: Not installed
2024-08-02 23:07:33,622:INFO:             kaleido: 0.2.1
2024-08-02 23:07:33,622:INFO:           schemdraw: 0.15
2024-08-02 23:07:33,623:INFO:         statsmodels: 0.14.1
2024-08-02 23:07:33,623:INFO:              sktime: 0.21.1
2024-08-02 23:07:33,623:INFO:               tbats: 1.1.3
2024-08-02 23:07:33,623:INFO:            pmdarima: 2.0.4
2024-08-02 23:07:33,623:INFO:              psutil: 5.9.1
2024-08-02 23:07:33,623:INFO:          markupsafe: 2.1.5
2024-08-02 23:07:33,623:INFO:             pickle5: Not installed
2024-08-02 23:07:33,623:INFO:         cloudpickle: 3.0.0
2024-08-02 23:07:33,623:INFO:         deprecation: 2.1.0
2024-08-02 23:07:33,623:INFO:              xxhash: 3.4.1
2024-08-02 23:07:33,623:INFO:           wurlitzer: Not installed
2024-08-02 23:07:33,624:INFO:PyCaret optional dependencies:
2024-08-02 23:07:33,624:INFO:                shap: Not installed
2024-08-02 23:07:33,624:INFO:           interpret: Not installed
2024-08-02 23:07:33,624:INFO:                umap: Not installed
2024-08-02 23:07:33,624:INFO:     ydata_profiling: Not installed
2024-08-02 23:07:33,624:INFO:  explainerdashboard: Not installed
2024-08-02 23:07:33,624:INFO:             autoviz: Not installed
2024-08-02 23:07:33,624:INFO:           fairlearn: Not installed
2024-08-02 23:07:33,624:INFO:          deepchecks: Not installed
2024-08-02 23:07:33,624:INFO:             xgboost: Not installed
2024-08-02 23:07:33,624:INFO:            catboost: Not installed
2024-08-02 23:07:33,625:INFO:              kmodes: Not installed
2024-08-02 23:07:33,625:INFO:             mlxtend: Not installed
2024-08-02 23:07:33,625:INFO:       statsforecast: Not installed
2024-08-02 23:07:33,625:INFO:        tune_sklearn: Not installed
2024-08-02 23:07:33,625:INFO:                 ray: Not installed
2024-08-02 23:07:33,625:INFO:            hyperopt: Not installed
2024-08-02 23:07:33,625:INFO:              optuna: Not installed
2024-08-02 23:07:33,625:INFO:               skopt: Not installed
2024-08-02 23:07:33,625:INFO:              mlflow: Not installed
2024-08-02 23:07:33,625:INFO:              gradio: Not installed
2024-08-02 23:07:33,626:INFO:             fastapi: Not installed
2024-08-02 23:07:33,626:INFO:             uvicorn: Not installed
2024-08-02 23:07:33,626:INFO:              m2cgen: Not installed
2024-08-02 23:07:33,626:INFO:           evidently: Not installed
2024-08-02 23:07:33,626:INFO:               fugue: Not installed
2024-08-02 23:07:33,626:INFO:           streamlit: Not installed
2024-08-02 23:07:33,626:INFO:             prophet: Not installed
2024-08-02 23:07:33,626:INFO:None
2024-08-02 23:07:33,627:INFO:Set up data.
2024-08-02 23:07:33,662:INFO:Set up folding strategy.
2024-08-02 23:07:33,663:INFO:Set up train/test split.
2024-08-02 23:07:33,677:INFO:Set up index.
2024-08-02 23:07:33,678:INFO:Assigning column types.
2024-08-02 23:07:33,682:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-02 23:07:33,683:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,690:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,697:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:33,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:33,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,862:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 23:07:33,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,021:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-02 23:07:34,027:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,342:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-02 23:07:34,356:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,517:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,668:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-02 23:07:34,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,828:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,926:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-02 23:07:34,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:34,991:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-02 23:07:35,087:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:35,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-02 23:07:35,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,309:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-02 23:07:35,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:35,629:INFO:Preparing preprocessing pipeline...
2024-08-02 23:07:35,629:INFO:Set up simple imputation.
2024-08-02 23:07:35,632:INFO:Set up encoding of categorical features.
2024-08-02 23:07:35,633:INFO:Set up column name cleaning.
2024-08-02 23:07:35,802:INFO:Finished creating preprocessing pipeline.
2024-08-02 23:07:35,809:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chima\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-08-02 23:07:35,809:INFO:Creating final display dataframe.
2024-08-02 23:07:36,240:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target    Rating Average
2                   Target type        Regression
3           Original data shape        (8861, 13)
4        Transformed data shape        (8861, 13)
5   Transformed train set shape        (6202, 13)
6    Transformed test set shape        (2659, 13)
7              Numeric features                 8
8          Categorical features                 2
9      Rows with missing values              4.4%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3d5f
2024-08-02 23:07:36,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:36,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:36,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:36,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-02 23:07:36,568:INFO:setup() successfully completed in 2.95s...............
2024-08-02 23:07:36,597:INFO:Initializing compare_models()
2024-08-02 23:07:36,598:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-08-02 23:07:36,598:INFO:Checking exceptions
2024-08-02 23:07:36,601:INFO:Preparing display monitor
2024-08-02 23:07:36,638:INFO:Initializing Linear Regression
2024-08-02 23:07:36,639:INFO:Total runtime is 1.6657511393229165e-05 minutes
2024-08-02 23:07:36,642:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:36,642:INFO:Initializing create_model()
2024-08-02 23:07:36,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:36,643:INFO:Checking exceptions
2024-08-02 23:07:36,643:INFO:Importing libraries
2024-08-02 23:07:36,643:INFO:Copying training dataset
2024-08-02 23:07:36,649:INFO:Defining folds
2024-08-02 23:07:36,649:INFO:Declaring metric variables
2024-08-02 23:07:36,652:INFO:Importing untrained model
2024-08-02 23:07:36,656:INFO:Linear Regression Imported successfully
2024-08-02 23:07:36,664:INFO:Starting cross validation
2024-08-02 23:07:36,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:47,675:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:47,681:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 656, in fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 656, in fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:47,682:INFO:Initializing create_model()
2024-08-02 23:07:47,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:47,682:INFO:Checking exceptions
2024-08-02 23:07:47,683:INFO:Importing libraries
2024-08-02 23:07:47,683:INFO:Copying training dataset
2024-08-02 23:07:47,705:INFO:Defining folds
2024-08-02 23:07:47,705:INFO:Declaring metric variables
2024-08-02 23:07:47,712:INFO:Importing untrained model
2024-08-02 23:07:47,723:INFO:Linear Regression Imported successfully
2024-08-02 23:07:47,738:INFO:Starting cross validation
2024-08-02 23:07:47,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:50,641:ERROR:create_model() for lr raised an exception or returned all 0.0:
2024-08-02 23:07:50,642:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 656, in fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 656, in fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 656, in fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 656, in fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:50,643:INFO:Initializing Lasso Regression
2024-08-02 23:07:50,643:INFO:Total runtime is 0.23342512448628744 minutes
2024-08-02 23:07:50,647:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:50,648:INFO:Initializing create_model()
2024-08-02 23:07:50,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:50,649:INFO:Checking exceptions
2024-08-02 23:07:50,649:INFO:Importing libraries
2024-08-02 23:07:50,649:INFO:Copying training dataset
2024-08-02 23:07:50,660:INFO:Defining folds
2024-08-02 23:07:50,660:INFO:Declaring metric variables
2024-08-02 23:07:50,666:INFO:Importing untrained model
2024-08-02 23:07:50,672:INFO:Lasso Regression Imported successfully
2024-08-02 23:07:50,687:INFO:Starting cross validation
2024-08-02 23:07:50,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:50,928:WARNING:create_model() for lasso raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:50,929:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:50,929:INFO:Initializing create_model()
2024-08-02 23:07:50,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:50,929:INFO:Checking exceptions
2024-08-02 23:07:50,929:INFO:Importing libraries
2024-08-02 23:07:50,929:INFO:Copying training dataset
2024-08-02 23:07:50,936:INFO:Defining folds
2024-08-02 23:07:50,937:INFO:Declaring metric variables
2024-08-02 23:07:50,941:INFO:Importing untrained model
2024-08-02 23:07:50,945:INFO:Lasso Regression Imported successfully
2024-08-02 23:07:50,954:INFO:Starting cross validation
2024-08-02 23:07:50,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:51,183:ERROR:create_model() for lasso raised an exception or returned all 0.0:
2024-08-02 23:07:51,183:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:51,184:INFO:Initializing Ridge Regression
2024-08-02 23:07:51,184:INFO:Total runtime is 0.242441725730896 minutes
2024-08-02 23:07:51,187:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:51,188:INFO:Initializing create_model()
2024-08-02 23:07:51,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:51,188:INFO:Checking exceptions
2024-08-02 23:07:51,188:INFO:Importing libraries
2024-08-02 23:07:51,188:INFO:Copying training dataset
2024-08-02 23:07:51,195:INFO:Defining folds
2024-08-02 23:07:51,196:INFO:Declaring metric variables
2024-08-02 23:07:51,200:INFO:Importing untrained model
2024-08-02 23:07:51,204:INFO:Ridge Regression Imported successfully
2024-08-02 23:07:51,211:INFO:Starting cross validation
2024-08-02 23:07:51,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:51,420:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:51,420:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_ridge.py", line 1126, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_ridge.py", line 1126, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:51,421:INFO:Initializing create_model()
2024-08-02 23:07:51,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:51,421:INFO:Checking exceptions
2024-08-02 23:07:51,421:INFO:Importing libraries
2024-08-02 23:07:51,421:INFO:Copying training dataset
2024-08-02 23:07:51,428:INFO:Defining folds
2024-08-02 23:07:51,428:INFO:Declaring metric variables
2024-08-02 23:07:51,432:INFO:Importing untrained model
2024-08-02 23:07:51,436:INFO:Ridge Regression Imported successfully
2024-08-02 23:07:51,443:INFO:Starting cross validation
2024-08-02 23:07:51,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:51,633:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2024-08-02 23:07:51,634:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_ridge.py", line 1126, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_ridge.py", line 1126, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_ridge.py", line 1126, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_ridge.py", line 1126, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:51,634:INFO:Initializing Elastic Net
2024-08-02 23:07:51,634:INFO:Total runtime is 0.24994171460469564 minutes
2024-08-02 23:07:51,638:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:51,638:INFO:Initializing create_model()
2024-08-02 23:07:51,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:51,638:INFO:Checking exceptions
2024-08-02 23:07:51,639:INFO:Importing libraries
2024-08-02 23:07:51,639:INFO:Copying training dataset
2024-08-02 23:07:51,645:INFO:Defining folds
2024-08-02 23:07:51,645:INFO:Declaring metric variables
2024-08-02 23:07:51,649:INFO:Importing untrained model
2024-08-02 23:07:51,653:INFO:Elastic Net Imported successfully
2024-08-02 23:07:51,660:INFO:Starting cross validation
2024-08-02 23:07:51,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:51,851:WARNING:create_model() for en raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:51,852:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:51,852:INFO:Initializing create_model()
2024-08-02 23:07:51,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:51,852:INFO:Checking exceptions
2024-08-02 23:07:51,852:INFO:Importing libraries
2024-08-02 23:07:51,853:INFO:Copying training dataset
2024-08-02 23:07:51,859:INFO:Defining folds
2024-08-02 23:07:51,860:INFO:Declaring metric variables
2024-08-02 23:07:51,864:INFO:Importing untrained model
2024-08-02 23:07:51,868:INFO:Elastic Net Imported successfully
2024-08-02 23:07:51,875:INFO:Starting cross validation
2024-08-02 23:07:51,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:52,069:ERROR:create_model() for en raised an exception or returned all 0.0:
2024-08-02 23:07:52,070:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_coordinate_descent.py", line 908, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:52,070:INFO:Initializing Least Angle Regression
2024-08-02 23:07:52,071:INFO:Total runtime is 0.2572250405947367 minutes
2024-08-02 23:07:52,074:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:52,075:INFO:Initializing create_model()
2024-08-02 23:07:52,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:52,075:INFO:Checking exceptions
2024-08-02 23:07:52,075:INFO:Importing libraries
2024-08-02 23:07:52,075:INFO:Copying training dataset
2024-08-02 23:07:52,083:INFO:Defining folds
2024-08-02 23:07:52,083:INFO:Declaring metric variables
2024-08-02 23:07:52,088:INFO:Importing untrained model
2024-08-02 23:07:52,092:INFO:Least Angle Regression Imported successfully
2024-08-02 23:07:52,099:INFO:Starting cross validation
2024-08-02 23:07:52,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:52,318:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:52,319:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:52,319:INFO:Initializing create_model()
2024-08-02 23:07:52,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:52,319:INFO:Checking exceptions
2024-08-02 23:07:52,319:INFO:Importing libraries
2024-08-02 23:07:52,319:INFO:Copying training dataset
2024-08-02 23:07:52,326:INFO:Defining folds
2024-08-02 23:07:52,326:INFO:Declaring metric variables
2024-08-02 23:07:52,330:INFO:Importing untrained model
2024-08-02 23:07:52,334:INFO:Least Angle Regression Imported successfully
2024-08-02 23:07:52,342:INFO:Starting cross validation
2024-08-02 23:07:52,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:52,540:ERROR:create_model() for lar raised an exception or returned all 0.0:
2024-08-02 23:07:52,541:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:52,541:INFO:Initializing Lasso Least Angle Regression
2024-08-02 23:07:52,541:INFO:Total runtime is 0.26505838632583617 minutes
2024-08-02 23:07:52,545:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:52,545:INFO:Initializing create_model()
2024-08-02 23:07:52,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:52,545:INFO:Checking exceptions
2024-08-02 23:07:52,545:INFO:Importing libraries
2024-08-02 23:07:52,545:INFO:Copying training dataset
2024-08-02 23:07:52,552:INFO:Defining folds
2024-08-02 23:07:52,552:INFO:Declaring metric variables
2024-08-02 23:07:52,556:INFO:Importing untrained model
2024-08-02 23:07:52,560:INFO:Lasso Least Angle Regression Imported successfully
2024-08-02 23:07:52,567:INFO:Starting cross validation
2024-08-02 23:07:52,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:52,762:WARNING:create_model() for llar raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:52,762:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:52,762:INFO:Initializing create_model()
2024-08-02 23:07:52,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:52,762:INFO:Checking exceptions
2024-08-02 23:07:52,763:INFO:Importing libraries
2024-08-02 23:07:52,763:INFO:Copying training dataset
2024-08-02 23:07:52,770:INFO:Defining folds
2024-08-02 23:07:52,771:INFO:Declaring metric variables
2024-08-02 23:07:52,775:INFO:Importing untrained model
2024-08-02 23:07:52,779:INFO:Lasso Least Angle Regression Imported successfully
2024-08-02 23:07:52,786:INFO:Starting cross validation
2024-08-02 23:07:52,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:52,983:ERROR:create_model() for llar raised an exception or returned all 0.0:
2024-08-02 23:07:52,984:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1144, in fit
    self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_least_angle.py", line 1026, in _fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:52,984:INFO:Initializing Orthogonal Matching Pursuit
2024-08-02 23:07:52,984:INFO:Total runtime is 0.2724417448043823 minutes
2024-08-02 23:07:52,987:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:52,988:INFO:Initializing create_model()
2024-08-02 23:07:52,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:52,988:INFO:Checking exceptions
2024-08-02 23:07:52,988:INFO:Importing libraries
2024-08-02 23:07:52,988:INFO:Copying training dataset
2024-08-02 23:07:52,995:INFO:Defining folds
2024-08-02 23:07:52,995:INFO:Declaring metric variables
2024-08-02 23:07:52,999:INFO:Importing untrained model
2024-08-02 23:07:53,003:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-02 23:07:53,010:INFO:Starting cross validation
2024-08-02 23:07:53,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:53,212:WARNING:create_model() for omp raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:53,213:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_omp.py", line 744, in fit
    X, y, X_offset, y_offset, X_scale, Gram, Xy = _pre_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 804, in _pre_fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_omp.py", line 744, in fit
    X, y, X_offset, y_offset, X_scale, Gram, Xy = _pre_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 804, in _pre_fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:53,213:INFO:Initializing create_model()
2024-08-02 23:07:53,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:53,213:INFO:Checking exceptions
2024-08-02 23:07:53,213:INFO:Importing libraries
2024-08-02 23:07:53,214:INFO:Copying training dataset
2024-08-02 23:07:53,220:INFO:Defining folds
2024-08-02 23:07:53,221:INFO:Declaring metric variables
2024-08-02 23:07:53,225:INFO:Importing untrained model
2024-08-02 23:07:53,229:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-02 23:07:53,236:INFO:Starting cross validation
2024-08-02 23:07:53,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:53,441:ERROR:create_model() for omp raised an exception or returned all 0.0:
2024-08-02 23:07:53,442:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_omp.py", line 744, in fit
    X, y, X_offset, y_offset, X_scale, Gram, Xy = _pre_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 804, in _pre_fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_omp.py", line 744, in fit
    X, y, X_offset, y_offset, X_scale, Gram, Xy = _pre_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 804, in _pre_fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_omp.py", line 744, in fit
    X, y, X_offset, y_offset, X_scale, Gram, Xy = _pre_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 804, in _pre_fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_omp.py", line 744, in fit
    X, y, X_offset, y_offset, X_scale, Gram, Xy = _pre_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 804, in _pre_fit
    X, y, X_offset, y_offset, X_scale = _preprocess_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_base.py", line 230, in _preprocess_data
    X = check_array(X, copy=copy, accept_sparse=["csr", "csc"], dtype=FLOAT_DTYPES)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:53,442:INFO:Initializing Bayesian Ridge
2024-08-02 23:07:53,442:INFO:Total runtime is 0.28007507721583047 minutes
2024-08-02 23:07:53,446:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:53,446:INFO:Initializing create_model()
2024-08-02 23:07:53,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:53,446:INFO:Checking exceptions
2024-08-02 23:07:53,447:INFO:Importing libraries
2024-08-02 23:07:53,447:INFO:Copying training dataset
2024-08-02 23:07:53,454:INFO:Defining folds
2024-08-02 23:07:53,454:INFO:Declaring metric variables
2024-08-02 23:07:53,458:INFO:Importing untrained model
2024-08-02 23:07:53,462:INFO:Bayesian Ridge Imported successfully
2024-08-02 23:07:53,470:INFO:Starting cross validation
2024-08-02 23:07:53,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:53,657:WARNING:create_model() for br raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:53,657:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_bayes.py", line 231, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_bayes.py", line 231, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:53,658:INFO:Initializing create_model()
2024-08-02 23:07:53,658:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:53,658:INFO:Checking exceptions
2024-08-02 23:07:53,658:INFO:Importing libraries
2024-08-02 23:07:53,658:INFO:Copying training dataset
2024-08-02 23:07:53,665:INFO:Defining folds
2024-08-02 23:07:53,665:INFO:Declaring metric variables
2024-08-02 23:07:53,670:INFO:Importing untrained model
2024-08-02 23:07:53,674:INFO:Bayesian Ridge Imported successfully
2024-08-02 23:07:53,682:INFO:Starting cross validation
2024-08-02 23:07:53,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:53,912:ERROR:create_model() for br raised an exception or returned all 0.0:
2024-08-02 23:07:53,913:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_bayes.py", line 231, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_bayes.py", line 231, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_bayes.py", line 231, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_bayes.py", line 231, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:53,913:INFO:Initializing Passive Aggressive Regressor
2024-08-02 23:07:53,913:INFO:Total runtime is 0.2879250486691793 minutes
2024-08-02 23:07:53,917:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:53,917:INFO:Initializing create_model()
2024-08-02 23:07:53,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:53,917:INFO:Checking exceptions
2024-08-02 23:07:53,917:INFO:Importing libraries
2024-08-02 23:07:53,918:INFO:Copying training dataset
2024-08-02 23:07:53,924:INFO:Defining folds
2024-08-02 23:07:53,924:INFO:Declaring metric variables
2024-08-02 23:07:53,928:INFO:Importing untrained model
2024-08-02 23:07:53,932:INFO:Passive Aggressive Regressor Imported successfully
2024-08-02 23:07:53,939:INFO:Starting cross validation
2024-08-02 23:07:53,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:54,132:WARNING:create_model() for par raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:54,132:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_passive_aggressive.py", line 567, in fit
    return self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1530, in _fit
    self._partial_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1435, in _partial_fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_passive_aggressive.py", line 567, in fit
    return self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1530, in _fit
    self._partial_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1435, in _partial_fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:54,132:INFO:Initializing create_model()
2024-08-02 23:07:54,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:54,133:INFO:Checking exceptions
2024-08-02 23:07:54,133:INFO:Importing libraries
2024-08-02 23:07:54,133:INFO:Copying training dataset
2024-08-02 23:07:54,140:INFO:Defining folds
2024-08-02 23:07:54,140:INFO:Declaring metric variables
2024-08-02 23:07:54,144:INFO:Importing untrained model
2024-08-02 23:07:54,148:INFO:Passive Aggressive Regressor Imported successfully
2024-08-02 23:07:54,156:INFO:Starting cross validation
2024-08-02 23:07:54,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:54,371:ERROR:create_model() for par raised an exception or returned all 0.0:
2024-08-02 23:07:54,372:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_passive_aggressive.py", line 567, in fit
    return self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1530, in _fit
    self._partial_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1435, in _partial_fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_passive_aggressive.py", line 567, in fit
    return self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1530, in _fit
    self._partial_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1435, in _partial_fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_passive_aggressive.py", line 567, in fit
    return self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1530, in _fit
    self._partial_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1435, in _partial_fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_passive_aggressive.py", line 567, in fit
    return self._fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1530, in _fit
    self._partial_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1435, in _partial_fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:54,372:INFO:Initializing Huber Regressor
2024-08-02 23:07:54,372:INFO:Total runtime is 0.2955750544865926 minutes
2024-08-02 23:07:54,376:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:54,376:INFO:Initializing create_model()
2024-08-02 23:07:54,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:54,376:INFO:Checking exceptions
2024-08-02 23:07:54,377:INFO:Importing libraries
2024-08-02 23:07:54,377:INFO:Copying training dataset
2024-08-02 23:07:54,384:INFO:Defining folds
2024-08-02 23:07:54,384:INFO:Declaring metric variables
2024-08-02 23:07:54,388:INFO:Importing untrained model
2024-08-02 23:07:54,392:INFO:Huber Regressor Imported successfully
2024-08-02 23:07:54,399:INFO:Starting cross validation
2024-08-02 23:07:54,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:54,604:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:54,605:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py", line 297, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py", line 297, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:54,605:INFO:Initializing create_model()
2024-08-02 23:07:54,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:54,605:INFO:Checking exceptions
2024-08-02 23:07:54,605:INFO:Importing libraries
2024-08-02 23:07:54,606:INFO:Copying training dataset
2024-08-02 23:07:54,612:INFO:Defining folds
2024-08-02 23:07:54,613:INFO:Declaring metric variables
2024-08-02 23:07:54,617:INFO:Importing untrained model
2024-08-02 23:07:54,621:INFO:Huber Regressor Imported successfully
2024-08-02 23:07:54,628:INFO:Starting cross validation
2024-08-02 23:07:54,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:54,823:ERROR:create_model() for huber raised an exception or returned all 0.0:
2024-08-02 23:07:54,824:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py", line 297, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py", line 297, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py", line 297, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\linear_model\_huber.py", line 297, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:54,824:INFO:Initializing K Neighbors Regressor
2024-08-02 23:07:54,824:INFO:Total runtime is 0.3031083901723226 minutes
2024-08-02 23:07:54,828:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:54,828:INFO:Initializing create_model()
2024-08-02 23:07:54,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:54,829:INFO:Checking exceptions
2024-08-02 23:07:54,829:INFO:Importing libraries
2024-08-02 23:07:54,829:INFO:Copying training dataset
2024-08-02 23:07:54,836:INFO:Defining folds
2024-08-02 23:07:54,836:INFO:Declaring metric variables
2024-08-02 23:07:54,840:INFO:Importing untrained model
2024-08-02 23:07:54,845:INFO:K Neighbors Regressor Imported successfully
2024-08-02 23:07:54,853:INFO:Starting cross validation
2024-08-02 23:07:54,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:55,056:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:55,057:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_regression.py", line 217, in fit
    return self._fit(X, y)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_base.py", line 663, in _fit
    self._tree = KDTree(
  File "sklearn\neighbors\_binary_tree.pxi", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_regression.py", line 217, in fit
    return self._fit(X, y)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_base.py", line 663, in _fit
    self._tree = KDTree(
  File "sklearn\neighbors\_binary_tree.pxi", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:55,057:INFO:Initializing create_model()
2024-08-02 23:07:55,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:55,057:INFO:Checking exceptions
2024-08-02 23:07:55,057:INFO:Importing libraries
2024-08-02 23:07:55,057:INFO:Copying training dataset
2024-08-02 23:07:55,065:INFO:Defining folds
2024-08-02 23:07:55,065:INFO:Declaring metric variables
2024-08-02 23:07:55,069:INFO:Importing untrained model
2024-08-02 23:07:55,073:INFO:K Neighbors Regressor Imported successfully
2024-08-02 23:07:55,081:INFO:Starting cross validation
2024-08-02 23:07:55,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:55,285:ERROR:create_model() for knn raised an exception or returned all 0.0:
2024-08-02 23:07:55,286:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_regression.py", line 217, in fit
    return self._fit(X, y)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_base.py", line 663, in _fit
    self._tree = KDTree(
  File "sklearn\neighbors\_binary_tree.pxi", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_regression.py", line 217, in fit
    return self._fit(X, y)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_base.py", line 663, in _fit
    self._tree = KDTree(
  File "sklearn\neighbors\_binary_tree.pxi", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_regression.py", line 217, in fit
    return self._fit(X, y)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_base.py", line 663, in _fit
    self._tree = KDTree(
  File "sklearn\neighbors\_binary_tree.pxi", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_regression.py", line 217, in fit
    return self._fit(X, y)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\neighbors\_base.py", line 663, in _fit
    self._tree = KDTree(
  File "sklearn\neighbors\_binary_tree.pxi", line 833, in sklearn.neighbors._kd_tree.BinaryTree.__init__
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:55,286:INFO:Initializing Decision Tree Regressor
2024-08-02 23:07:55,286:INFO:Total runtime is 0.3108084559440613 minutes
2024-08-02 23:07:55,290:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:55,290:INFO:Initializing create_model()
2024-08-02 23:07:55,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:55,290:INFO:Checking exceptions
2024-08-02 23:07:55,290:INFO:Importing libraries
2024-08-02 23:07:55,290:INFO:Copying training dataset
2024-08-02 23:07:55,297:INFO:Defining folds
2024-08-02 23:07:55,297:INFO:Declaring metric variables
2024-08-02 23:07:55,301:INFO:Importing untrained model
2024-08-02 23:07:55,305:INFO:Decision Tree Regressor Imported successfully
2024-08-02 23:07:55,312:INFO:Starting cross validation
2024-08-02 23:07:55,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:55,517:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:55,518:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:55,518:INFO:Initializing create_model()
2024-08-02 23:07:55,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:55,518:INFO:Checking exceptions
2024-08-02 23:07:55,518:INFO:Importing libraries
2024-08-02 23:07:55,518:INFO:Copying training dataset
2024-08-02 23:07:55,525:INFO:Defining folds
2024-08-02 23:07:55,525:INFO:Declaring metric variables
2024-08-02 23:07:55,529:INFO:Importing untrained model
2024-08-02 23:07:55,534:INFO:Decision Tree Regressor Imported successfully
2024-08-02 23:07:55,542:INFO:Starting cross validation
2024-08-02 23:07:55,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:55,742:ERROR:create_model() for dt raised an exception or returned all 0.0:
2024-08-02 23:07:55,743:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:55,743:INFO:Initializing Random Forest Regressor
2024-08-02 23:07:55,743:INFO:Total runtime is 0.3184250632921855 minutes
2024-08-02 23:07:55,747:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:55,748:INFO:Initializing create_model()
2024-08-02 23:07:55,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:55,748:INFO:Checking exceptions
2024-08-02 23:07:55,748:INFO:Importing libraries
2024-08-02 23:07:55,748:INFO:Copying training dataset
2024-08-02 23:07:55,756:INFO:Defining folds
2024-08-02 23:07:55,757:INFO:Declaring metric variables
2024-08-02 23:07:55,761:INFO:Importing untrained model
2024-08-02 23:07:55,765:INFO:Random Forest Regressor Imported successfully
2024-08-02 23:07:55,773:INFO:Starting cross validation
2024-08-02 23:07:55,774:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:55,971:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:55,972:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:55,972:INFO:Initializing create_model()
2024-08-02 23:07:55,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:55,972:INFO:Checking exceptions
2024-08-02 23:07:55,972:INFO:Importing libraries
2024-08-02 23:07:55,972:INFO:Copying training dataset
2024-08-02 23:07:55,979:INFO:Defining folds
2024-08-02 23:07:55,979:INFO:Declaring metric variables
2024-08-02 23:07:55,983:INFO:Importing untrained model
2024-08-02 23:07:55,988:INFO:Random Forest Regressor Imported successfully
2024-08-02 23:07:55,995:INFO:Starting cross validation
2024-08-02 23:07:55,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:56,195:ERROR:create_model() for rf raised an exception or returned all 0.0:
2024-08-02 23:07:56,196:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:56,196:INFO:Initializing Extra Trees Regressor
2024-08-02 23:07:56,196:INFO:Total runtime is 0.32597509622573856 minutes
2024-08-02 23:07:56,200:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:56,200:INFO:Initializing create_model()
2024-08-02 23:07:56,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:56,200:INFO:Checking exceptions
2024-08-02 23:07:56,200:INFO:Importing libraries
2024-08-02 23:07:56,201:INFO:Copying training dataset
2024-08-02 23:07:56,207:INFO:Defining folds
2024-08-02 23:07:56,207:INFO:Declaring metric variables
2024-08-02 23:07:56,211:INFO:Importing untrained model
2024-08-02 23:07:56,215:INFO:Extra Trees Regressor Imported successfully
2024-08-02 23:07:56,222:INFO:Starting cross validation
2024-08-02 23:07:56,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:56,416:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:56,417:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:56,417:INFO:Initializing create_model()
2024-08-02 23:07:56,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:56,417:INFO:Checking exceptions
2024-08-02 23:07:56,417:INFO:Importing libraries
2024-08-02 23:07:56,417:INFO:Copying training dataset
2024-08-02 23:07:56,423:INFO:Defining folds
2024-08-02 23:07:56,424:INFO:Declaring metric variables
2024-08-02 23:07:56,428:INFO:Importing untrained model
2024-08-02 23:07:56,432:INFO:Extra Trees Regressor Imported successfully
2024-08-02 23:07:56,439:INFO:Starting cross validation
2024-08-02 23:07:56,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:56,650:ERROR:create_model() for et raised an exception or returned all 0.0:
2024-08-02 23:07:56,651:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_forest.py", line 345, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:56,651:INFO:Initializing AdaBoost Regressor
2024-08-02 23:07:56,651:INFO:Total runtime is 0.3335584322611491 minutes
2024-08-02 23:07:56,655:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:56,655:INFO:Initializing create_model()
2024-08-02 23:07:56,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:56,656:INFO:Checking exceptions
2024-08-02 23:07:56,656:INFO:Importing libraries
2024-08-02 23:07:56,656:INFO:Copying training dataset
2024-08-02 23:07:56,663:INFO:Defining folds
2024-08-02 23:07:56,663:INFO:Declaring metric variables
2024-08-02 23:07:56,668:INFO:Importing untrained model
2024-08-02 23:07:56,672:INFO:AdaBoost Regressor Imported successfully
2024-08-02 23:07:56,680:INFO:Starting cross validation
2024-08-02 23:07:56,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:56,891:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:56,892:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'The Crusades'

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Escape from 100 Million B.C.'

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'The King of All Bards'


2024-08-02 23:07:56,892:INFO:Initializing create_model()
2024-08-02 23:07:56,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:56,892:INFO:Checking exceptions
2024-08-02 23:07:56,893:INFO:Importing libraries
2024-08-02 23:07:56,893:INFO:Copying training dataset
2024-08-02 23:07:56,900:INFO:Defining folds
2024-08-02 23:07:56,900:INFO:Declaring metric variables
2024-08-02 23:07:56,905:INFO:Importing untrained model
2024-08-02 23:07:56,909:INFO:AdaBoost Regressor Imported successfully
2024-08-02 23:07:56,917:INFO:Starting cross validation
2024-08-02 23:07:56,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:57,132:ERROR:create_model() for ada raised an exception or returned all 0.0:
2024-08-02 23:07:57,132:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'The Crusades'

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Escape from 100 Million B.C.'

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'The King of All Bards'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'The Crusades'

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'Escape from 100 Million B.C.'

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 162, in fit
    sample_weight, estimator_weight, estimator_error = self._boost(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_weight_boosting.py", line 1152, in _boost
    estimator.fit(X_, y_)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 1247, in fit
    super().fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\tree\_classes.py", line 186, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 579, in _validate_data
    X = check_array(X, input_name="X", **check_X_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
ValueError: could not convert string to float: 'The King of All Bards'


2024-08-02 23:07:57,133:INFO:Initializing Gradient Boosting Regressor
2024-08-02 23:07:57,133:INFO:Total runtime is 0.3415917317072551 minutes
2024-08-02 23:07:57,137:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:57,137:INFO:Initializing create_model()
2024-08-02 23:07:57,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:57,137:INFO:Checking exceptions
2024-08-02 23:07:57,137:INFO:Importing libraries
2024-08-02 23:07:57,137:INFO:Copying training dataset
2024-08-02 23:07:57,144:INFO:Defining folds
2024-08-02 23:07:57,145:INFO:Declaring metric variables
2024-08-02 23:07:57,149:INFO:Importing untrained model
2024-08-02 23:07:57,153:INFO:Gradient Boosting Regressor Imported successfully
2024-08-02 23:07:57,161:INFO:Starting cross validation
2024-08-02 23:07:57,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:57,365:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2024-08-02 23:07:57,365:WARNING:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_gb.py", line 429, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_gb.py", line 429, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:57,365:INFO:Initializing create_model()
2024-08-02 23:07:57,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:57,366:INFO:Checking exceptions
2024-08-02 23:07:57,366:INFO:Importing libraries
2024-08-02 23:07:57,366:INFO:Copying training dataset
2024-08-02 23:07:57,372:INFO:Defining folds
2024-08-02 23:07:57,372:INFO:Declaring metric variables
2024-08-02 23:07:57,376:INFO:Importing untrained model
2024-08-02 23:07:57,380:INFO:Gradient Boosting Regressor Imported successfully
2024-08-02 23:07:57,390:INFO:Starting cross validation
2024-08-02 23:07:57,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:07:57,620:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2024-08-02 23:07:57,620:ERROR:Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_gb.py", line 429, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_gb.py", line 429, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_gb.py", line 429, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Last Battle: Twilight - 2000'

--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\ensemble\_gb.py", line 429, in fit
    X, y = self._validate_data(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\base.py", line 584, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 1106, in check_X_y
    X = check_array(
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\sklearn\utils\_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "C:\Users\chima\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\pandas\core\generic.py", line 2069, in __array__
    return np.asarray(self._values, dtype=dtype)
ValueError: could not convert string to float: 'Siege at Peking'


2024-08-02 23:07:57,621:INFO:Initializing Light Gradient Boosting Machine
2024-08-02 23:07:57,621:INFO:Total runtime is 0.34972505172093715 minutes
2024-08-02 23:07:57,625:INFO:SubProcess create_model() called ==================================
2024-08-02 23:07:57,625:INFO:Initializing create_model()
2024-08-02 23:07:57,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:07:57,625:INFO:Checking exceptions
2024-08-02 23:07:57,625:INFO:Importing libraries
2024-08-02 23:07:57,625:INFO:Copying training dataset
2024-08-02 23:07:57,633:INFO:Defining folds
2024-08-02 23:07:57,633:INFO:Declaring metric variables
2024-08-02 23:07:57,637:INFO:Importing untrained model
2024-08-02 23:07:57,641:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-02 23:07:57,648:INFO:Starting cross validation
2024-08-02 23:07:57,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:08:00,134:INFO:Calculating mean and std
2024-08-02 23:08:00,138:INFO:Creating metrics dataframe
2024-08-02 23:08:00,145:INFO:Uploading results into container
2024-08-02 23:08:00,146:INFO:Uploading model into container now
2024-08-02 23:08:00,146:INFO:_master_model_container: 1
2024-08-02 23:08:00,147:INFO:_display_container: 2
2024-08-02 23:08:00,147:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 23:08:00,147:INFO:create_model() successfully completed......................................
2024-08-02 23:08:00,978:INFO:SubProcess create_model() end ==================================
2024-08-02 23:08:00,978:INFO:Creating metrics dataframe
2024-08-02 23:08:00,988:INFO:Initializing Dummy Regressor
2024-08-02 23:08:00,988:INFO:Total runtime is 0.4058417121569316 minutes
2024-08-02 23:08:00,992:INFO:SubProcess create_model() called ==================================
2024-08-02 23:08:00,992:INFO:Initializing create_model()
2024-08-02 23:08:00,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B97C8F0790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:08:00,992:INFO:Checking exceptions
2024-08-02 23:08:00,992:INFO:Importing libraries
2024-08-02 23:08:00,992:INFO:Copying training dataset
2024-08-02 23:08:00,999:INFO:Defining folds
2024-08-02 23:08:00,999:INFO:Declaring metric variables
2024-08-02 23:08:01,004:INFO:Importing untrained model
2024-08-02 23:08:01,008:INFO:Dummy Regressor Imported successfully
2024-08-02 23:08:01,015:INFO:Starting cross validation
2024-08-02 23:08:01,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-02 23:08:01,250:INFO:Calculating mean and std
2024-08-02 23:08:01,252:INFO:Creating metrics dataframe
2024-08-02 23:08:01,255:INFO:Uploading results into container
2024-08-02 23:08:01,256:INFO:Uploading model into container now
2024-08-02 23:08:01,256:INFO:_master_model_container: 2
2024-08-02 23:08:01,257:INFO:_display_container: 2
2024-08-02 23:08:01,257:INFO:DummyRegressor()
2024-08-02 23:08:01,257:INFO:create_model() successfully completed......................................
2024-08-02 23:08:02,111:INFO:SubProcess create_model() end ==================================
2024-08-02 23:08:02,111:INFO:Creating metrics dataframe
2024-08-02 23:08:02,138:INFO:Initializing create_model()
2024-08-02 23:08:02,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:08:02,139:INFO:Checking exceptions
2024-08-02 23:08:02,142:INFO:Importing libraries
2024-08-02 23:08:02,142:INFO:Copying training dataset
2024-08-02 23:08:02,155:INFO:Defining folds
2024-08-02 23:08:02,155:INFO:Declaring metric variables
2024-08-02 23:08:02,155:INFO:Importing untrained model
2024-08-02 23:08:02,156:INFO:Declaring custom model
2024-08-02 23:08:02,156:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-02 23:08:02,158:INFO:Cross validation set to False
2024-08-02 23:08:02,158:INFO:Fitting Model
2024-08-02 23:08:02,235:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-02 23:08:02,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000512 seconds.
2024-08-02 23:08:02,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 23:08:02,237:INFO:[LightGBM] [Info] Total Bins 1419
2024-08-02 23:08:02,237:INFO:[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 12
2024-08-02 23:08:02,237:INFO:[LightGBM] [Info] Start training from score 6.625967
2024-08-02 23:08:02,368:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 23:08:02,368:INFO:create_model() successfully completed......................................
2024-08-02 23:08:02,741:INFO:_master_model_container: 2
2024-08-02 23:08:02,741:INFO:_display_container: 2
2024-08-02 23:08:02,742:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 23:08:02,742:INFO:compare_models() successfully completed......................................
2024-08-02 23:08:02,780:INFO:Initializing finalize_model()
2024-08-02 23:08:02,780:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-02 23:08:02,781:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-02 23:08:02,785:INFO:Initializing create_model()
2024-08-02 23:08:02,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-02 23:08:02,785:INFO:Checking exceptions
2024-08-02 23:08:02,787:INFO:Importing libraries
2024-08-02 23:08:02,787:INFO:Copying training dataset
2024-08-02 23:08:02,787:INFO:Defining folds
2024-08-02 23:08:02,787:INFO:Declaring metric variables
2024-08-02 23:08:02,788:INFO:Importing untrained model
2024-08-02 23:08:02,788:INFO:Declaring custom model
2024-08-02 23:08:02,789:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-02 23:08:02,790:INFO:Cross validation set to False
2024-08-02 23:08:02,790:INFO:Fitting Model
2024-08-02 23:08:02,882:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-08-02 23:08:02,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.
2024-08-02 23:08:02,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-02 23:08:02,884:INFO:[LightGBM] [Info] Total Bins 1424
2024-08-02 23:08:02,884:INFO:[LightGBM] [Info] Number of data points in the train set: 8861, number of used features: 12
2024-08-02 23:08:02,885:INFO:[LightGBM] [Info] Start training from score 6.629909
2024-08-02 23:08:03,041:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-02 23:08:03,041:INFO:create_model() successfully completed......................................
2024-08-02 23:08:03,375:INFO:_master_model_container: 2
2024-08-02 23:08:03,375:INFO:_display_container: 2
2024-08-02 23:08:03,384:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-02 23:08:03,385:INFO:finalize_model() successfully completed......................................
2024-08-02 23:08:03,720:INFO:Initializing predict_model()
2024-08-02 23:08:03,721:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Min Players', 'Max Players',
                                             'Play Time', 'Min Age',
                                             'Users Rated', 'BGG Rank',
                                             'Complexity Average',
                                             'Owned Users'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Mechanics', 'Domains'],
                                    transformer=TargetEncoder(cols=['Mechanics',
                                                                    'Domains'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B91ABB6CA0>)
2024-08-02 23:08:03,721:INFO:Checking exceptions
2024-08-02 23:08:03,721:INFO:Preloading libraries
2024-08-02 23:08:03,723:INFO:Set up data.
2024-08-02 23:08:03,749:INFO:Set up index.
2024-08-02 23:08:04,176:INFO:Initializing plot_model()
2024-08-02 23:08:04,176:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, system=True)
2024-08-02 23:08:04,176:INFO:Checking exceptions
2024-08-02 23:08:04,181:INFO:Preloading libraries
2024-08-02 23:08:04,192:INFO:Copying training dataset
2024-08-02 23:08:04,193:INFO:Plot type: residuals
2024-08-02 23:08:04,649:INFO:Fitting Model
2024-08-02 23:08:04,729:INFO:Scoring test/hold-out set
2024-08-02 23:08:05,288:INFO:Visual Rendered Successfully
2024-08-02 23:08:05,650:INFO:plot_model() successfully completed......................................
2024-08-02 23:08:05,666:INFO:Initializing plot_model()
2024-08-02 23:08:05,667:INFO:plot_model(plot=manifold, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, system=True)
2024-08-02 23:08:05,667:INFO:Checking exceptions
2024-08-02 23:08:05,672:INFO:Preloading libraries
2024-08-02 23:08:05,684:INFO:Copying training dataset
2024-08-02 23:08:05,684:INFO:Plot type: manifold
2024-08-02 23:08:06,130:INFO:Fitting & Transforming Model
2024-08-02 23:08:25,356:INFO:Visual Rendered Successfully
2024-08-02 23:08:25,681:INFO:plot_model() successfully completed......................................
2024-08-02 23:08:25,728:INFO:Initializing plot_model()
2024-08-02 23:08:25,728:INFO:plot_model(plot=rfe, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, system=True)
2024-08-02 23:08:25,728:INFO:Checking exceptions
2024-08-02 23:08:25,733:INFO:Preloading libraries
2024-08-02 23:08:25,747:INFO:Copying training dataset
2024-08-02 23:08:25,747:INFO:Plot type: rfe
2024-08-02 23:08:26,192:INFO:Fitting Model
2024-08-02 23:09:09,898:INFO:Initializing plot_model()
2024-08-02 23:09:09,898:INFO:plot_model(plot=rfe, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, system=True)
2024-08-02 23:09:09,898:INFO:Checking exceptions
2024-08-02 23:09:09,904:INFO:Preloading libraries
2024-08-02 23:09:09,917:INFO:Copying training dataset
2024-08-02 23:09:09,917:INFO:Plot type: rfe
2024-08-02 23:09:10,369:INFO:Fitting Model
2024-08-02 23:09:14,650:INFO:Initializing plot_model()
2024-08-02 23:09:14,650:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B97B4309A0>, system=True)
2024-08-02 23:09:14,650:INFO:Checking exceptions
2024-08-02 23:09:14,656:INFO:Preloading libraries
2024-08-02 23:09:14,670:INFO:Copying training dataset
2024-08-02 23:09:14,670:INFO:Plot type: feature
2024-08-02 23:09:14,671:WARNING:No coef_ found. Trying feature_importances_
2024-08-02 23:09:15,004:INFO:Visual Rendered Successfully
2024-08-02 23:09:15,355:INFO:plot_model() successfully completed......................................
